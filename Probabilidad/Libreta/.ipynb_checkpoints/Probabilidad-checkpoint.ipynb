{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de contenido 游눞<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Matem치ticas-para-Data-Science:-Probabilidad\" data-toc-modified-id=\"Matem치ticas-para-Data-Science:-Probabilidad-1\">Matem치ticas para Data Science: Probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Incertidumbre-y-probabilidad\" data-toc-modified-id=\"Incertidumbre-y-probabilidad-1.1\">Incertidumbre y probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Axiomas-de-la-probabilidad\" data-toc-modified-id=\"Axiomas-de-la-probabilidad-1.1.1\">Axiomas de la probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Axioma-1.\" data-toc-modified-id=\"Axioma-1.-1.1.1.1\">Axioma 1.</a></span></li><li><span><a href=\"#Axioma-2.\" data-toc-modified-id=\"Axioma-2.-1.1.1.2\">Axioma 2.</a></span></li><li><span><a href=\"#Axioma-3.\" data-toc-modified-id=\"Axioma-3.-1.1.1.3\">Axioma 3.</a></span></li></ul></li><li><span><a href=\"#Propiedades-que-se-deducen-de-los-axiomas\" data-toc-modified-id=\"Propiedades-que-se-deducen-de-los-axiomas-1.1.2\">Propiedades que se deducen de los axiomas</a></span></li><li><span><a href=\"#Probabilidad-en-Machine-Learning\" data-toc-modified-id=\"Probabilidad-en-Machine-Learning-1.1.3\">Probabilidad en Machine Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fuentes-de-incertidumbre\" data-toc-modified-id=\"Fuentes-de-incertidumbre-1.1.3.1\">Fuentes de incertidumbre</a></span></li></ul></li></ul></li><li><span><a href=\"#Fundamentos-de-probabilidad\" data-toc-modified-id=\"Fundamentos-de-probabilidad-1.2\">Fundamentos de probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tipos-de-probabilidad\" data-toc-modified-id=\"Tipos-de-probabilidad-1.2.1\">Tipos de probabilidad</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matem치ticas para Data Science: Probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incertidumbre y probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axiomas de la probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un conjunto de sucesos elementales $\\Omega$, sobre el que se ha definido una $\\sigma$-치lgebra $\\sigma$  (familia $\\Sigma$ no vac칤a de subconjuntos de un conjunto $X$, cerrada bajo complementos, uniones e intersecciones contables) de conjuntos de $\\Omega$ y una funci칩n $P$ que asigna valores reales a los miembros de $\\sigma$, a los que denominamos \"sucesos\", se dice que $P$ es una probabilidad sobre $(\\Omega, \\sigma)$ si se cumplen los siguientes 3 axiomas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axioma 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de un evento $S$ no puede ser negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$0 \\leq P(S)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axioma 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de un evento seguro, $\\Omega$, es igual a 1, denotado simb칩licamente como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\Omega) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axioma 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $E_1, E_2, ...$ son eventos **mutuamente excluyentes** (su intersecci칩n es el conjunto vac칤o), entonces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(E_1 \\cup E_2 \\cup ...) = \\sum{P(E_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seg칰n este axioma se puede calcular la probabilidad de un suceso compuesto de varias alternativas mutuamente excluyentes sumando las probabilidades de sus componentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En t칠rminos m치s formales, una probabilidad es una medida sobre una $\\sigma$-치lgebra (sigma-치lgebra) de subconjuntos del espacio muestral, siendo los subconjuntos miembros de la $\\sigma$-치lgebra los sucesos y definida de tal manera que la medida del total sea 1. Tal medida, gracias a su definici칩n matem치tica, verifica igualmente los 3 axiomas de Kolmog칩rov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la terna formada por el **espacio muestral, la $\\sigma$-치lgebra y la funci칩n de probabilidad** se la denomina **espacio probabil칤stico** , esto es, un \"espacio de sucesos\" en el que se ha definido los posibles sucesos a considerar (la $ \\sigma$-치lgebra) y la probabilidad de cada suceso (la funci칩n de probabilidad)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades que se deducen de los axiomas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los axiomas anteriores podemos obtener las siguiente proposiciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $P(\\phi)= 0$ donde el conjunto vac칤o ($\\phi$) representa en probabilidad el **suceso imposible**.\n",
    "\n",
    "2. Para cualquier evento, $P(E) \\leq 1$.\n",
    "\n",
    "3. $P(A^c) = 1 - P(A)$, donde $A^c$ representa el conjunto complemento de $A$ (todos los elementos que no est치n en $A$).\n",
    "\n",
    "4. Si $E \\subseteq F$ entonces, $P(E) \\leq P(F)$. Si $E$ es un subconjunto de $F$, la probabilidad de $E$ es menor que la probabilidad de $F$.\n",
    "\n",
    "5. $P(E \\cup F) = P(E) + P(F) - P(E \\cap F)$. Sumamos las probabilidades individuales y restamos la parte en que interseccionan para no contarla 2 veces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad en Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuentes de incertidumbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Datos**: Para obtener los datos partimos de una obtenci칩n o una medici칩n de datos, por lo que esta recolecci칩n de datos siempre estar치 sujeta a ciertos m치rgenes de error que mantendr치n nuestros datos desde un inicio con cierta \"imperfecci칩n\" o incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Atributos del modelo**: Tambi칠n llamados **predictores** son un subconjunto o reducci칩n de todas las variables que intervienen en un problema en espec칤fico para facilitar la resoluci칩n del problema. Es decir, al estudiar un problema complejo usualmente estudiamos ciertas variables que resultan relevantes para nosotros o que creemos que est치n estrechamente relacionadas con el fen칩meno de estudio, pero en realidad puede que estemos dejando muchas variables de lado, las cuales pueden hacer peque침as contribuciones al problema real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Arquitectura del modelo**: Nuestro modelo al final de cuentas siempre ser치 una versi칩n simplificada de la realidad, de forma que podamos \"aproximar\" el comportamiento que estamos interesados en estudiar. As칤 que es de esperarse que se \"pierda\" algo de informaci칩n o exactitud cuando comparemos nuestros resultados arrojados por el modelo vs el fen칩meno real. Nuestro trabajo es tratar de aproximarnos lo m치s posible y minimizar esos errores con modelos m치s completos y complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, al trabajar con modelos de clasificaci칩n trabajamos con probabilidades para deducir a que grupo pertenece cierto elemento de entrada. Aunque nunca tendremos una certeza del 100% si que podremos calcular las probabilidades individuales de que pertenezca a cada uno de los grupos para tomar decisiones m치s certeras ya que nuestro modelo nos arrojar치 la opci칩n que nos arroje las probabilidades m치s altas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo de la arquitectura general de un modelo de clasificaci칩n supervisada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/sxCngb6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tenemos nuestra **fase de entrenamiento** donde comenzamos con nuestros datos etiquetados, de forma que tenemos ya ubicados ciertos atributos o features para despu칠s pasar por un extractor de atributos de forma que ubica las variables m치s importantes para que el modelo realice sus predicciones. Una vez pasa por el extractor pasamos de tener un input de cierto tipo a tener 칰nicamente atributos o variables con las que vamos a trabajar. Posteriormente entra en juego nuestro algoritmos de Machine Learning, que variar치n dependiendo de la tarea a resolver y que t칠cnicas va a utilizar, pero al final va a arrojarnos un modelo matem치tico de clasificaci칩n que se adaptar치 seg칰n nuestro data set de entrenamiento.\n",
    "\n",
    "Despu칠s, en nuestra parte de **predicci칩n** una vez que ya tenemos nuestro modelo de clasificaci칩n le pasamos **nuevos datos** con los que va a tratar de hacer predicciones a partir de lo que aprendi칩 de los datos de entrenamiento. Para esto ingresamos nuestros datos, que ya no est치n necesariamente etiquetados; pasan por el extractor de atributos y a partir de los features que reconoce como m치s importantes trata de realizar predicciones. De forma que al final del proceso obtenemos una etiqueta que nos 칤ndica a que clase pertenece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede que en la mayor칤a de etapas de nuestro modelo tengamos que trabajar con probabilidades para realizar nuestra predicciones aunque no siempre tiene que ser as칤, esto depender치 siempre del dise침o que elijamos para nuestro algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/6Fy93Tm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que seleccionamos el **dise침o** de nuestro modelo procedemos a definir la etapa de entrenamiento, es decir, como va a realizar el proceso de la asignaci칩n de los valores de nuestros inputs para ciertos outputs. Usualmente se suele utilizar la estimaci칩n por **m치xima verosimilitud** o **MLE** por sus siglas en ingl칠s; la cual es una t칠cnica que se usa para ajustar nuestro modelo y estimar sus par치metros, de forma que a partir de esa t칠cnica nuestro modelo aprender치 a asignar probabilidades a cada una de nuestras posibles ocurrencias de nuestros datos. \n",
    "\n",
    "Despu칠s pasamos por una **etapa de calibraci칩n**, donde lo que calibramos no son nuestros par치metros en s칤 (de eso ya se encarga el entrenamiento), si no que ahora tratamos de minimizar los errores dados por variables externas al proceso de optimizaci칩n, es decir, errores que vienen dados por **hiper-par치metros** (par치metros fuera de nuestro esquema de optimizaci칩n).\n",
    "\n",
    "Finalmente pasamos por un **proceso de interpretaci칩n** de la predicci칩n realizada, por que a pesar de que al final lo que estamos obteniendo solo son n칰meros o probabilidades, muchas veces viene como resultado de un proceso sumamente complejo y nos puede resultar muy dif칤cil o confuso el interpretar los resultados. Por ejemplo, si estamos recibiendo probabilidades como valores de salida, muchas veces tenemos que reinterpretar esos datos tambi칠n de forma probabil칤stica para llegar a una conclusi칩n clara."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conjunta (joint)\n",
    "* Marginal\n",
    "* Condicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a considerar un ejemplo de un lanzamiento de 2 dados para ver las diferentes perspectivas de cada tipo de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del lanzamiento de 1 dado tenemos 6 posibles opciones, pero al lanzar 2 dados vamos a tener 36 posibles combinaciones. \n",
    "\n",
    "Podemos imaginarlo como si por cada posible resultado en el dado A tendremos 6 posibles resultados del dado B, por lo que tendremos $6 \\cdot 6$ combinaciones (como si recorrieramos los 6 posibles eventos de B en cada evento de A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/TeWn9rQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, pensemos **쮺칩mo calcular칤amos la probabilidad de que ambos dados caigan en n칰mero par**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los lanzamientos de los dados son eventos independientes, es decir, obtenemos un resultado en el dado A sin que afecte al dado B. Entonces podemos calcular cual es la probabilidad de que un solo dado caiga en n칰mero par, que es una probabilidad de $P(\\text{par}) = \\frac{3}{6}$ y ahora, para cada unos de los 3 posibles casos donde es par en nuestro dado A tendremos otros 3 posibles casos de obtener un n칰mero par en nuestro dado B, por lo que lo podemos expresar como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{par}, \\text{par})= \\frac{3}{6} \\cdot \\frac{3}{6} = \\frac{1}{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XX2tf24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver a la probabilidad anterior como la probabilidad de la **uni칩n de 2 sucesos independientes**. Cuando calculamos probabilidades de 2 o m치s eventos que ocurren o son estudiados en el mismo experimento se le llama **probabilidad conjunta**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora consideremos la siguiente pregunta, **쮺u치l es la probabilidad de que A caiga par, dado que cay칩 B en par**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso estamos condicionando el calculo de una probabilidad a que previamente ocurri칩 otro evento que nos interesa, es decir, en lugar de evaluar las probabilidades sobre todo nuestro espacio muestral $S$, estamos evaluando nuestras probabilidades en un \"sub-espacio muestral\" que solo abarca los eventos en los que ocurri칩 nuestro evento en B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma que nuestro espacio muestral pasa de 36 posibilidades a 18 (6 posibles eventos de A y 3 eventos de B donde son pares). Y ahora calculamos nuestra probabilidad de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A=\\text{par}|B=\\text{par}) = \\frac{9}{18} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/xsCliKI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos relacionar estos 2 resultados aparentemente distintos de la siguiente forma. Recordemos que ya calculamos la probabilidad de que ambos resultados sean par y la probabilidad de que un dado sea par dado que el otro tambi칠n es par.\n",
    "\n",
    "Ahora vamos a preguntarnos. **쮺u치l es la probabilidad de que B sea par?** De nuevo es una probabilidad independiente de lo que ocurre en A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(B) = \\frac{18}{36} = \\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que si nos damos cuenta, la probabilidad de dicho evento es la suma de nuestras columnas amarillas de la imagen de arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y pongamos atenci칩n en que pasa al multiplicar nuestra $P(B) \\cdot P(A|B)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(B) \\cdot P(A|B) = \\frac{18}{36} \\cdot \\frac{9}{18} = \\frac{9}{36} = \\frac{1}{4} = P(\\text{par}, \\text{par})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es decir, al multiplicar la probabilidad de nuestro evento B por la probabilidad de nuestro evento A dado B, obtenemos la **probabilidad conjunta**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, esto anterior no es un caso particular sino que se le conoce como la **regla del producto** que dice lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A,B) = P(A|B)P(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o escrita de una forma en la que no la vamos a encontrar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(A|B) = \\frac{P(A \\cap B)}{P(B)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hablemos sobre la **probabilidad marginal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con probabilidad marginal nos referimos a cuando obtenemos una probabilidad \"sencilla\" a partir de una probabilidad conjunta. Es decir, la probabilidad de un evento simple que es independiente al resto de eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y se expresa de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p_x(x) = \\sum_{y}{P(x,y)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad marginal de $x$ es la suma de todas las probabilidades conjuntas sobre los dem치s estados que no consideran a $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir c칤clicamente a la probabilidad marginal a partir de la conjunta y la condicional o a la condicional en t칠rminos de la conjunta y la marginal, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenido 游눞",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.273px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
