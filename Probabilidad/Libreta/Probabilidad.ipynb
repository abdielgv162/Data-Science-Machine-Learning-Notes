{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de contenido 游눞<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Matem치ticas-para-Data-Science:-Probabilidad\" data-toc-modified-id=\"Matem치ticas-para-Data-Science:-Probabilidad-1\">Matem치ticas para Data Science: Probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Incertidumbre-y-probabilidad\" data-toc-modified-id=\"Incertidumbre-y-probabilidad-1.1\">Incertidumbre y probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Axiomas-de-la-probabilidad\" data-toc-modified-id=\"Axiomas-de-la-probabilidad-1.1.1\">Axiomas de la probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Axioma-1.\" data-toc-modified-id=\"Axioma-1.-1.1.1.1\">Axioma 1.</a></span></li><li><span><a href=\"#Axioma-2.\" data-toc-modified-id=\"Axioma-2.-1.1.1.2\">Axioma 2.</a></span></li><li><span><a href=\"#Axioma-3.\" data-toc-modified-id=\"Axioma-3.-1.1.1.3\">Axioma 3.</a></span></li></ul></li><li><span><a href=\"#Propiedades-que-se-deducen-de-los-axiomas\" data-toc-modified-id=\"Propiedades-que-se-deducen-de-los-axiomas-1.1.2\">Propiedades que se deducen de los axiomas</a></span></li><li><span><a href=\"#Probabilidad-en-Machine-Learning\" data-toc-modified-id=\"Probabilidad-en-Machine-Learning-1.1.3\">Probabilidad en Machine Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fuentes-de-incertidumbre\" data-toc-modified-id=\"Fuentes-de-incertidumbre-1.1.3.1\">Fuentes de incertidumbre</a></span></li></ul></li></ul></li><li><span><a href=\"#Fundamentos-de-probabilidad\" data-toc-modified-id=\"Fundamentos-de-probabilidad-1.2\">Fundamentos de probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tipos-de-probabilidad\" data-toc-modified-id=\"Tipos-de-probabilidad-1.2.1\">Tipos de probabilidad</a></span></li><li><span><a href=\"#Ejemplos-de-c치lculo-de-probabilidad\" data-toc-modified-id=\"Ejemplos-de-c치lculo-de-probabilidad-1.2.2\">Ejemplos de c치lculo de probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Correlaciones-de-eventos\" data-toc-modified-id=\"Correlaciones-de-eventos-1.2.2.1\">Correlaciones de eventos</a></span></li><li><span><a href=\"#Ejercicio-#1\" data-toc-modified-id=\"Ejercicio-#1-1.2.2.2\">Ejercicio #1</a></span></li><li><span><a href=\"#Paradoja-쯡i침o-o-ni침a?\" data-toc-modified-id=\"Paradoja-쯡i침o-o-ni침a?-1.2.2.3\">Paradoja 쯡i침o o ni침a?</a></span></li><li><span><a href=\"#El-problema-de-Monthy-Hall\" data-toc-modified-id=\"El-problema-de-Monthy-Hall-1.2.2.4\">El problema de Monthy Hall</a></span></li></ul></li></ul></li><li><span><a href=\"#Distribuciones-de-probabilidad\" data-toc-modified-id=\"Distribuciones-de-probabilidad-1.3\">Distribuciones de probabilidad</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matem치ticas para Data Science: Probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incertidumbre y probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axiomas de la probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un conjunto de sucesos elementales $\\Omega$, sobre el que se ha definido una $\\sigma$-치lgebra $\\sigma$  (familia $\\Sigma$ no vac칤a de subconjuntos de un conjunto $X$, cerrada bajo complementos, uniones e intersecciones contables) de conjuntos de $\\Omega$ y una funci칩n $P$ que asigna valores reales a los miembros de $\\sigma$, a los que denominamos \"sucesos\", se dice que $P$ es una probabilidad sobre $(\\Omega, \\sigma)$ si se cumplen los siguientes 3 axiomas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axioma 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de un evento $S$ no puede ser negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$0 \\leq P(S)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axioma 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de un evento seguro, $\\Omega$, es igual a 1, denotado simb칩licamente como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\Omega) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axioma 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $E_1, E_2, ...$ son eventos **mutuamente excluyentes** (su intersecci칩n es el conjunto vac칤o), entonces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(E_1 \\cup E_2 \\cup ...) = \\sum{P(E_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seg칰n este axioma se puede calcular la probabilidad de un suceso compuesto de varias alternativas mutuamente excluyentes sumando las probabilidades de sus componentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En t칠rminos m치s formales, una probabilidad es una medida sobre una $\\sigma$-치lgebra (sigma-치lgebra) de subconjuntos del espacio muestral, siendo los subconjuntos miembros de la $\\sigma$-치lgebra los sucesos y definida de tal manera que la medida del total sea 1. Tal medida, gracias a su definici칩n matem치tica, verifica igualmente los 3 axiomas de Kolmog칩rov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la terna formada por el **espacio muestral, la $\\sigma$-치lgebra y la funci칩n de probabilidad** se la denomina **espacio probabil칤stico** , esto es, un \"espacio de sucesos\" en el que se ha definido los posibles sucesos a considerar (la $ \\sigma$-치lgebra) y la probabilidad de cada suceso (la funci칩n de probabilidad)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades que se deducen de los axiomas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los axiomas anteriores podemos obtener las siguiente proposiciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $P(\\phi)= 0$ donde el conjunto vac칤o ($\\phi$) representa en probabilidad el **suceso imposible**.\n",
    "\n",
    "2. Para cualquier evento, $P(E) \\leq 1$.\n",
    "\n",
    "3. $P(A^c) = 1 - P(A)$, donde $A^c$ representa el conjunto complemento de $A$ (todos los elementos que no est치n en $A$).\n",
    "\n",
    "4. Si $E \\subseteq F$ entonces, $P(E) \\leq P(F)$. Si $E$ es un subconjunto de $F$, la probabilidad de $E$ es menor que la probabilidad de $F$.\n",
    "\n",
    "5. $P(E \\cup F) = P(E) + P(F) - P(E \\cap F)$. Sumamos las probabilidades individuales y restamos la parte en que interseccionan para no contarla 2 veces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad en Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuentes de incertidumbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Datos**: Para obtener los datos partimos de una obtenci칩n o una medici칩n de datos, por lo que esta recolecci칩n de datos siempre estar치 sujeta a ciertos m치rgenes de error que mantendr치n nuestros datos desde un inicio con cierta \"imperfecci칩n\" o incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Atributos del modelo**: Tambi칠n llamados **predictores** son un subconjunto o reducci칩n de todas las variables que intervienen en un problema en espec칤fico para facilitar la resoluci칩n del problema. Es decir, al estudiar un problema complejo usualmente estudiamos ciertas variables que resultan relevantes para nosotros o que creemos que est치n estrechamente relacionadas con el fen칩meno de estudio, pero en realidad puede que estemos dejando muchas variables de lado, las cuales pueden hacer peque침as contribuciones al problema real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Arquitectura del modelo**: Nuestro modelo al final de cuentas siempre ser치 una versi칩n simplificada de la realidad, de forma que podamos \"aproximar\" el comportamiento que estamos interesados en estudiar. As칤 que es de esperarse que se \"pierda\" algo de informaci칩n o exactitud cuando comparemos nuestros resultados arrojados por el modelo vs el fen칩meno real. Nuestro trabajo es tratar de aproximarnos lo m치s posible y minimizar esos errores con modelos m치s completos y complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, al trabajar con modelos de clasificaci칩n trabajamos con probabilidades para deducir a que grupo pertenece cierto elemento de entrada. Aunque nunca tendremos una certeza del 100% si que podremos calcular las probabilidades individuales de que pertenezca a cada uno de los grupos para tomar decisiones m치s certeras ya que nuestro modelo nos arrojar치 la opci칩n que nos arroje las probabilidades m치s altas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo de la arquitectura general de un modelo de clasificaci칩n supervisada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/sxCngb6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tenemos nuestra **fase de entrenamiento** donde comenzamos con nuestros datos etiquetados, de forma que tenemos ya ubicados ciertos atributos o features para despu칠s pasar por un extractor de atributos de forma que ubica las variables m치s importantes para que el modelo realice sus predicciones. Una vez pasa por el extractor pasamos de tener un input de cierto tipo a tener 칰nicamente atributos o variables con las que vamos a trabajar. Posteriormente entra en juego nuestro algoritmos de Machine Learning, que variar치n dependiendo de la tarea a resolver y que t칠cnicas va a utilizar, pero al final va a arrojarnos un modelo matem치tico de clasificaci칩n que se adaptar치 seg칰n nuestro data set de entrenamiento.\n",
    "\n",
    "Despu칠s, en nuestra parte de **predicci칩n** una vez que ya tenemos nuestro modelo de clasificaci칩n le pasamos **nuevos datos** con los que va a tratar de hacer predicciones a partir de lo que aprendi칩 de los datos de entrenamiento. Para esto ingresamos nuestros datos, que ya no est치n necesariamente etiquetados; pasan por el extractor de atributos y a partir de los features que reconoce como m치s importantes trata de realizar predicciones. De forma que al final del proceso obtenemos una etiqueta que nos 칤ndica a que clase pertenece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede que en la mayor칤a de etapas de nuestro modelo tengamos que trabajar con probabilidades para realizar nuestra predicciones aunque no siempre tiene que ser as칤, esto depender치 siempre del dise침o que elijamos para nuestro algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/6Fy93Tm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que seleccionamos el **dise침o** de nuestro modelo procedemos a definir la etapa de entrenamiento, es decir, como va a realizar el proceso de la asignaci칩n de los valores de nuestros inputs para ciertos outputs. Usualmente se suele utilizar la estimaci칩n por **m치xima verosimilitud** o **MLE** por sus siglas en ingl칠s; la cual es una t칠cnica que se usa para ajustar nuestro modelo y estimar sus par치metros, de forma que a partir de esa t칠cnica nuestro modelo aprender치 a asignar probabilidades a cada una de nuestras posibles ocurrencias de nuestros datos. \n",
    "\n",
    "Despu칠s pasamos por una **etapa de calibraci칩n**, donde lo que calibramos no son nuestros par치metros en s칤 (de eso ya se encarga el entrenamiento), si no que ahora tratamos de minimizar los errores dados por variables externas al proceso de optimizaci칩n, es decir, errores que vienen dados por **hiper-par치metros** (par치metros fuera de nuestro esquema de optimizaci칩n).\n",
    "\n",
    "Finalmente pasamos por un **proceso de interpretaci칩n** de la predicci칩n realizada, por que a pesar de que al final lo que estamos obteniendo solo son n칰meros o probabilidades, muchas veces viene como resultado de un proceso sumamente complejo y nos puede resultar muy dif칤cil o confuso el interpretar los resultados. Por ejemplo, si estamos recibiendo probabilidades como valores de salida, muchas veces tenemos que reinterpretar esos datos tambi칠n de forma probabil칤stica para llegar a una conclusi칩n clara."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conjunta (joint)\n",
    "* Marginal\n",
    "* Condicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a considerar un ejemplo de un lanzamiento de 2 dados para ver las diferentes perspectivas de cada tipo de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del lanzamiento de 1 dado tenemos 6 posibles opciones, pero al lanzar 2 dados vamos a tener 36 posibles combinaciones. \n",
    "\n",
    "Podemos imaginarlo como si por cada posible resultado en el dado A tendremos 6 posibles resultados del dado B, por lo que tendremos $6 \\cdot 6$ combinaciones (como si recorrieramos los 6 posibles eventos de B en cada evento de A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/TeWn9rQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, pensemos **쮺칩mo calcular칤amos la probabilidad de que ambos dados caigan en n칰mero par**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los lanzamientos de los dados son eventos independientes, es decir, obtenemos un resultado en el dado A sin que afecte al dado B. Entonces podemos calcular cual es la probabilidad de que un solo dado caiga en n칰mero par, que es una probabilidad de $P(\\text{par}) = \\frac{3}{6}$ y ahora, para cada unos de los 3 posibles casos donde es par en nuestro dado A tendremos otros 3 posibles casos de obtener un n칰mero par en nuestro dado B, por lo que lo podemos expresar como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{par}, \\text{par})= \\frac{3}{6} \\cdot \\frac{3}{6} = \\frac{1}{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XX2tf24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver a la probabilidad anterior como la probabilidad de la **uni칩n de 2 sucesos independientes**. Cuando calculamos probabilidades de 2 o m치s eventos que ocurren o son estudiados en el mismo experimento se le llama **probabilidad conjunta**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora consideremos la siguiente pregunta, **쮺u치l es la probabilidad de que A caiga par, dado que cay칩 B en par**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso estamos condicionando el calculo de una probabilidad a que previamente ocurri칩 otro evento que nos interesa, es decir, en lugar de evaluar las probabilidades sobre todo nuestro espacio muestral $S$, estamos evaluando nuestras probabilidades en un \"sub-espacio muestral\" que solo abarca los eventos en los que ocurri칩 nuestro evento en B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma que nuestro espacio muestral pasa de 36 posibilidades a 18 (6 posibles eventos de A y 3 eventos de B donde son pares). Y ahora calculamos nuestra probabilidad de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A=\\text{par}|B=\\text{par}) = \\frac{9}{18} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/xsCliKI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos relacionar estos 2 resultados aparentemente distintos de la siguiente forma. Recordemos que ya calculamos la probabilidad de que ambos resultados sean par y la probabilidad de que un dado sea par dado que el otro tambi칠n es par.\n",
    "\n",
    "Ahora vamos a preguntarnos. **쮺u치l es la probabilidad de que B sea par?** De nuevo es una probabilidad independiente de lo que ocurre en A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(B) = \\frac{18}{36} = \\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que si nos damos cuenta, la probabilidad de dicho evento es la suma de nuestras columnas amarillas de la imagen de arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y pongamos atenci칩n en que pasa al multiplicar nuestra $P(B) \\cdot P(A|B)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(B) \\cdot P(A|B) = \\frac{18}{36} \\cdot \\frac{9}{18} = \\frac{9}{36} = \\frac{1}{4} = P(\\text{par}, \\text{par})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es decir, al multiplicar la probabilidad de nuestro evento B por la probabilidad de nuestro evento A dado B, obtenemos la **probabilidad conjunta**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, esto anterior no es un caso particular sino que se le conoce como la **regla del producto** que dice lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A,B) = P(A|B)P(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o escrita de una forma en la que no la vamos a encontrar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(A|B) = \\frac{P(A \\cap B)}{P(B)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hablemos sobre la **probabilidad marginal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con probabilidad marginal nos referimos a cuando obtenemos una probabilidad \"sencilla\" a partir de una probabilidad conjunta. Es decir, la probabilidad de un evento simple que es independiente al resto de eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y se expresa de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p_x(x) = \\sum_{y}{P(x,y)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad marginal de $x$ es la suma de todas las probabilidades conjuntas sobre los dem치s estados que no consideran a $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir c칤clicamente a la probabilidad marginal a partir de la conjunta y la condicional o a la condicional en t칠rminos de la conjunta y la marginal, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de c치lculo de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlaciones de eventos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados los siguientes 3 eventos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A = {el resultado de lanzar un dado es 4}\n",
    "* B = {el resultado de lanzar un dado es par}\n",
    "* C = {el resultado de lanzar un dado es impar}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos **cual es la probabilidad de que ocurra A**:\n",
    "\n",
    "$$P(A) = \\frac{1}{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la **probabilidad de A dado que ocurri칩 B**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B) = \\frac{1}{3} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entre 3 ya que el evento B reduce el espacio a 3 eventos posibles donde es par, mientras que el evento A solo forma parte de 1 solo de esos eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, calculemos la **probabilidad de A dado C**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C reduce nuestro espacio a los casos donde sale {1, 3, 5}, pero A es el evento {4}. Por lo que tenemos eventos excluyentes y se interseccionan en el vac칤o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos decir que A y C est치n negativamente coorelacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|C) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una probabilidad igual a 0 dice que los eventos son **excluyentes**, pero NO nos est치 diciendo que sean **independientes**. De hecho, como vimos en el caso anterior, son altamente dependientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{excluyente} \\not= \\text{independiente}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para el siguiente ejemplo consideremos un juego de ruleta de casino que puede tomar 8 valores y donde tenemos a los siguientes 2 jugadores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/2c2ZYR7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, los eventos donde ganar el jugador 1 y donde gana el jugador 2 son **mutuamente excluyentes**, es decir, si gana uno el otro pierde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos preguntarnos, 쮺u치l es la probabilidad de que gane el jugador 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(W_1) = \\frac{4}{8} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o, 쮺u치l es la probabilidad de que gane 1 sabiendo que gan칩 2 (dado que ocurrieron eventos de el conjunto B)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(W_1 | B) = \\frac{0}{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para ponerlo un poquito m치s interesante el jugador 2 cambia su conjunto B por el conjunto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$C = {4,5,6,7}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y repetimos la misma pregunta, 쮺u치l es la probabilidad de que gane 1 dado que ocurrieron eventos del conjunto C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que C reduce nuestro espacio muestral a 4 posibles eventos {4,5,6,7} y de esos eventos A solo contiene a {4}, por lo que podemos deducirlo r치pidamente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(W_1|C)= \\frac{1}{4}= 25\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debido a que, sabiendo que el jugador 2 gan칩 podemos encontrar una menor posibilidad de que el jugador 1 haya ganado decimos que estos eventos est치n **negativamente relacionados**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el jugador 1 mantiene su conjunto de eventos $\\{1,2,3,4\\}$ y el jugador 2 cambia su conjunto a $\\{2,3,6,7\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쮺u치l es la probabilidad de que gane el jugador 1 sabiendo que gan칩 el jugador 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B) = \\frac{2}{4} = 50\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paradoja 쯡i침o o ni침a?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos las siguientes frases:\n",
    "\n",
    "* Una mujer tiene 2 beb칠s donde el mayor es un var칩n.\n",
    "* Una mujer tiene 2 beb칠s donde uno de ellos es var칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de que parece el mismo enunciado o que se refiere a lo mismo, contiene una peque침a diferencia gramatical que nos brinda informaci칩n adicional. De forma que al realizar el calculo de las probabilidades tendremos una diferencia al realizar el conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a empezar con la siguiente pregunta, **쮺u치l es la probabilidad de que esta mujer tenga 2 hijos varones?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un inicio, sin tener en cuenta factores externos, tenemos un 50% de probabilidad de que nazca un ni침o y 50% de que nazca una ni침a en cada nacimiento. Por lo que podemos expresar al nacimiento de 2 ni침os de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{v,v})= \\frac{1}{2} \\cdot \\frac{1}{2}= \\frac{1}{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, volviendo a nuestro ejemplo donde una sola mujer tiene 2 beb칠s podemos tener el siguiente espacio muestral:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/vDU7yiI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando consideramos el **primer enunciado**, es decir, cuando **el mayor es var칩n**, reducimos nuestro espacio muestral al siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/TvrTPAj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que la probabilidad de que el siguiente tambi칠n sea var칩n es de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{v,v}) = P(\\text{v}|M_\\text{varon})= \\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver que pasa en el **segundo enunciado**, donde **uno de ellos** es var칩n. En ese caso nuestro espacio se restringe al siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/8b6OCsY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que nuestra probabilidad de que uno de ellos sea var칩n es de:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(v,v) = \\frac{1}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El problema de Monthy Hall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema sali칩 de un show de TV donde se ten칤a a un participante que tenia en frente 3 puertas y una de ellas conten칤a un premio. Entonces, el participante ten칤a que elegir una puerta cualquiera tratando de atinarle a la puerta correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/YZ5DLIy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que inicialmente ten칤a una probabilidad de $\\frac{1}{3}$ de atinarle a la puerta correcta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La din치mica del programa consist칤a en que primero el participante seleccionaba una puerta y antes de que supiera si el premio estaba ah칤 o no, llegaba el presentador y abr칤a otra puerta donde no estaba el premio, de forma que el participante se quedaba con 2 opciones, pod칤a mantener su elecci칩n o hacer un cambio hac칤a la puerta restante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitivamente podr칤amos caer en el pensamiento de decir, \"tengo 2 puertas y en 1 de ellas est치 el premio, por lo que realice o no el cambio de puerta sigo teniendo la misma probabilidad del 50% de atinarle a la correcta\".\n",
    "\n",
    "Y justo aqu칤 es donde est치 la paradoja por qu칠 resulta que no funciona as칤. Veamos por qu칠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad, la confusi칩n viene al tratar el problema como si pasaramos a tener un nuevo espacio muestral donde ahora solo tenemos 2 puertas y regresamos a un $50\\%$ de probabilidad de atinarle. La realidad es que seguimos teniendo nuestro espacio de 3 puertas, pero ahora con informaci칩n extra. Vamos a ver los casos posibles que tenemos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/Amyh17E.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a verlo desde otra perspectiva, 쯖u치l es la probabilidad de que nosotros hayamos elegido una puerta incorrecta? Esta probabilidad ser칤a de $\\frac{2}{3} \\approx 0.66$. Entonces, es mucho m치s probable que nosotros hayamos elegido una puerta incorrecta, 쯡o?\n",
    "\n",
    "As칤 que, como tambi칠n sabemos, el presentador siempre abrir치 una puerta que tambi칠n es la incorrecta por lo que en 2 de 3 posibles casos vamos a dar con la puerta correcta al hacer el cambio, es decir, escogemos una incorrecta y el presentador abre la incorrecta y por lo tanto, al hacer el cambio damos con el premio. Por el otro lado, solo hay 1 caso de 3 en donde al hacer el cambio pasamos de la puerta correcta a la incorrecta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "P(\\text{win}|\\text{stay}) = \\frac{1}{3} \\\\\n",
    "P(\\text{win}|\\text{switch}) = \\frac{2}{3}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluimos que tenemos m치s probabilidad de ganar si hacemos el cambio de puerta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a incorporar un poco de c치lculo en Probabilidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenido 游눞",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.273px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
