{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos 游눞<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-para-data-scientist-avanzado\" data-toc-modified-id=\"Python-para-data-scientist-avanzado-1\">Python para data scientist avanzado</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Machine-Learning:-Modelaci칩n-avanzada\" data-toc-modified-id=\"1.-Machine-Learning:-Modelaci칩n-avanzada-1.1\">1. Machine Learning: Modelaci칩n avanzada</a></span><ul class=\"toc-item\"><li><span><a href=\"#Validaci칩n-interna-y-externa\" data-toc-modified-id=\"Validaci칩n-interna-y-externa-1.1.1\">Validaci칩n interna y externa</a></span></li><li><span><a href=\"#Validaci칩n-Externa-en-Python\" data-toc-modified-id=\"Validaci칩n-Externa-en-Python-1.1.2\">Validaci칩n Externa en Python</a></span></li><li><span><a href=\"#쯈u칠-es-y-c칩mo-act칰a-el-K-Fold?\" data-toc-modified-id=\"쯈u칠-es-y-c칩mo-act칰a-el-K-Fold?-1.1.3\">쯈u칠 es y c칩mo act칰a el K-Fold?</a></span></li><li><span><a href=\"#Leave-One-Out\" data-toc-modified-id=\"Leave-One-Out-1.1.4\">Leave One Out</a></span></li><li><span><a href=\"#Redes-neuronales\" data-toc-modified-id=\"Redes-neuronales-1.1.5\">Redes neuronales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conceptos\" data-toc-modified-id=\"Conceptos-1.1.5.1\">Conceptos</a></span></li><li><span><a href=\"#Ventajas\" data-toc-modified-id=\"Ventajas-1.1.5.2\">Ventajas</a></span></li><li><span><a href=\"#Desventajas\" data-toc-modified-id=\"Desventajas-1.1.5.3\">Desventajas</a></span></li></ul></li><li><span><a href=\"#Redes-neuronales-en-c칩digo\" data-toc-modified-id=\"Redes-neuronales-en-c칩digo-1.1.6\">Redes neuronales en c칩digo</a></span></li><li><span><a href=\"#XGboost-y-los-치rboles-de-decisi칩n\" data-toc-modified-id=\"XGboost-y-los-치rboles-de-decisi칩n-1.1.7\">XGboost y los 치rboles de decisi칩n</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python para data scientist avanzado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Machine Learning: Modelaci칩n avanzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validaci칩n interna y externa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, hablemos sobre la validaci칩n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Uso inteligente de los datos disponibles:** Es decir, no utilizar todos los datos de golpe y en lugar de ello, pensar en para qu칠 los queremos utilizar y c칩mo podr칤amos interpretarlos en dicho caso tambi칠n teniendo en cuenta el modelo que vamos a utilizar. Cuando utilizamos todos los datos para entrenar y evaluar al modelo estaremos en el caso de **validaci칩n interna** mientras que por el otro lado, cuando utilizamos s칩lo unos cu치ntos datos para entrenar y unos cu치ntos para evaluar entonces estamos en el caso de **validaci칩n externa**.\n",
    "\n",
    "* **M치s all치 de $R^2$ y el overfittin:** Es muy t칤pico simplemente, querer maximizar el $R^2$ (coeficiente de determinaci칩n) de nuestros modelos utilizando todos nuestros datos. En casos particulares c칩mo en las *ciencias sociales* s칤 que nos interesar칤a encontrar el modelo con el $R^2$ m치s alto posible, olvidandonos totalmente del posible **overfitting**, pero en otro tipo de casos donde queremos *generalizar* el aprendizaje deber칤amos de tener m치s cuidado con ello.\n",
    "\n",
    "* **Train / Test:** Es muy com칰n partir nuestro conjunto de *datos en datos de entrenamiento* y *datos de pruebas*, normalmente los primeros ocupan un 80% de nuestro conjunto total y utilizamos el 20% restante para validar que tan bueno es nuestro modelo al realizar predicciones.\n",
    "\n",
    "* **Tiempo y potencial computacional:** Hay que tener en cuenta que esto suele llevar m치s tiempo y recursos, ya que podr칤amos requerir de varios procesos de entrenamientos a la vez que requerir칤amos ir evaluando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos una comparativa entre *validaci칩n interna* y *validaci칩n externa*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/DCE8egK.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, cuando nos referimos a la validaci칩n externa tambi칠n hablamos de **validaci칩n cruzada**. Es decir, partir de una serie de bloque en donde entrenamos nuestro modelo y utilizamos el 칰ltimo para evaluarlo, para obtener un valor de $R^2$ y \"retroalimentar\" o volver a empezar.\n",
    "\n",
    "Pongamos un ejemplo para que sea m치s claro, supongamos que tenemos datos divididos en los siguientes 4 bloques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XP7Bcw9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podr칤amos comenzar por ejemplo, utilizando los bloques 1,2 y 3 para entrenar nuestro modelo y despu칠s testear con el bloque 4, recolectamos nuestro $R^2$ volvemos a empezar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/fm5mF8O.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, partiendo de nuestro valor obtenido $R^2$ repetimos el proceso, pero cambiando de bloques. Digamos que ahora utilizaremos los bloques 1,2,4 para entrenar y el bloque 3 para testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/ufenaR5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y as칤 podr칤amos continuar las veces que consideremos necesarias o hasta que utilicemos todas las combinaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre los tipos de validaci칩n m치s utilizados en ML tenemos las siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Interna:** Utilizar **todos los datos** para todo.\n",
    "\n",
    "* **Externa aleatoria:** Partir la base de datos en *train/test* **al azar** y posteriormente, evaluar nuestro modelo.\n",
    "\n",
    "* **Externa k-fold:** Partir la base de datos en *train/test* al azar y posteriormente, evaluar nuestro modelo. Esto realizado **m칰ltiples veces** (c칩mo en las im치genes de arriba).\n",
    "\n",
    "* **Leave One Out:** Similar a k-fold, pero aqu칤 **dejamos \"fuera\" del proceso a uno de nuestros puntos o bloques**. Y hacemos esto para todos los puntos de la base de datos. Esto es muy costoso, pero nos permite obtener una estimaci칩n muy precisa de que tan bien funciona nuestro modelo.\n",
    "\n",
    "* **Bootstrap:** Nos permite **obtener estimadores**. Llendo un poco m치s all치 de los test cl치sicos, bas치ndonos en un **re-muestreo con reemplazamiento**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validaci칩n Externa en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre que empezamos un proyecto de ML basado en la modelizaci칩n de datos una de las primeras cosas en las que tenemos que pensar es en **c칩mo validar nuestros datos**. Para realizar esto utilizaremos la funci칩n `train_test_split` incluida en ScikitLearn. Ya conocemos esta funcionalidad en el notebook de [Fundamentos Pr치cticos de ML](https://github.com/abdielgv162/Data-Science-Machine-Learning-Notes/blob/master/Fundamentos_Practicos_de_Machine_Learning/Fundamentos_Practicos_de_Machine_Learning.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a cargar nuestros datos que descargamos de [Kaggle](https://www.kaggle.com/vikalpdongre/us-flights-data-2008?select=2008.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar nuestros datos con un DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.DataFrame(data)\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = DF.keys()\n",
    "print(sorted(keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizamos `dropna` para eliminar los valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta ser치 nuestra \"variable respuesta\"\n",
    "df = data.dropna(subset=[\"ArrDelay\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a quedarnos solamente con 1000 filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a escoger 3 \"variables regresoras\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
    "print(X.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y nuestra variable respuesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['ArrDelay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a dividir nuestros datos en **datos de entrenamiento** y **datos de pruebas**. Para ello utilizaremos la instrucci칩n ` train_test_split()` y c칩mo argumentos le pasaremos a nuestras variables `X`, `Y` de arriba y la porci칩n de los datos destinada al testeo, en este caso el 20%. El argumento `random_state` controlamos la selecci칩n aleatoria de los datos antes de la partici칩n :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se suele utilizar may칰scula en la $X$ ya que son valores que permanecen fijos (constante) y min칰scula en la $y$ ya que es nuestra variable a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear 2 modelos de regresi칩n lineal para estudiar un tipo de validaci칩n Interno y otro Externo. Hagamos primero la Interna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrInterna = linear_model.LinearRegression() # Establecemos el modelo a usar\n",
    "regrInterna.fit(X, Y) # Entrenamos utilizando TODOS los datos\n",
    "prediccionesInterna = regrInterna.predict(X) # Devuelve las predicciones seg칰n todo X\n",
    "print(\"R2:\", r2_score(Y, prediccionesInterna)) # Devuelve R2 comparando los valores con la predicci칩n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hagamos la Externa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrExterna = linear_model.LinearRegression() \n",
    "regrExterna.fit(X_train, y_train) # Esntrenamos con los DATOS DE ENTRENAMIENTO\n",
    "prediccionesExterna = regrExterna.predict(X_test) # Realiza predicciones de los valores de testing\n",
    "print(\"R2: \", r2_score(y_test, prediccionesExterna)) # Devuelve R2 seg칰n las predicciones del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que si bien, tenemos un \"mejor resultado\" en la **validaci칩n interna** tambi칠n tenemos un overfitting m치s alto, ya que estamos prediciendo los datos con los que lo entrenamos. Mientras que en el caso de la **validaci칩n externa** tenemos un valor de $R^2$ m치s peque침o, pero a la vez tenemos una \"generalizaci칩n\" m치s vers치til de nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 쯈u칠 es y c칩mo act칰a el K-Fold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, la validaci칩n externa es una buena manera de evaluar que tan bueno es nuestro modelo, pero en muchos casos es dependiente de qu칠 selecci칩n concreta hayamos hecho en el conjunto `X_train` y `X_test`. Esto implica que, dependiendo que datos \"caigan\" en un grupo u otro; por lo que no siempre estaremos tan seguros de que tan buena haya sido la selecci칩n.\n",
    "\n",
    "Aqu칤 propondremos utilizar **K-Fold**, el cu치l pr치cticamente realizar치 el mismo procedimiento de ` train_test_split` **m칰ltiples veces**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna(subset=[\"ArrDelay\"])\n",
    "df = df.sample(frac=1).head(5000)\n",
    "\n",
    "# Es importante resetear el 칤ndice de los datos cuando hacemos\n",
    "# selecciones aleatorias\n",
    "df = df.reset_index()\n",
    "\n",
    "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
    "y = df['ArrDelay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sintaxis es muy similar a la que utilizamos en el caso anterior. KFold nos permite elegir cu치ntas particiones queremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqu칤 se vuelve importante tener los indices reseteados\n",
    "kf = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las particiones de nuestras variables X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos una regresi칩n lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "# Por cada vez que repitamos la partici칩n\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    # Localizamos los datos que vamos a colocar en cada partici칩n\n",
    "    X_train, X_test = X.loc[train_index], X.iloc[test_index,]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #Entrenamos\n",
    "    reg.fit(X_train, y_train)\n",
    "    # Testeamos\n",
    "    predictions = reg.predict(X_test)\n",
    "    print(\"R2: \", r2_score(y_test, predictions))\n",
    "    \n",
    "    # Guardamos\n",
    "    results.append(r2_score(y_test, predictions))\n",
    "    \n",
    "print(\"R2 promedio\", np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu칤 es m치s claro visualizar c칩mo dependiendo de la selecci칩n de nuestros datos de entrenamiento tendremos mejores o peores predicciones. En este caso con KFold tenemos el promedio de todos estos, manteniendo un valor de $R^2$ m치s alto que con el split anterior. \n",
    "\n",
    "Utilizar el promedio nos ayuda a compensar la dependencia de datos concretos, este es un tipo de validaci칩n m치s representativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hablar de otra forma de validaci칩n que si bien es m치s costosa computacionalmente (y en tiempo), es un tanto divertida e interesante. Lo que haremos ser치 entrenar al modelo con todos los datos excepto 1, es decir, en nuestra l칤nea de c칩digo `test_size` tendr칤amos $\\frac{1}{n}$. La particularidad de este proceso es que lo repetimos $n$ veces, de ah칤 la raz칩n por la que sea tan costoso, pero es muy buena opci칩n en caso de tener muestras muy peque침as de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna(subset = [\"ArrDelay\"])\n",
    "df = df.sample(frac=1).head(5000)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
    "y = df['ArrDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "error_vector = []\n",
    "for train_index, test_index in loo.split(X):\n",
    "    \n",
    "    X_train, X_test = X.loc[train_index,], X.loc[test_index,]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    reg.fit(X_train, y_train)\n",
    "    predictions = reg.predict(X_test)\n",
    "    \n",
    "    error_vector.append( int((y_test - predictions[0])**2 ) ) \n",
    "    print('Error Cuadratico: ', ( (y_test - predictions[0])**2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales son uno de los modelos m치s populares hoy en d칤a, su funcionamiento se basa en tratar de replicar los procesos cognitivos de un cerebro humano; partiendo desde conceptos como neuronas artificiales, funciones de activaci칩n hasta tener redes s칰per complejas cada vez m치s profundas. Son muy costosas computacionalmente, pero tambi칠n son muy buenas al aproximar todo tipo de estructuras internas dentro de nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/p6d6Fjw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la imagen de arriba cada bolita representa una neurona y tenemos dividido al modelo en distintas capas. En nuestra primera capa tenemos nuestros inputs (datos), o variables regresoras. Despu칠s, tenemos capas ocultas que representan ***combinaciones lineales** o pesos de los inputs y de otras capas oculats. Finalmente, tenemos nuestros valores de salida o outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conceptos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Neuronas:** Son cada uno de los elementos individuales informativos que generamos al intentar relacionar y explicar nuestros outputs a trav칠s de nuestros inputs.\n",
    "* **Enlaces:** Son las combinaciones lineales entre los elementos de la red.\n",
    "* **Funci칩n de p칠rdida:** Funci칩n matem치tica que relaciona un evento o tarea con un n칰mero que representa el coste de realizarla.\n",
    "* **Aprendizaje autom치tico:** Cuando desarrollamos algoritmos y modelos que pueden \"aprender\" a realizar una tarea sin necesidad de ser impl칤citamente programados para ello. En general, se basan en iterar distintos procesos hasta minimizar una funci칩n de p칠rdida.\n",
    "* **Funci칩n de activaci칩n:** Funci칩n matem치tica que describe c칩mo se \"encienden\" o activan nuestras neuronas o elementos de nuestra red.\n",
    "* **Tipo de aprendizaje:** Supervisado, no supervisado o reforzado.\n",
    "* **Coste:** Coste computacional en funci칩n de la cantidad de datos y la profundidad o cantidad de capas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventajas         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Adaptativas:** Funcionan para todo tipo de distribuci칩n de datos, lineales o no lineales.\n",
    "* **Paralelizables:** Podemos distribuir el c치lculo en distintos computadores o servidores.\n",
    "* **Tolerancia a fallos**: Si alguna parte del modelo falla o pierde algo de informaci칩n, podemos repararlo sin haber perdido todo lo que hemos hecho.\n",
    "* **Potencial predictivo:** Son muy buenas generalizando los patrones en los, siempre y cuando est칠n bien calibradas y construidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Coste computacional**: Por lo mismo de la profundidad a la que pueden llegar, requieren de gran poder de c칩mputo.\n",
    "* **Cajas negras:** En realidad no sabemos exactamente que es lo que pasa dentro del modelo, solo podemos entenderlo al nivel de sus capas m치s simples, el resto es gracias a la conexi칩n y trabajo conjunto de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes neuronales en c칩digo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar ScikitLearn para ver c칩mo podr칤amos ajustar redes neuronales. Utilizamos `MLPClassifier` al trabajar con datos categ칩ricos y `MLPRegressor` con datos num칠ricos; despu칠s importamos a `StandardScaler` escalar nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Validaci칩n externa\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna(subset = ['AirTime','Distance','TaxiIn', 'TaxiOut', 'DepDelay'])\n",
    "df = df.sample(frac=1).head(1000)\n",
    "\n",
    "\n",
    "X = df[['AirTime','Distance','TaxiIn', 'TaxiOut', 'DepDelay']]\n",
    "Y = df['ArrDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dividir los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que tenemos datos que miden cosas distintas, algunas columnas miden tiempo, otras distancia, etc. As칤 que vamos a estandarizar nuestros valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hace es estandarizar las caracter칤sticas eliminando la media y escalando a la varianza de la unidad. La puntuaci칩n est치ndar de una muestra $x$ se calcula c칩mo:\n",
    "\n",
    "$$ z = \\frac{(x-u)}{s}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $u$ es la media de nuestras muestras, $s$ es la desviaci칩n est치ndar de las muestras y $x$ nuestras muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a ajustar a la red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, ))\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print('R2: ', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos un $R^2$ muy alto, pero recordemos que tenemos la variable ` 'DepDelay'` tanto en $X$ c칩mo en $Y$, por lo que esperar칤amos que est칠n muy correlacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay algunos par치metros que podemos modificar para adaptar este tipo de modelos:\n",
    "\n",
    "* **`solver`:** Indica a nuestra funci칩n c칩mo resolver el problema de optimizaci칩n.\n",
    "    * `lbfgs`: es un optimizador de la familia de m칠todos cuasi-Newton.\n",
    "    * `sgd`: se refiere a un descenso del gradiente estoc치stico.\n",
    "    * `adam`:  se refiere a un optimizador estoc치stico basado en gradientes propuesto por Kingma, Diederik y Jimmy Ba.\n",
    "\n",
    "\n",
    "* **`alpha`:** Penalizaci칩n a la complejidad del modelo, nos ayuda a controlar el **overfitting**.\n",
    "\n",
    "\n",
    "* **`hidden_layer_sizes`:** N칰mero de capas ocultas en las que trabajamos, esto depende much칤simo de los datos que estemos utilizando. NO siempre es mejor tener m치s capas.\n",
    "    * Primero recibe el n칰mero de capas.\n",
    "    * Despu칠s de la coma recibe el n칰mero de neuronas (generalmente se mantiene vac칤o).\n",
    "\n",
    "\n",
    "* **`activation`:** Indica cu치l es la funci칩n de activaci칩n que utilizaremos.\n",
    "    * `identity`: activaci칩n sin operaci칩n, 칰til para implementar cuellos de botella lineales, devuelve $f(x) = x$.\n",
    "\n",
    "    * `logistic`: la funci칩n sigmoidea log칤stica, devuelve $f (x) =\\frac{1}{ (1 + exp (-x))}$.\n",
    "\n",
    "    * `tanh`:  la funci칩n tan hiperb칩lica, devuelve $f (x) = tanh (x)$.\n",
    "\n",
    "    * `relu`: la funci칩n de unidad lineal rectificada, devuelve $f (x) = max (0, x)$.\n",
    "    \n",
    "    \n",
    "* **`learning_rate`**: Velocidad de aprendizaje de nuestra red. \n",
    "    * `constant`: es una tasa de aprendizaje constante dada por `learning_rate_init`. Este es el valor predeterminado.\n",
    "    * `invscaling`: disminuye gradualmente la tasa de aprendizaje `learning_rate_` en cada paso de tiempo $t$ utilizando un exponente de escala inversa de `power_t` . `effective_learning_rate = learning_rate_init / pow(t, power_t)`.\n",
    "    * `adaptive`: mantiene la tasa de aprendizaje constante en `learning_rate_init` siempre que la p칠rdida de entrenamiento siga disminuyendo.\n",
    "    \n",
    "\n",
    "* `max_iter`: N칰mero m치ximo de iteraciones.\n",
    "\n",
    "\n",
    "* `warm_start`: El modelo comienza desde la soluci칩n de la 칰ltima vez que la hemos ejecutado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost y los 치rboles de decisi칩n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost es una \"evoluci칩n\" de los 치rboles de clasificaci칩n. Se podr칤a decir que estamos mezclando varios 치rboles y evaluando que tan bueno es el modelo. \n",
    "\n",
    "El elemento clave de esto es nuestra funci칩n de p칠rdida, com칰nmente utilizando la media de los errores al cuadrado junto con una **penalizaci칩n de complejidad**, es decir, vamos a penalizar los modelos que sean muy complejos; esto 칰ltimo es lo que nos permite evitar el **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/cart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a diferencia de los 치rboles normales, en este caso asigna **valores reales** a nuestros posibles eventos, de manera que podr칤amos generar una m칠trica que vamos a poder a침adir a nuevos 치rboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/twocart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de forma que la predicci칩n de nuestros eventos estar치 en funci칩n de los distintos 치rboles que utilicemos. De forma que al final obtenemos una estructura como la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/struct_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estar칤amos **acumulando los valores** de nuestros eventos o en este caso, de nuestros individuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Documentaci칩n de XGboost ](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de Contenidos 游눞",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
