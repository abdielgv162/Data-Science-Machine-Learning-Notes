{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Tabla de Contenidos 游눞",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Python_para_Data_Scientist_Avanzado.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "kvzP1zUemWHl"
      },
      "source": [
        "<h1>Tabla de Contenidos 游눞<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-para-data-scientist-avanzado\" data-toc-modified-id=\"Python-para-data-scientist-avanzado-1\">Python para data scientist avanzado</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Machine-Learning:-Modelaci칩n-avanzada\" data-toc-modified-id=\"1.-Machine-Learning:-Modelaci칩n-avanzada-1.1\">1. Machine Learning: Modelaci칩n avanzada</a></span><ul class=\"toc-item\"><li><span><a href=\"#Validaci칩n-interna-y-externa\" data-toc-modified-id=\"Validaci칩n-interna-y-externa-1.1.1\">Validaci칩n interna y externa</a></span></li><li><span><a href=\"#Validaci칩n-Externa-en-Python\" data-toc-modified-id=\"Validaci칩n-Externa-en-Python-1.1.2\">Validaci칩n Externa en Python</a></span></li><li><span><a href=\"#쯈u칠-es-y-c칩mo-act칰a-el-K-Fold?\" data-toc-modified-id=\"쯈u칠-es-y-c칩mo-act칰a-el-K-Fold?-1.1.3\">쯈u칠 es y c칩mo act칰a el K-Fold?</a></span></li><li><span><a href=\"#Leave-One-Out\" data-toc-modified-id=\"Leave-One-Out-1.1.4\">Leave One Out</a></span></li><li><span><a href=\"#Redes-neuronales\" data-toc-modified-id=\"Redes-neuronales-1.1.5\">Redes neuronales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conceptos\" data-toc-modified-id=\"Conceptos-1.1.5.1\">Conceptos</a></span></li><li><span><a href=\"#Ventajas\" data-toc-modified-id=\"Ventajas-1.1.5.2\">Ventajas</a></span></li><li><span><a href=\"#Desventajas\" data-toc-modified-id=\"Desventajas-1.1.5.3\">Desventajas</a></span></li></ul></li><li><span><a href=\"#Redes-neuronales-en-c칩digo\" data-toc-modified-id=\"Redes-neuronales-en-c칩digo-1.1.6\">Redes neuronales en c칩digo</a></span></li><li><span><a href=\"#XGboost-y-los-치rboles-de-decisi칩n\" data-toc-modified-id=\"XGboost-y-los-치rboles-de-decisi칩n-1.1.7\">XGboost y los 치rboles de decisi칩n</a></span></li></ul></li></ul></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtpkHaJnmWHm"
      },
      "source": [
        "# Python para data scientist avanzado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQFEZMRfmWHn"
      },
      "source": [
        "## 1. Machine Learning: Modelaci칩n avanzada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3XBINu6mWHn"
      },
      "source": [
        "### Validaci칩n interna y externa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k97CBSzamWHo"
      },
      "source": [
        "Primero, hablemos sobre la validaci칩n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyLAx5wemWHo"
      },
      "source": [
        "* **Uso inteligente de los datos disponibles:** Es decir, no utilizar todos los datos de golpe y en lugar de ello, pensar en para qu칠 los queremos utilizar y c칩mo podr칤amos interpretarlos en dicho caso tambi칠n teniendo en cuenta el modelo que vamos a utilizar. Cuando utilizamos todos los datos para entrenar y evaluar al modelo estaremos en el caso de **validaci칩n interna** mientras que por el otro lado, cuando utilizamos s칩lo unos cu치ntos datos para entrenar y unos cu치ntos para evaluar entonces estamos en el caso de **validaci칩n externa**.\n",
        "\n",
        "* **M치s all치 de $R^2$ y el overfittin:** Es muy t칤pico simplemente, querer maximizar el $R^2$ (coeficiente de determinaci칩n) de nuestros modelos utilizando todos nuestros datos. En casos particulares c칩mo en las *ciencias sociales* s칤 que nos interesar칤a encontrar el modelo con el $R^2$ m치s alto posible, olvidandonos totalmente del posible **overfitting**, pero en otro tipo de casos donde queremos *generalizar* el aprendizaje deber칤amos de tener m치s cuidado con ello.\n",
        "\n",
        "* **Train / Test:** Es muy com칰n partir nuestro conjunto de *datos en datos de entrenamiento* y *datos de pruebas*, normalmente los primeros ocupan un 80% de nuestro conjunto total y utilizamos el 20% restante para validar que tan bueno es nuestro modelo al realizar predicciones.\n",
        "\n",
        "* **Tiempo y potencial computacional:** Hay que tener en cuenta que esto suele llevar m치s tiempo y recursos, ya que podr칤amos requerir de varios procesos de entrenamientos a la vez que requerir칤amos ir evaluando."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXcGqTLYmWHo"
      },
      "source": [
        "Hagamos una comparativa entre *validaci칩n interna* y *validaci칩n externa*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kq89jZ6mWHp"
      },
      "source": [
        "![](https://i.imgur.com/DCE8egK.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrrjx63XmWHp"
      },
      "source": [
        "Normalmente, cuando nos referimos a la validaci칩n externa tambi칠n hablamos de **validaci칩n cruzada**. Es decir, partir de una serie de bloque en donde entrenamos nuestro modelo y utilizamos el 칰ltimo para evaluarlo, para obtener un valor de $R^2$ y \"retroalimentar\" o volver a empezar.\n",
        "\n",
        "Pongamos un ejemplo para que sea m치s claro, supongamos que tenemos datos divididos en los siguientes 4 bloques:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvt90n8mmWHp"
      },
      "source": [
        "![](https://i.imgur.com/XP7Bcw9.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGN-QlU_mWHq"
      },
      "source": [
        "Podr칤amos comenzar por ejemplo, utilizando los bloques 1,2 y 3 para entrenar nuestro modelo y despu칠s testear con el bloque 4, recolectamos nuestro $R^2$ volvemos a empezar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tTQHwN-mWHq"
      },
      "source": [
        "![](https://i.imgur.com/fm5mF8O.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgpRFRmPmWHq"
      },
      "source": [
        "Ahora, partiendo de nuestro valor obtenido $R^2$ repetimos el proceso, pero cambiando de bloques. Digamos que ahora utilizaremos los bloques 1,2,4 para entrenar y el bloque 3 para testeo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktpJn5iSmWHr"
      },
      "source": [
        "![](https://i.imgur.com/ufenaR5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A10yZd4mWHr"
      },
      "source": [
        "y as칤 podr칤amos continuar las veces que consideremos necesarias o hasta que utilicemos todas las combinaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu-5clfkmWHr"
      },
      "source": [
        "Entre los tipos de validaci칩n m치s utilizados en ML tenemos las siguientes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnRvnANSmWHr"
      },
      "source": [
        "* **Interna:** Utilizar **todos los datos** para todo.\n",
        "\n",
        "* **Externa aleatoria:** Partir la base de datos en *train/test* **al azar** y posteriormente, evaluar nuestro modelo.\n",
        "\n",
        "* **Externa k-fold:** Partir la base de datos en *train/test* al azar y posteriormente, evaluar nuestro modelo. Esto realizado **m칰ltiples veces** (c칩mo en las im치genes de arriba).\n",
        "\n",
        "* **Leave One Out:** Similar a k-fold, pero aqu칤 **dejamos \"fuera\" del proceso a uno de nuestros puntos o bloques**. Y hacemos esto para todos los puntos de la base de datos. Esto es muy costoso, pero nos permite obtener una estimaci칩n muy precisa de que tan bien funciona nuestro modelo.\n",
        "\n",
        "* **Bootstrap:** Nos permite **obtener estimadores**. Llendo un poco m치s all치 de los test cl치sicos, bas치ndonos en un **re-muestreo con reemplazamiento**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpC9NdL6mWHr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6KfZGjmmWHs"
      },
      "source": [
        "### Validaci칩n Externa en Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmfkt4vomWHs"
      },
      "source": [
        "Siempre que empezamos un proyecto de ML basado en la modelizaci칩n de datos una de las primeras cosas en las que tenemos que pensar es en **c칩mo validar nuestros datos**. Para realizar esto utilizaremos la funci칩n `train_test_split` incluida en ScikitLearn. Ya conocemos esta funcionalidad en el notebook de [Fundamentos Pr치cticos de ML](https://github.com/abdielgv162/Data-Science-Machine-Learning-Notes/blob/master/Fundamentos_Practicos_de_Machine_Learning/Fundamentos_Practicos_de_Machine_Learning.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTFn_3_tmWHs"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M4ifDawmWHs"
      },
      "source": [
        "Vamos a cargar nuestros datos que descargamos de [Kaggle](https://www.kaggle.com/vikalpdongre/us-flights-data-2008?select=2008.csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vZweSYZmWHt"
      },
      "source": [
        "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuMKF62XmWHt"
      },
      "source": [
        "Vamos a visualizar nuestros datos con un DF:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF5eYulemWHt"
      },
      "source": [
        "DF = pd.DataFrame(data)\n",
        "DF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84-xNNvVmWHt"
      },
      "source": [
        "keys = DF.keys()\n",
        "print(sorted(keys))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-k6ONN6mWHt"
      },
      "source": [
        "utilizamos `dropna` para eliminar los valores faltantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIfQu4qRmWHt"
      },
      "source": [
        "# Esta ser치 nuestra \"variable respuesta\"\n",
        "df = data.dropna(subset=[\"ArrDelay\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtoZdHvrmWHu"
      },
      "source": [
        "vamos a quedarnos solamente con 1000 filas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV5wsmsSmWHu"
      },
      "source": [
        "df = df.sample(frac=1).head(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsFKelVEmWHu"
      },
      "source": [
        "Vamos a escoger 3 \"variables regresoras\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3kMhVsvmWHu"
      },
      "source": [
        "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
        "print(X.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKznxLBgmWHu"
      },
      "source": [
        "y nuestra variable respuesta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiX0H6Z5mWHu"
      },
      "source": [
        "Y = df['ArrDelay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAT4PzPBmWHv"
      },
      "source": [
        "Ahora, vamos a dividir nuestros datos en **datos de entrenamiento** y **datos de pruebas**. Para ello utilizaremos la instrucci칩n ` train_test_split()` y c칩mo argumentos le pasaremos a nuestras variables `X`, `Y` de arriba y la porci칩n de los datos destinada al testeo, en este caso el 20%. El argumento `random_state` controlamos la selecci칩n aleatoria de los datos antes de la partici칩n :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5pfeK7_mWHv"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYPHqo4imWHv"
      },
      "source": [
        "> Se suele utilizar may칰scula en la $X$ ya que son valores que permanecen fijos (constante) y min칰scula en la $y$ ya que es nuestra variable a predecir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuWx2bK0mWHv"
      },
      "source": [
        "Vamos a crear 2 modelos de regresi칩n lineal para estudiar un tipo de validaci칩n Interno y otro Externo. Hagamos primero la Interna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1DQ0MOJmWHv"
      },
      "source": [
        "regrInterna = linear_model.LinearRegression() # Establecemos el modelo a usar\n",
        "regrInterna.fit(X, Y) # Entrenamos utilizando TODOS los datos\n",
        "prediccionesInterna = regrInterna.predict(X) # Devuelve las predicciones seg칰n todo X\n",
        "print(\"R2:\", r2_score(Y, prediccionesInterna)) # Devuelve R2 comparando los valores con la predicci칩n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL63yLI0mWHw"
      },
      "source": [
        "Ahora hagamos la Externa:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWPx8MpemWHw"
      },
      "source": [
        "regrExterna = linear_model.LinearRegression() \n",
        "regrExterna.fit(X_train, y_train) # Esntrenamos con los DATOS DE ENTRENAMIENTO\n",
        "prediccionesExterna = regrExterna.predict(X_test) # Realiza predicciones de los valores de testing\n",
        "print(\"R2: \", r2_score(y_test, prediccionesExterna)) # Devuelve R2 seg칰n las predicciones del test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7BD1CBZmWHw"
      },
      "source": [
        "Podemos ver que si bien, tenemos un \"mejor resultado\" en la **validaci칩n interna** tambi칠n tenemos un overfitting m치s alto, ya que estamos prediciendo los datos con los que lo entrenamos. Mientras que en el caso de la **validaci칩n externa** tenemos un valor de $R^2$ m치s peque침o, pero a la vez tenemos una \"generalizaci칩n\" m치s vers치til de nuestros datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71WXLNo0mWHx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruqdcxU6mWHx"
      },
      "source": [
        "### 쯈u칠 es y c칩mo act칰a el K-Fold?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nwo14f-mWHx"
      },
      "source": [
        "En general, la validaci칩n externa es una buena manera de evaluar que tan bueno es nuestro modelo, pero en muchos casos es dependiente de qu칠 selecci칩n concreta hayamos hecho en el conjunto `X_train` y `X_test`. Esto implica que, dependiendo que datos \"caigan\" en un grupo u otro; por lo que no siempre estaremos tan seguros de que tan buena haya sido la selecci칩n.\n",
        "\n",
        "Aqu칤 propondremos utilizar **K-Fold**, el cu치l pr치cticamente realizar치 el mismo procedimiento de ` train_test_split` **m칰ltiples veces**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIdD1o7wmWHy"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I72JNl5FmWHy"
      },
      "source": [
        "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVRhc5-wmWHz"
      },
      "source": [
        "df = data.dropna(subset=[\"ArrDelay\"])\n",
        "df = df.sample(frac=1).head(5000)\n",
        "\n",
        "# Es importante resetear el 칤ndice de los datos cuando hacemos\n",
        "# selecciones aleatorias\n",
        "df = df.reset_index()\n",
        "\n",
        "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
        "y = df['ArrDelay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud18GdjFmWHz"
      },
      "source": [
        "La sintaxis es muy similar a la que utilizamos en el caso anterior. KFold nos permite elegir cu치ntas particiones queremos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWHzBu2YmWHz"
      },
      "source": [
        "# Aqu칤 se vuelve importante tener los indices reseteados\n",
        "kf = KFold(n_splits=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFe33oQNmWHz"
      },
      "source": [
        "Obtenemos las particiones de nuestras variables X:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbZfMZ_NmWHz"
      },
      "source": [
        "kf.get_n_splits(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zj8Zh-7mWH0"
      },
      "source": [
        "Aplicamos una regresi칩n lineal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhpEXZk0mWH0"
      },
      "source": [
        "reg = linear_model.LinearRegression()\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "# Por cada vez que repitamos la partici칩n\n",
        "for train_index, test_index in kf.split(X):\n",
        "    \n",
        "    # Localizamos los datos que vamos a colocar en cada partici칩n\n",
        "    X_train, X_test = X.loc[train_index], X.iloc[test_index,]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "    #Entrenamos\n",
        "    reg.fit(X_train, y_train)\n",
        "    # Testeamos\n",
        "    predictions = reg.predict(X_test)\n",
        "    print(\"R2: \", r2_score(y_test, predictions))\n",
        "    \n",
        "    # Guardamos\n",
        "    results.append(r2_score(y_test, predictions))\n",
        "    \n",
        "print(\"R2 promedio\", np.mean(results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVQfYA8FmWH0"
      },
      "source": [
        "Aqu칤 es m치s claro visualizar c칩mo dependiendo de la selecci칩n de nuestros datos de entrenamiento tendremos mejores o peores predicciones. En este caso con KFold tenemos el promedio de todos estos, manteniendo un valor de $R^2$ m치s alto que con el split anterior. \n",
        "\n",
        "Utilizar el promedio nos ayuda a compensar la dependencia de datos concretos, este es un tipo de validaci칩n m치s representativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXby9o4rmWH0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7O_x91JmWH0"
      },
      "source": [
        "### Leave One Out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QC13nYDmWH1"
      },
      "source": [
        "Ahora vamos a hablar de otra forma de validaci칩n que si bien es m치s costosa computacionalmente (y en tiempo), es un tanto divertida e interesante. Lo que haremos ser치 entrenar al modelo con todos los datos excepto 1, es decir, en nuestra l칤nea de c칩digo `test_size` tendr칤amos $\\frac{1}{n}$. La particularidad de este proceso es que lo repetimos $n$ veces, de ah칤 la raz칩n por la que sea tan costoso, pero es muy buena opci칩n en caso de tener muestras muy peque침as de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_RQhVGGmWH1"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn import linear_model\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO_0rgtBmWH1"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z19ZXYD9mWH1"
      },
      "source": [
        "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUuZLu40mWH1"
      },
      "source": [
        "df = data.dropna(subset = [\"ArrDelay\"])\n",
        "df = df.sample(frac=1).head(5000)\n",
        "\n",
        "df = df.reset_index()\n",
        "\n",
        "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
        "y = df['ArrDelay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NMYPcILmWH1"
      },
      "source": [
        "loo = LeaveOneOut()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lttSn9yUmWH2"
      },
      "source": [
        "reg = linear_model.LinearRegression()\n",
        "error_vector = []\n",
        "for train_index, test_index in loo.split(X):\n",
        "    \n",
        "    X_train, X_test = X.loc[train_index,], X.loc[test_index,]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    reg.fit(X_train, y_train)\n",
        "    predictions = reg.predict(X_test)\n",
        "    \n",
        "    error_vector.append( int((y_test - predictions[0])**2 ) ) \n",
        "    print('Error Cuadratico: ', ( (y_test - predictions[0])**2 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_GWeYhamWH2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFYg_fnMmWH2"
      },
      "source": [
        "### Redes neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9fCTXZDmWH2"
      },
      "source": [
        "Las redes neuronales son uno de los modelos m치s populares hoy en d칤a, su funcionamiento se basa en tratar de replicar los procesos cognitivos de un cerebro humano; partiendo desde conceptos como neuronas artificiales, funciones de activaci칩n hasta tener redes s칰per complejas cada vez m치s profundas. Son muy costosas computacionalmente, pero tambi칠n son muy buenas al aproximar todo tipo de estructuras internas dentro de nuestros datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJlvdhxumWH3"
      },
      "source": [
        "![](https://i.imgur.com/p6d6Fjw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hcFZUEymWH3"
      },
      "source": [
        "En la imagen de arriba cada bolita representa una neurona y tenemos dividido al modelo en distintas capas. En nuestra primera capa tenemos nuestros inputs (datos), o variables regresoras. Despu칠s, tenemos capas ocultas que representan ***combinaciones lineales** o pesos de los inputs y de otras capas oculats. Finalmente, tenemos nuestros valores de salida o outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rW8nr0YmWH3"
      },
      "source": [
        "#### Conceptos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCKw6BfDmWH3"
      },
      "source": [
        "* **Neuronas:** Son cada uno de los elementos individuales informativos que generamos al intentar relacionar y explicar nuestros outputs a trav칠s de nuestros inputs.\n",
        "* **Enlaces:** Son las combinaciones lineales entre los elementos de la red.\n",
        "* **Funci칩n de p칠rdida:** Funci칩n matem치tica que relaciona un evento o tarea con un n칰mero que representa el coste de realizarla.\n",
        "* **Aprendizaje autom치tico:** Cuando desarrollamos algoritmos y modelos que pueden \"aprender\" a realizar una tarea sin necesidad de ser impl칤citamente programados para ello. En general, se basan en iterar distintos procesos hasta minimizar una funci칩n de p칠rdida.\n",
        "* **Funci칩n de activaci칩n:** Funci칩n matem치tica que describe c칩mo se \"encienden\" o activan nuestras neuronas o elementos de nuestra red.\n",
        "* **Tipo de aprendizaje:** Supervisado, no supervisado o reforzado.\n",
        "* **Coste:** Coste computacional en funci칩n de la cantidad de datos y la profundidad o cantidad de capas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t1QJP3PmWH3"
      },
      "source": [
        "#### Ventajas         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWYufFgemWH3"
      },
      "source": [
        "* **Adaptativas:** Funcionan para todo tipo de distribuci칩n de datos, lineales o no lineales.\n",
        "* **Paralelizables:** Podemos distribuir el c치lculo en distintos computadores o servidores.\n",
        "* **Tolerancia a fallos**: Si alguna parte del modelo falla o pierde algo de informaci칩n, podemos repararlo sin haber perdido todo lo que hemos hecho.\n",
        "* **Potencial predictivo:** Son muy buenas generalizando los patrones en los, siempre y cuando est칠n bien calibradas y construidas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AgDShkemWH4"
      },
      "source": [
        "#### Desventajas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5P-dDXgmWH4"
      },
      "source": [
        "* **Coste computacional**: Por lo mismo de la profundidad a la que pueden llegar, requieren de gran poder de c칩mputo.\n",
        "* **Cajas negras:** En realidad no sabemos exactamente que es lo que pasa dentro del modelo, solo podemos entenderlo al nivel de sus capas m치s simples, el resto es gracias a la conexi칩n y trabajo conjunto de ellas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9zBMnJvmWH4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnAkD0-VmWH4"
      },
      "source": [
        "### Redes neuronales en c칩digo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYgLg-mkmWH4"
      },
      "source": [
        "Vamos a utilizar ScikitLearn para ver c칩mo podr칤amos ajustar redes neuronales. Utilizamos `MLPClassifier` al trabajar con datos categ칩ricos y `MLPRegressor` con datos num칠ricos; despu칠s importamos a `StandardScaler` escalar nuestros datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FAjE62BmWH4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Validaci칩n externa\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTHGXPnLmWH4"
      },
      "source": [
        "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yNf5L2UmWH5"
      },
      "source": [
        "df = data.dropna(subset = ['AirTime','Distance','TaxiIn', 'TaxiOut', 'DepDelay'])\n",
        "df = df.sample(frac=1).head(1000)\n",
        "\n",
        "\n",
        "X = df[['AirTime','Distance','TaxiIn', 'TaxiOut', 'DepDelay']]\n",
        "Y = df['ArrDelay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nSzTd77mWH5"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TreL7aSKmWH5"
      },
      "source": [
        "Vamos a dividir los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwL9KSFZmWH5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reA7MF8KmWH5"
      },
      "source": [
        "Recordemos que tenemos datos que miden cosas distintas, algunas columnas miden tiempo, otras distancia, etc. As칤 que vamos a estandarizar nuestros valores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIcIK6crmWH5"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh4yAT_VmWH6"
      },
      "source": [
        "Lo que hace es estandarizar las caracter칤sticas eliminando la media y escalando a la varianza de la unidad. La puntuaci칩n est치ndar de una muestra $x$ se calcula c칩mo:\n",
        "\n",
        "$$ z = \\frac{(x-u)}{s}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBcjuOnGmWH6"
      },
      "source": [
        "donde $u$ es la media de nuestras muestras, $s$ es la desviaci칩n est치ndar de las muestras y $x$ nuestras muestras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiGOqoBTmWH6"
      },
      "source": [
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGpJJOxqmWH6"
      },
      "source": [
        "Ahora, vamos a ajustar a la red neuronal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X8XzIzKmWH6"
      },
      "source": [
        "clf = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, ))\n",
        "\n",
        "model = clf.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print('R2: ', r2_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN8zLgLbmWH6"
      },
      "source": [
        "Podemos ver que tenemos un $R^2$ muy alto, pero recordemos que tenemos la variable ` 'DepDelay'` tanto en $X$ c칩mo en $Y$, por lo que esperar칤amos que est칠n muy correlacionados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdRiDolgmWH7"
      },
      "source": [
        "Hay algunos par치metros que podemos modificar para adaptar este tipo de modelos:\n",
        "\n",
        "* **`solver`:** Indica a nuestra funci칩n c칩mo resolver el problema de optimizaci칩n.\n",
        "    * `lbfgs`: es un optimizador de la familia de m칠todos cuasi-Newton.\n",
        "    * `sgd`: se refiere a un descenso del gradiente estoc치stico.\n",
        "    * `adam`:  se refiere a un optimizador estoc치stico basado en gradientes propuesto por Kingma, Diederik y Jimmy Ba.\n",
        "\n",
        "\n",
        "* **`alpha`:** Penalizaci칩n a la complejidad del modelo, nos ayuda a controlar el **overfitting**.\n",
        "\n",
        "\n",
        "* **`hidden_layer_sizes`:** N칰mero de capas ocultas en las que trabajamos, esto depende much칤simo de los datos que estemos utilizando. NO siempre es mejor tener m치s capas.\n",
        "    * Primero recibe el n칰mero de capas.\n",
        "    * Despu칠s de la coma recibe el n칰mero de neuronas (generalmente se mantiene vac칤o).\n",
        "\n",
        "\n",
        "* **`activation`:** Indica cu치l es la funci칩n de activaci칩n que utilizaremos.\n",
        "    * `identity`: activaci칩n sin operaci칩n, 칰til para implementar cuellos de botella lineales, devuelve $f(x) = x$.\n",
        "\n",
        "    * `logistic`: la funci칩n sigmoidea log칤stica, devuelve $f (x) =\\frac{1}{ (1 + exp (-x))}$.\n",
        "\n",
        "    * `tanh`:  la funci칩n tan hiperb칩lica, devuelve $f (x) = tanh (x)$.\n",
        "\n",
        "    * `relu`: la funci칩n de unidad lineal rectificada, devuelve $f (x) = max (0, x)$.\n",
        "    \n",
        "    \n",
        "* **`learning_rate`**: Velocidad de aprendizaje de nuestra red. \n",
        "    * `constant`: es una tasa de aprendizaje constante dada por `learning_rate_init`. Este es el valor predeterminado.\n",
        "    * `invscaling`: disminuye gradualmente la tasa de aprendizaje `learning_rate_` en cada paso de tiempo $t$ utilizando un exponente de escala inversa de `power_t` . `effective_learning_rate = learning_rate_init / pow(t, power_t)`.\n",
        "    * `adaptive`: mantiene la tasa de aprendizaje constante en `learning_rate_init` siempre que la p칠rdida de entrenamiento siga disminuyendo.\n",
        "    \n",
        "\n",
        "* `max_iter`: N칰mero m치ximo de iteraciones.\n",
        "\n",
        "\n",
        "* `warm_start`: El modelo comienza desde la soluci칩n de la 칰ltima vez que la hemos ejecutado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz6QgufLmWH7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ53XbmcmWH7"
      },
      "source": [
        "### XGboost y los 치rboles de decisi칩n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dUxGQuzmWH7"
      },
      "source": [
        "XGboost es una \"evoluci칩n\" de los 치rboles de clasificaci칩n. Se podr칤a decir que estamos mezclando varios 치rboles y evaluando que tan bueno es el modelo. \n",
        "\n",
        "El elemento clave de esto es nuestra funci칩n de p칠rdida, com칰nmente utilizando la media de los errores al cuadrado junto con una **penalizaci칩n de complejidad**, es decir, vamos a penalizar los modelos que sean muy complejos; esto 칰ltimo es lo que nos permite evitar el **overfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr-DB39TmWH7"
      },
      "source": [
        "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/cart.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-6_pnLzmWH7"
      },
      "source": [
        "a diferencia de los 치rboles normales, en este caso asigna **valores reales** a nuestros posibles eventos, de manera que podr칤amos generar una m칠trica que vamos a poder a침adir a nuevos 치rboles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6JGThzhmWH8"
      },
      "source": [
        "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/twocart.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw__LVsJmWH8"
      },
      "source": [
        "de forma que la predicci칩n de nuestros eventos estar치 en funci칩n de los distintos 치rboles que utilicemos. De forma que al final obtenemos una estructura como la siguiente:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5rnlabGmWH8"
      },
      "source": [
        "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/struct_score.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AU98xOYmWH8"
      },
      "source": [
        "estar칤amos **acumulando los valores** de nuestros eventos o en este caso, de nuestros individuos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyc5vywSmWH8"
      },
      "source": [
        "[Documentaci칩n de XGboost ](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq5SahpvmWH8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa58cEcbnU83"
      },
      "source": [
        "Ya que el paquete XGboost suele dar problemas, de aqu칤 en adelante estar칠 utilizando colab para no instalarlo; por lo que las llamadas de los archivos se veran distintas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB7yvoGtmWH9"
      },
      "source": [
        "### KGboost en Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Dw7lnDm0hj"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WISf0eUm2rK"
      },
      "source": [
        "from xgboost import XGBRegressor #pip install xgboost\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOMUujSonKJ3"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DataSets/2008.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6bU5SA7nR5u"
      },
      "source": [
        "df = data.dropna(subset=['ArrDelay'])\n",
        "df = df.sample(frac=1).head(10000)\n",
        "\n",
        "X = df[[\"AirTime\", \"Distance\", \"TaxiIn\", \"TaxiOut\", \"DepDelay\"]]\n",
        "Y = df[\"ArrDelay\"]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx6YsJVWnwTi"
      },
      "source": [
        "podr칤amos utilizar variables categ칩ricas y convertirlas en dummies de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfqMmRTeoLGe"
      },
      "source": [
        "#df['Month'] = df['Month'].apply(str)\n",
        "#df['DayofMonth'] = df['DayofMonth'].apply(str)\n",
        "#df['DayOfWeek'] = df['DayOfWeek'].apply(str)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj9iIwQAoXRX"
      },
      "source": [
        "#dummies = pd.get_dummies(data= df[['Month', 'DayofMonth', 'DayOfWeek', 'Origin', 'Dest']])\n",
        "#X = dummies.add(X, fill_value=0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxi29534ozUd"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyMXMuIGpF83"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg_17vSPpQa-"
      },
      "source": [
        "Ahora, vamos a llamar al modelo XGboost:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhlxb_fZpjhI"
      },
      "source": [
        "model = XGBRegressor(n_jobs=-1, learning_rate=.5, max_depth=2,\n",
        "                     colsample_bytree=1, verbosity=2, subsample=1, n_stimators=500)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq4_bqzyqSsz"
      },
      "source": [
        "* `n_jobs`: Nos permite paralelizar el procedimiento. En este caso asignamos todos los procesadores excepto 1.\n",
        "* `learning_rate`: Velocidad a la que aprende el modelo.\n",
        "* `max_depth`: Profundidad m치xima de los 치rboles.\n",
        "* `colsample_bytree`: Qu칠 porcentaje de columnas queremos utilizar para lso 치rboles. En este caso, usamos todos.\n",
        "* `verbosity`: Aqu칤 le decimos si queremos que nos muestre los resultados, dependiendo el valor nos da cierta informaci칩n extra.\n",
        "* `subsample`: Cu치ntas filas tomamos para los 치rboles.\n",
        "* `n_stimators`: N칰mero de 치rboles que queremos.\n",
        "\n",
        "A칰n hay m치s par치metros que podr칤amos modificar, para m치s detalles tenemos la documentaci칩n oficial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDR_GTlzp2DD"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HT9JHLep4rx",
        "outputId": "2e3d4945-9cfa-4479-88e6-7844d650a313"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "print('R2: ', r2_score(y_test, predictions))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2:  0.9371116163116314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J16T5BJrlMx"
      },
      "source": [
        "Como vemos es un modelo con el que podemos obtener muy buenos resultados, el 칰nico inconveniente es que tendremos que moficiar muchos par치metros hasta dar con la versi칩n m치s 칩ptima para nuestros datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMhfBPUFqMih"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcbEmUUdrjNM"
      },
      "source": [
        "## 2. Funciones clave en Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWPYrNxNtT5r"
      },
      "source": [
        "### Seleccionar variables en Machine Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkq2uGTktZNZ"
      },
      "source": [
        "Cuando estamos creando modelos para bases de datos con muchas columnas (variables), puede que queramos omitir cierta cantidad de ellas dependiendo del problema que estemos haciendo, ya que algunas de ellas no ser칤an relevantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQGz8li9trI_"
      },
      "source": [
        "from sklearn import linear_model\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-M1WpwWtw0H"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DataSets/2008.csv')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPMWERSnt-VG",
        "outputId": "f5dddf56-266d-453b-f166-8fec385a9444"
      },
      "source": [
        "print(sorted(data.keys()))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ActualElapsedTime', 'AirTime', 'ArrDelay', 'ArrTime', 'CRSArrTime', 'CRSDepTime', 'CRSElapsedTime', 'CancellationCode', 'Cancelled', 'CarrierDelay', 'DayOfWeek', 'DayofMonth', 'DepDelay', 'DepTime', 'Dest', 'Distance', 'Diverted', 'FlightNum', 'LateAircraftDelay', 'Month', 'NASDelay', 'Origin', 'SecurityDelay', 'TailNum', 'TaxiIn', 'TaxiOut', 'UniqueCarrier', 'WeatherDelay', 'Year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09xFW1wmt5kY"
      },
      "source": [
        "df = data.dropna(subset = ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayOfWeek', 'DayofMonth', 'Month', 'DepDelay', 'WeatherDelay'])\n",
        "df = df.sample(frac = 1).head(1000)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvE0gmcFudEt"
      },
      "source": [
        "X = df[ ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayOfWeek', 'DayofMonth', 'Month', 'DepDelay', 'WeatherDelay']]\n",
        "Y = df['ArrDelay']"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rg8TZF-u4UA"
      },
      "source": [
        "Usemos un modelo de regresi칩n lineal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eurf9IvXutEH"
      },
      "source": [
        "regression = linear_model.LinearRegression()\n",
        "regression.fit(X,Y)\n",
        "predictions = regression.predict(X)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTREIYrow6bh",
        "outputId": "69f8479d-c1e7-4e88-b445-9661e64f9ec8"
      },
      "source": [
        "print('R2: ', r2_score(Y, predictions))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2:  0.9694363013700205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXuRv2UCu2Fz"
      },
      "source": [
        "Para saber cuales de estas variables realmente son representativas (te칩ricamente) haremos un an치lisis estad칤stico. Utilizaremos las siguientes instrucciones para hacer que Python nos muestre datos similares a los que esperar칤amos al utilizar R. Esto lo lograremos con el paquete `statsmodels.api`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBuFfhBevNrO",
        "outputId": "2fd136a4-77cc-4b57-cb85-34afbbf25d7f"
      },
      "source": [
        "# Test estadistico\n",
        "X2 = sm.add_constant(X)\n",
        "est = sm.OLS(Y, X2)\n",
        "est2 = est.fit()\n",
        "print(est2.summary())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:               ArrDelay   R-squared:                       0.969\n",
            "Model:                            OLS   Adj. R-squared:                  0.969\n",
            "Method:                 Least Squares   F-statistic:                     3489.\n",
            "Date:                Fri, 02 Jul 2021   Prob (F-statistic):               0.00\n",
            "Time:                        01:03:31   Log-Likelihood:                -3719.5\n",
            "No. Observations:                1000   AIC:                             7459.\n",
            "Df Residuals:                     990   BIC:                             7508.\n",
            "Df Model:                           9                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const          -21.6959      1.326    -16.362      0.000     -24.298     -19.094\n",
            "AirTime          0.4308      0.021     20.521      0.000       0.390       0.472\n",
            "Distance        -0.0521      0.003    -19.957      0.000      -0.057      -0.047\n",
            "TaxiIn           0.7445      0.048     15.492      0.000       0.650       0.839\n",
            "TaxiOut          0.8153      0.015     54.168      0.000       0.786       0.845\n",
            "DayOfWeek       -0.0134      0.159     -0.084      0.933      -0.326       0.299\n",
            "DayofMonth      -0.0278      0.037     -0.760      0.447      -0.100       0.044\n",
            "Month           -0.0958      0.090     -1.069      0.285      -0.272       0.080\n",
            "DepDelay         0.9556      0.006    167.401      0.000       0.944       0.967\n",
            "WeatherDelay     0.0354      0.016      2.163      0.031       0.003       0.068\n",
            "==============================================================================\n",
            "Omnibus:                       59.658   Durbin-Watson:                   1.934\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              229.226\n",
            "Skew:                           0.063   Prob(JB):                     1.68e-50\n",
            "Kurtosis:                       5.342   Cond. No.                     4.14e+03\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 4.14e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e6TDYENvkIE"
      },
      "source": [
        "Particularmente nos interesa la columna ` P>|t|`, aqu칤 tenemos la probabilidad de que cada una de las variables sea relevante o no en nuestro modelo. Es decir, que tan relevante podr칤a ser al generar cambios significativos en nuestros resultados. \n",
        "\n",
        "En este caso decimos que es significativo cuando el valor es pr칩ximo a 0, dir칤amos que `DayOfWeek` es la menos relevante. Si el valor est치 por encima de $0.5$ decimos que no es relevante para el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkk7wfMwv980"
      },
      "source": [
        "Vamos a probar nuestro modelo omitiendo las variables que no son tan relevantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqzCw2cdxGZ2"
      },
      "source": [
        "df = data.dropna(subset = ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayofMonth', 'Month', 'DepDelay', 'WeatherDelay'])\n",
        "df = df.sample(frac = 1).head(1000)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilr9l3FVxJmD"
      },
      "source": [
        "X = df[ ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayofMonth', 'Month', 'DepDelay', 'WeatherDelay']]\n",
        "Y = df['ArrDelay']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYNnGw0QxMRY"
      },
      "source": [
        "regression = linear_model.LinearRegression()\n",
        "regression.fit(X,Y)\n",
        "predictions = regression.predict(X)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUXsDQ0YxObf",
        "outputId": "ef95485b-8025-4105-a4c9-1585c382f4e0"
      },
      "source": [
        "print('R2: ', r2_score(Y, predictions))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2:  0.9538875382623997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMAOP4w7xQRy"
      },
      "source": [
        "Podr칤amos obtener un score menor, pero al trabajar con menos variables el modelo es menos costoso computacionalmente, nos ahorra tiempo y realmente no tendr칤amos un cambio tan significativo.\n",
        "\n",
        "Podr칤amos repetir el procedimiento var칤as veces para quitarnos de encima las variables que no son necesarias y ahorrarnos costes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k1GwYE7xa55",
        "outputId": "2ef80d7d-e047-4180-8e19-f39799d9b7cc"
      },
      "source": [
        "# Test estadistico\n",
        "X2 = sm.add_constant(X)\n",
        "est = sm.OLS(Y, X2)\n",
        "est2 = est.fit()\n",
        "print(est2.summary())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:               ArrDelay   R-squared:                       0.954\n",
            "Model:                            OLS   Adj. R-squared:                  0.954\n",
            "Method:                 Least Squares   F-statistic:                     2562.\n",
            "Date:                Fri, 02 Jul 2021   Prob (F-statistic):               0.00\n",
            "Time:                        01:12:49   Log-Likelihood:                -3800.0\n",
            "No. Observations:                1000   AIC:                             7618.\n",
            "Df Residuals:                     991   BIC:                             7662.\n",
            "Df Model:                           8                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const          -23.4468      1.293    -18.131      0.000     -25.984     -20.909\n",
            "AirTime          0.4791      0.023     21.158      0.000       0.435       0.523\n",
            "Distance        -0.0585      0.003    -20.846      0.000      -0.064      -0.053\n",
            "TaxiIn           0.8351      0.050     16.568      0.000       0.736       0.934\n",
            "TaxiOut          0.7655      0.021     36.836      0.000       0.725       0.806\n",
            "DayofMonth      -0.0112      0.039     -0.289      0.772      -0.087       0.065\n",
            "Month            0.1094      0.097      1.124      0.261      -0.082       0.300\n",
            "DepDelay         0.9574      0.007    131.517      0.000       0.943       0.972\n",
            "WeatherDelay     0.0271      0.016      1.649      0.100      -0.005       0.059\n",
            "==============================================================================\n",
            "Omnibus:                       86.675   Durbin-Watson:                   1.932\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              412.812\n",
            "Skew:                          -0.224   Prob(JB):                     2.29e-90\n",
            "Kurtosis:                       6.115   Cond. No.                     3.73e+03\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 3.73e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQGsr2kjxsc5"
      },
      "source": [
        "Por ejemplo, ahora podr칤amos extraer la variable `DayofMonth`. Aunque es importante aclarar que aqu칤 esta marcandonos estas variables como **menos significativas** dado que no las estamos tratando adecuadamente, las estamos utilizando de fomra num칠rica cuando tendr칤amos que trabajarla m치s de en forma de `dummies` (como factores).\n",
        "\n",
        "쯇odr칤amos automatizar este proceso?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgvdGy7qxx1V"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky9Hu1_37dPn"
      },
      "source": [
        "### Selecci칩n automatizada de variables en ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gImgjOPj7g0e"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn import linear_model\n",
        "import pandas as pd"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnVkNB0M7nSN"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DataSets/2008.csv')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZhk9C947rOw"
      },
      "source": [
        "Para realizar nuestra selecci칩n automatizada de variables utilizaremos `.feature_selection.RFE` (eliminaci칩n de caracter칤sticas recursivas) el cual tiene el objetivo de seleccionar las caracter칤sticas considerando recursivamente conjuntos de caracter칤sticas cada vez m치s peque침os. \n",
        "\n",
        "Primero, el estimador se entrena en el conjunto inicial de caracter칤sticas y la importancia de cada una se obtiene a trav칠s de cualquier atributo espec칤fico o invocable. Luego, las caracter칤sticas menos importantes se eliminan del conjunto actual. Repetimos ese proceso recursivamente hasta que se obtiene el n칰mero deseado de caracter칤sticas para seleccionar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwL_XBTA9XX4"
      },
      "source": [
        "Vamos a partir de las siguientes variables elegidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zty_AtGX8V0O"
      },
      "source": [
        "df = data.dropna(subset = ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayOfWeek', 'DayofMonth', 'Month','DepDelay', 'WeatherDelay'])\n",
        "df = df.sample(frac = 1).head(1000)\n",
        "\n",
        "X = df[ ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayOfWeek', 'DayofMonth', 'Month','DepDelay', 'WeatherDelay']]\n",
        "Y = df['ArrDelay']\n",
        "\n",
        "regression = linear_model.LinearRegression()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDHqqAZR-md2"
      },
      "source": [
        "Llamamos al RFE, pasandole nuestra regresi칩n y diciendole que queremos 4 variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUZ30SYL9UVL",
        "outputId": "2c76a48f-4166-4b95-afd6-e24cd7fc5eaa"
      },
      "source": [
        "selector = RFE(estimator=regression, n_features_to_select=4)\n",
        "selector.fit(X, Y)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
              "                               normalize=False),\n",
              "    n_features_to_select=4, step=1, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXipaOcK-0bF"
      },
      "source": [
        "Vamos a ver con que variables nos hemos quedado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkIaFzsO-iZW",
        "outputId": "692f3b6d-31ac-45dd-999b-251b669994e3"
      },
      "source": [
        "print(selector.ranking_)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 5 1 1 1 6 2 1 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZF_q0f8-zFq"
      },
      "source": [
        "Si sabemos a priori cu치l o cuales son las variables m치s corelacionadas podr칤amos verificar si esto funcion칩 correctamente. En este caso, si o si, tendr칤amos que quedarnos con `DepDelay` ya que es la que est치 m치s relatcionada con `ArrDelay` (retraso de salida con retraso de llegada)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10vBSx6S_Lem",
        "outputId": "fc6ac747-f75f-4f6e-de2f-7c487c1280e2"
      },
      "source": [
        "X.columns[selector.support_]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TaxiIn', 'TaxiOut', 'DayOfWeek', 'DepDelay'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkUIk2O5_bx_"
      },
      "source": [
        "Haciendo la prueba con 1 sola variable tendr칤amos que obtener `DepDelay`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je42z_bX_snO",
        "outputId": "5fa74369-f4ba-4110-d30a-a18d58f8e0fa"
      },
      "source": [
        "selector = RFE(estimator=regression, n_features_to_select=1)\n",
        "selector.fit(X, Y)\n",
        "print(selector.ranking_)\n",
        "X.columns[selector.support_]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 8 3 2 4 9 5 1 6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DepDelay'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZEXScp0_zGT"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5luk2l1VB-WN"
      },
      "source": [
        "### Selecci칩n de par치metros en ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgVn876CB86"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpE7Imy2CSWT"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DataSets/2008.csv')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpXnu-HjCbah"
      },
      "source": [
        "Ahora, vamos a crear un modelo para seleccionar nuestros par치metros que sea aplicable a cualquier modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBdYUw-gCjxQ"
      },
      "source": [
        "df = data.dropna(subset=['AirTime', 'Distance','TaxiIn', 'TaxiOut', 'DepDelay'])\n",
        "df = df.sample(frac=1).head(1000)\n",
        "X = df[ ['AirTime', 'Distance','TaxiIn', 'TaxiOut', 'DepDelay'] ]\n",
        "Y = df['ArrDelay']\n",
        "\n",
        "# Separando datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .2, random_state = 1)\n",
        "\n",
        "# Estandarizamos\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train) # Notemos que siempre utilizamos el train, NO introducir X o habr칤a overfitting\n",
        "\n",
        "# Reasginamos a los valores de entrenamiento y test\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4lBfm0WE3FD"
      },
      "source": [
        "Vamos a generar 3 listas de 3 par치metros que queremos estudiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHov86e4C4DO"
      },
      "source": [
        "alphas = [0.000001, 0.0001, 0.01, 0.1] # Penalizaci칩n de complejidad\n",
        "layers = [2, 5, 10, 50, 100] # N칰m de capas ocultas\n",
        "solvers = ['lbfgs', 'adam'] # Optimizadores"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfzzhI3RFf9f"
      },
      "source": [
        "Vamos a ver cu치ntas combinaciones tendr칤amos con las selecciones de esos 3 par치metros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vba0EFBYE14H",
        "outputId": "152362cc-d077-4e8f-da1e-e8bfa75c7734"
      },
      "source": [
        "print(len(alphas)*len(layers)*len(solvers), 'Combinaciones posibles')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40 Combinaciones posibles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZKxQPb3Fxbb"
      },
      "source": [
        "Esto nos da una idea de cu치nto podr칤amos tardar en evaluar cada caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "376-1w-bF2zv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}