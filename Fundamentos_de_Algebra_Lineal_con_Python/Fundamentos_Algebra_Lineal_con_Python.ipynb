{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de contenidos <span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Fundamentos-de-lgebra-lineal-con-Python\" data-toc-modified-id=\"Fundamentos-de-lgebra-lineal-con-Python-0\">Fundamentos de lgebra lineal con Python</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conceptos-b谩sicos\" data-toc-modified-id=\"Conceptos-b谩sicos-0.1\">Conceptos b谩sicos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Escalar\" data-toc-modified-id=\"Escalar-0.1.1\">Escalar</a></span></li><li><span><a href=\"#Vector\" data-toc-modified-id=\"Vector-0.1.2\">Vector</a></span></li><li><span><a href=\"#Matriz\" data-toc-modified-id=\"Matriz-0.1.3\">Matriz</a></span></li><li><span><a href=\"#Tensor\" data-toc-modified-id=\"Tensor-0.1.4\">Tensor</a></span></li></ul></li><li><span><a href=\"#Operaciones-b谩sicas\" data-toc-modified-id=\"Operaciones-b谩sicas-0.2\">Operaciones b谩sicas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dimensi贸n-de-un-escalar,-vector,-matriz-o-tensor\" data-toc-modified-id=\"Dimensi贸n-de-un-escalar,-vector,-matriz-o-tensor-0.2.1\">Dimensi贸n de un escalar, vector, matriz o tensor</a></span></li><li><span><a href=\"#Transposici贸n\" data-toc-modified-id=\"Transposici贸n-0.2.2\">Transposici贸n</a></span></li><li><span><a href=\"#Suma-de-matrices\" data-toc-modified-id=\"Suma-de-matrices-0.2.3\">Suma de matrices</a></span></li><li><span><a href=\"#Suma-de-matrices-y-vectores-con-dimensiones-distintas-(broadcasting)\" data-toc-modified-id=\"Suma-de-matrices-y-vectores-con-dimensiones-distintas-(broadcasting)-0.2.4\">Suma de matrices y vectores con dimensiones distintas (broadcasting)</a></span></li></ul></li><li><span><a href=\"#Operaciones-con-matrices\" data-toc-modified-id=\"Operaciones-con-matrices-0.3\">Operaciones con matrices</a></span><ul class=\"toc-item\"><li><span><a href=\"#Producto-interno-de-matrices-y--vectores\" data-toc-modified-id=\"Producto-interno-de-matrices-y--vectores-0.3.1\">Producto interno de matrices y  vectores</a></span></li><li><span><a href=\"#Producto-interno-entre-2-matrices\" data-toc-modified-id=\"Producto-interno-entre-2-matrices-0.3.2\">Producto interno entre 2 matrices</a></span></li><li><span><a href=\"#Propiedades-de-las-matrices\" data-toc-modified-id=\"Propiedades-de-las-matrices-0.3.3\">Propiedades de las matrices</a></span><ul class=\"toc-item\"><li><span><a href=\"#Asociativa\" data-toc-modified-id=\"Asociativa-0.3.3.1\">Asociativa</a></span></li><li><span><a href=\"#Distributiva:\" data-toc-modified-id=\"Distributiva:-0.3.3.2\">Distributiva:</a></span></li><li><span><a href=\"#Conmutativa:\" data-toc-modified-id=\"Conmutativa:-0.3.3.3\">Conmutativa:</a></span></li></ul></li><li><span><a href=\"#Conmutatividad-en-producto-interno-de-vectores\" data-toc-modified-id=\"Conmutatividad-en-producto-interno-de-vectores-0.3.4\">Conmutatividad en producto interno de vectores</a></span></li><li><span><a href=\"#Transposici贸n-del-producto-de-matrices\" data-toc-modified-id=\"Transposici贸n-del-producto-de-matrices-0.3.5\">Transposici贸n del producto de matrices</a></span></li><li><span><a href=\"#C贸mo-comprobar-la-soluci贸n-de-un-sistema-de-ecuaciones-lineales\" data-toc-modified-id=\"C贸mo-comprobar-la-soluci贸n-de-un-sistema-de-ecuaciones-lineales-0.3.6\">C贸mo comprobar la soluci贸n de un sistema de ecuaciones lineales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Combinaci贸n-lineal\" data-toc-modified-id=\"Combinaci贸n-lineal-0.3.6.1\">Combinaci贸n lineal</a></span></li><li><span><a href=\"#Ecuaci贸n-lineal\" data-toc-modified-id=\"Ecuaci贸n-lineal-0.3.6.2\">Ecuaci贸n lineal</a></span></li><li><span><a href=\"#Sistema-de-ecuaciones-lineales\" data-toc-modified-id=\"Sistema-de-ecuaciones-lineales-0.3.6.3\">Sistema de ecuaciones lineales</a></span></li></ul></li><li><span><a href=\"#Tipos-especiales-de-matrices:-Identidad,-Inversa-y-Singular\" data-toc-modified-id=\"Tipos-especiales-de-matrices:-Identidad,-Inversa-y-Singular-0.3.7\">Tipos especiales de matrices: Identidad, Inversa y Singular</a></span><ul class=\"toc-item\"><li><span><a href=\"#Matriz-Identidad\" data-toc-modified-id=\"Matriz-Identidad-0.3.7.1\">Matriz Identidad</a></span></li><li><span><a href=\"#Matriz-Inversa\" data-toc-modified-id=\"Matriz-Inversa-0.3.7.2\">Matriz Inversa</a></span></li><li><span><a href=\"#Matriz-Singular\" data-toc-modified-id=\"Matriz-Singular-0.3.7.3\">Matriz Singular</a></span></li></ul></li><li><span><a href=\"#Utilizando-la-Inversa-de-una-matriz-para-resolver-un-sistema-de-ecuaciones\" data-toc-modified-id=\"Utilizando-la-Inversa-de-una-matriz-para-resolver-un-sistema-de-ecuaciones-0.3.8\">Utilizando la Inversa de una matriz para resolver un sistema de ecuaciones</a></span></li></ul></li><li><span><a href=\"#Sistemas-de-ecuaciones-lineales\" data-toc-modified-id=\"Sistemas-de-ecuaciones-lineales-0.4\">Sistemas de ecuaciones lineales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ejemplos-de-sistemas-sin-soluci贸n,-con-una-soluci贸n-y-con-infinitas-soluciones\" data-toc-modified-id=\"Ejemplos-de-sistemas-sin-soluci贸n,-con-una-soluci贸n-y-con-infinitas-soluciones-0.4.1\">Ejemplos de sistemas sin soluci贸n, con una soluci贸n y con infinitas soluciones</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sistema-Incompatible-(sin-soluciones)\" data-toc-modified-id=\"Sistema-Incompatible-(sin-soluciones)-0.4.1.1\">Sistema Incompatible (sin soluciones)</a></span></li><li><span><a href=\"#Sistema-Compatible\" data-toc-modified-id=\"Sistema-Compatible-0.4.1.2\">Sistema Compatible</a></span></li></ul></li><li><span><a href=\"#Graficar-vectores\" data-toc-modified-id=\"Graficar-vectores-0.4.2\">Graficar vectores</a></span></li><li><span><a href=\"#驴Qu茅-es-una-combinaci贸n-lineal?\" data-toc-modified-id=\"驴Qu茅-es-una-combinaci贸n-lineal?-0.4.3\">驴Qu茅 es una combinaci贸n lineal?</a></span></li><li><span><a href=\"#驴Qu茅-es-un-espacio-y-un-subespacio?\" data-toc-modified-id=\"驴Qu茅-es-un-espacio-y-un-subespacio?-0.4.4\">驴Qu茅 es un espacio y un subespacio?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Condiciones-necesarias-y-suficientes-para-definir-un-subespacio\" data-toc-modified-id=\"Condiciones-necesarias-y-suficientes-para-definir-un-subespacio-0.4.4.1\">Condiciones necesarias y suficientes para definir un subespacio</a></span></li><li><span><a href=\"#Conjunto-generador\" data-toc-modified-id=\"Conjunto-generador-0.4.4.2\">Conjunto generador</a></span></li></ul></li><li><span><a href=\"#Vectores-linealmente-Independientes\" data-toc-modified-id=\"Vectores-linealmente-Independientes-0.4.5\">Vectores linealmente Independientes</a></span></li><li><span><a href=\"#Validar-que-una-matriz-tenga-inversa\" data-toc-modified-id=\"Validar-que-una-matriz-tenga-inversa-0.4.6\">Validar que una matriz tenga inversa</a></span></li></ul></li><li><span><a href=\"#Norma\" data-toc-modified-id=\"Norma-0.5\">Norma</a></span><ul class=\"toc-item\"><li><span><a href=\"#驴Qu茅-es-una-norma-y-para-qu茅-se-usa?-Desigualdad-triangular\" data-toc-modified-id=\"驴Qu茅-es-una-norma-y-para-qu茅-se-usa?-Desigualdad-triangular-0.5.1\">驴Qu茅 es una norma y para qu茅 se usa? Desigualdad triangular</a></span><ul class=\"toc-item\"><li><span><a href=\"#Propiedades\" data-toc-modified-id=\"Propiedades-0.5.1.1\">Propiedades</a></span></li></ul></li><li><span><a href=\"#Tipos-de-normas:-norma-0,-norma-1,-norma-2,-norma-infinito-y-norma-L2-al-cuadrado\" data-toc-modified-id=\"Tipos-de-normas:-norma-0,-norma-1,-norma-2,-norma-infinito-y-norma-L2-al-cuadrado-0.5.2\">Tipos de normas: norma 0, norma 1, norma 2, norma infinito y norma L2 al cuadrado</a></span><ul class=\"toc-item\"><li><span><a href=\"#L0\" data-toc-modified-id=\"L0-0.5.2.1\">L0</a></span></li><li><span><a href=\"#L1\" data-toc-modified-id=\"L1-0.5.2.2\">L1</a></span></li><li><span><a href=\"#L2\" data-toc-modified-id=\"L2-0.5.2.3\">L2</a></span></li><li><span><a href=\"#$L2^2$\" data-toc-modified-id=\"$L2^2$-0.5.2.4\">$L2^2$</a></span></li><li><span><a href=\"#$L-\\infty$\" data-toc-modified-id=\"$L-\\infty$-0.5.2.5\">$L \\infty$</a></span></li></ul></li><li><span><a href=\"#El-producto-interno-como-funci贸n-de-una-norma-y-su-visualizaci贸n\" data-toc-modified-id=\"El-producto-interno-como-funci贸n-de-una-norma-y-su-visualizaci贸n-0.5.3\">El producto interno como funci贸n de una norma y su visualizaci贸n</a></span></li><li><span><a href=\"#VIDEO:-Similaridad-coseno\" data-toc-modified-id=\"VIDEO:-Similaridad-coseno-0.5.4\">VIDEO: Similaridad coseno</a></span></li></ul></li><li><span><a href=\"#Matrices-y-vectores-especiales\" data-toc-modified-id=\"Matrices-y-vectores-especiales-0.6\">Matrices y vectores especiales</a></span><ul class=\"toc-item\"><li><span><a href=\"#La-matriz-diagonal\" data-toc-modified-id=\"La-matriz-diagonal-0.6.1\">La matriz diagonal</a></span></li><li><span><a href=\"#Matriz-sim茅trica\" data-toc-modified-id=\"Matriz-sim茅trica-0.6.2\">Matriz sim茅trica</a></span></li><li><span><a href=\"#Vectores-ortogonales,-matrices-ortogonales-y-sus-propiedades\" data-toc-modified-id=\"Vectores-ortogonales,-matrices-ortogonales-y-sus-propiedades-0.6.3\">Vectores ortogonales, matrices ortogonales y sus propiedades</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vectores-Ortogonales\" data-toc-modified-id=\"Vectores-Ortogonales-0.6.3.1\">Vectores Ortogonales</a></span></li><li><span><a href=\"#Vectores-Ortonormales\" data-toc-modified-id=\"Vectores-Ortonormales-0.6.3.2\">Vectores Ortonormales</a></span></li></ul></li><li><span><a href=\"#Matrices-ortogonales-y-sus-propiedades\" data-toc-modified-id=\"Matrices-ortogonales-y-sus-propiedades-0.6.4\">Matrices ortogonales y sus propiedades</a></span><ul class=\"toc-item\"><li><span><a href=\"#Matriz-de-rotaci贸n\" data-toc-modified-id=\"Matriz-de-rotaci贸n-0.6.4.1\">Matriz de rotaci贸n</a></span></li></ul></li></ul></li><li><span><a href=\"#El-determinante-y-la-traza\" data-toc-modified-id=\"El-determinante-y-la-traza-0.7\">El determinante y la traza</a></span><ul class=\"toc-item\"><li><span><a href=\"#Determinante\" data-toc-modified-id=\"Determinante-0.7.1\">Determinante</a></span></li><li><span><a href=\"#Traza\" data-toc-modified-id=\"Traza-0.7.2\">Traza</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ArqM3v4Prsa"
   },
   "source": [
    "# Fundamentos de lgebra lineal con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rZTAWNHbHd7"
   },
   "source": [
    "## Conceptos b谩sicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ_RxEzUbwme"
   },
   "source": [
    "### Escalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h45LCAh7dMQu"
   },
   "source": [
    "Se denomina **escalar** a los n煤meros reales, constantes o complejos que sirven para describir un fen贸meno f铆sico (o de otro tipo) con magnitud, pero sin la caracter铆stica *vectorial* de la direcci贸n. M谩s formalmente, **es un tensor de orden cero**.\n",
    "\n",
    "En t茅rminos matem谩ticos, se llama **escalar** a los elementos de un *cuerpo* (en algunos casos tambi茅n a los elementos de un anillo), generalmente n煤meros, y en particular se usa con vectores en 谩lgebra lineal y en cualquier rama que use *m贸dulos* o *espacios vectoriales*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqjY2wLWdzLq"
   },
   "source": [
    "Al trabajar en Python con escalares tenemos de muchos tipos, por ejemplo, **enteros**, **flotantes**, **complejos**, **string** o **null/non-type**, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrVjCsXmdl4e",
    "outputId": "afec4022-0097-47c0-9dde-280bab804233"
   },
   "outputs": [],
   "source": [
    "escalar_int = 5\n",
    "print(escalar_int)\n",
    "print(type(escalar_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlUH_6VddxA6",
    "outputId": "cc718110-5c8e-4e4c-8003-4796aaf683da"
   },
   "outputs": [],
   "source": [
    "escalar_float = 3.1416\n",
    "print(escalar_float)\n",
    "print(type(escalar_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VCmLRW32eK0I",
    "outputId": "e80ff0cc-5687-49ad-e498-1bfea385356b"
   },
   "outputs": [],
   "source": [
    "escalar_bool = True\n",
    "print(escalar_bool)\n",
    "print(type(escalar_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgItgc5oeQQj",
    "outputId": "8734922e-0a12-457e-8625-1d021519cd8e"
   },
   "outputs": [],
   "source": [
    "import cmath\n",
    "escalar_complex = complex(5, 3)\n",
    "print(escalar_complex)\n",
    "print(type(escalar_complex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG8ogn0gf8RR"
   },
   "source": [
    "### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWlRQDoIf9s5"
   },
   "source": [
    "Es un 茅nte matem谩tico como la *recta* o el *plano*. Se puede representar mediante un segmento de recta, orientado dentro del *espacio euclidiano tridimensional*. Ek vectir tiene 3 elementos:\n",
    "\n",
    "* M贸dulo (cu谩nto mide)\n",
    "* Direcci贸n (谩ngulo respecto a alg煤n eje)\n",
    "* Sentido (hac铆a donde \"apunta\" la cabeza de la flecha)\n",
    "\n",
    "En matem谩ticas se define al vector como **un elemento de un espacio vectorial**. Esta noci贸n es m谩s abstracta y para muchos espacios vectoriales no es posible representar sus vectores mediante el m贸dulo y la direcci贸n. En particular los espacios de dimensi贸n infinita sin producto escalar no son representables de ese modo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SO4g1bLJg8VL"
   },
   "source": [
    "Se llama **vector** de dimensi贸n $n$ a una **tupla** de n煤meros reales (que se llaman componentes del vector). El conjunto de todos los vectores de dimensi贸n se representa c贸mo $\\mathbb{R}^n$ (formado mediante el producto cartesiano).\n",
    "\n",
    "As铆, un vector $v$ perteneciente a un espacio $\\mathbb{R}$ se representa como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJ82nmPZhbfs"
   },
   "source": [
    "$$ v = (a_1, a_2, a_3, ... ,a_n),\\text{donde } v \\in \\mathbb{R}^n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdLKEbAchcN-"
   },
   "source": [
    "Podemos ver al vector como un *conjunto de n煤meros*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyhFwYb7fC1S",
    "outputId": "be90253b-77c0-4bf1-def5-7f9c55aca051"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Vector Columna\n",
    "column_vector = np.array([[1],[2],[3]])\n",
    "print(column_vector)\n",
    "print(type(column_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBt4D69YiYom",
    "outputId": "81210bae-810a-49bd-ffae-ed014aaaca3b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Vector Fila\n",
    "row_vector = np.array([1,2,3])\n",
    "print(row_vector)\n",
    "print(type(row_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfbmZeMriw9Y"
   },
   "source": [
    "### Matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqPnyoNFiz9l"
   },
   "source": [
    "En matem谩ticas, una **matriz** es un *arreglo bidimensional de n煤meros*. Dado que puede definirse tanto la suma como el producto de matrices, en mayor generalidad se dice que son **elementos de un anillo**. Una matriz se representa por medio de una letra may煤scula $(A,B, \\dots)$ y sus elementos con la misma letra en min煤scula $(a,b,\\dots)$, con un doble sub铆ndice, donde el primero indica la fila y el segundo la columna a la que pertenece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf3MUk29izWv"
   },
   "source": [
    "$$A = \n",
    "\\begin{pmatrix}\n",
    "a_{11} & a_{12} & \\dots & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\dots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m1} & a_{m2} & \\dots & a_{mn} \\\\\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SKfZQOTlC26"
   },
   "source": [
    "Siempre que 2 matrices tengan el mismo n煤mero de filas y de columnas, pueden sumarse o restarse elemento por elemento.\n",
    "\n",
    "Las matrices sirven para representar las coeficientes de los sistemas de ecuaciones lineales o para representar transformaciones lineales dadas una base.\n",
    "\n",
    "Pueden sumarse, multiplicarse y descomponerse de varias formas, lo que tambi茅n las hace un concepto clave en el campo del 谩lgebra lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFzlOqHxnYAJ",
    "outputId": "ef04994c-f343-45de-d58e-44e8a463fccf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "matrix = np.array([\n",
    "                   [0, 1, 2 ,3],\n",
    "                   [3, 2, 1, 0],\n",
    "                   [1, 2, 3, 4],\n",
    "                   [3, 2, 1, 0]\n",
    "])\n",
    "\n",
    "print(matrix)\n",
    "print(type(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36dImWdwldTy"
   },
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTp1OnhAlevF"
   },
   "source": [
    "Un **tensor** es cierta clase de entidad  algebraica de varios componentes que generalizan los conceptos de escalar, vector y matriz **de manera que sea independiente de cualquier sistema de coordenadas**. Se suele utilizar el convenio se **suma de Einstein**.\n",
    "\n",
    "Una vez elegida la base vectorial, los componentes de un tensor en una base vendr谩n dadas por una **multi-matriz**. El orden del tensor ser谩 el n煤mero de 铆ndices necesarios para especificar sin ambig眉edad un componente de un tensor: \n",
    "\n",
    "* Un **escalar** ser谩 considerado como un tensor de orden 0.\n",
    "* Un **vecor** ser谩 considerado como un tensor de orden 1.\n",
    "* Y dada una *base vectorial*, los tensores de segundo orden pueden ser representados por una **matriz**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25xyl56dpa4i"
   },
   "source": [
    "![](https://miro.medium.com/max/891/0*jGB1CGQ9HdeUwlgB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD5S95zIoKNi"
   },
   "source": [
    "Podemos ver al tensor como varias matrices acomodadas en \"capas\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdLDQGUjnz0_",
    "outputId": "5384d5c4-902b-4c06-bea6-c6011a625679"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tensor = np.array([\n",
    "                   [ [11,22,33],  [44,55,66],   [77,88,99]    ],\n",
    "                   [ [99,368,777],[666,555,444],[333,222,111] ],\n",
    "                   [ [13,297,306],[546,58,642], [27,328,943]  ]\n",
    "])\n",
    "print(tensor)\n",
    "print(type(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "723Uwk3ooZP5"
   },
   "source": [
    "Vamos a visualizar nuestro tensor, **suponiendo** que los datos que tenemos son los que representan a una imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "n3AMZePloe2B",
    "outputId": "df32b415-d74f-43f4-f641-7dbdbc5f8dca"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(tensor, interpolation='nearest')\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ki-gAhkqesVr"
   },
   "source": [
    "Podemos decir que en lo que se diferencian nuestros elementos como los escalares, vectores, matrices y tensores es en los *grados de libertad que tenemos para interactuar con ellos*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGEjSb1TjMJM"
   },
   "source": [
    "![](https://i.imgur.com/vDwWVp9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXVt09Mqp1Ib"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Xy8Pndop2uu"
   },
   "source": [
    "## Operaciones b谩sicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu4-yX6FHnc5"
   },
   "source": [
    "### Dimensi贸n de un escalar, vector, matriz o tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0vHD_5-HucJ"
   },
   "source": [
    "En 谩lgebra lineal es importante tener en consideraci贸n las dimensiones que tienen nuestras matrices, vectores y tensores. Ya que algunas veces, de ello depender谩 si las operaciones entre ellos est谩n definidas o no. Por ejemplo, en el caso de una multiplicaci贸n de una matriz por un vector (producto interno), tenemos que coincidir en la dimensi贸n de nuestro vector con la cantidad de filas que tiene nuestra matriz.\n",
    "\n",
    "De forma que se cumple que, si tenemos una matriz de $m\\times n$ por un vector columna $n\\times 1$, entonces obtendremos de resultado un vector fila de $m \\times 1$ (m谩s adelante veremos este tema con calma)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-Azhm4RKwBq"
   },
   "source": [
    "$$\\begin{align*}\n",
    "  A\\cdot {x}=\n",
    "  \\left[\n",
    "    \\begin{array}{cccc}\n",
    "      a_{11} & a_{12} & \\ldots & a_{1n}\\\\\n",
    "      a_{21} & a_{22} & \\ldots & a_{2n}\\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      a_{m1} & a_{m2} & \\ldots & a_{mn}\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  \\left[\n",
    "    \\begin{array}{c}\n",
    "      x_1\\\\\n",
    "      x_2\\\\\n",
    "      \\vdots\\\\\n",
    "      x_n\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  =\n",
    "  \\left[\n",
    "    \\begin{array}{c}\n",
    "      a_{11}x_1+a_{12}x_2 + \\cdots + a_{1n} x_n\\\\\n",
    "      a_{21}x_1+a_{22}x_2 + \\cdots + a_{2n} x_n\\\\\n",
    "      \\vdots\\\\\n",
    "      a_{m1}x_1+a_{m2}x_2 + \\cdots + a_{mn} x_n\\\\\n",
    "    \\end{array}\n",
    "  \\right].\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbZ4iC2ILFct"
   },
   "source": [
    "Entonces, es importante conocer las dimensiones de nuestros `arrays`, y para ello tenemos el m茅todo `.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBfkqNKjIuKl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scalar = 5.679\n",
    "row_vector = np.array([1,2,3])\n",
    "column_vector = np.array([[1],\n",
    "                          [2],\n",
    "                          [3]])\n",
    "matrix = np.array([[1,2],\n",
    "                   [2,3]])\n",
    "tensor = np.array([\n",
    "                   [ [11,22,33],  [44,55,66],   [77,88,99]    ],\n",
    "                   [ [99,368,777],[666,555,444],[333,222,111] ],\n",
    "                   [ [13,297,306],[546,58,642], [27,328,943]  ]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDVx4q6jLUE6"
   },
   "source": [
    "El siguiente error ocurre por que el escalar es considerado un tensor de dimensi贸n 0, es decir, no tiene dimensi贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "8tM8_UGcJ0Oq",
    "outputId": "817a0c76-dba3-4816-9456-cc374c671947"
   },
   "outputs": [],
   "source": [
    "scalar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dshxNlKMgo9"
   },
   "source": [
    "Vamos a ver la dimensi贸n del resto de elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5DsXlQSLOl-",
    "outputId": "a78e1ebe-cf80-4e9f-b04e-1e2c987ac5ec"
   },
   "outputs": [],
   "source": [
    "row_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpy6QJfgMNdq",
    "outputId": "57e6b9a7-ce87-43ce-ba0a-650a942d9de0"
   },
   "outputs": [],
   "source": [
    "column_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NjZmzppjMSP-",
    "outputId": "93d1a960-f43d-4981-aca0-c7d69fcac52f"
   },
   "outputs": [],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxfg2p28MVA5",
    "outputId": "2f70871b-f009-4dcc-b572-e97b90ac0909"
   },
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3OX9nzwMWBo"
   },
   "source": [
    "驴Qu茅 pasa si utilizamos `len()` en lugar de `shape`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE-wGxQEM4yb",
    "outputId": "b5748e84-30fb-4c83-c2cf-cdd28262522d"
   },
   "outputs": [],
   "source": [
    "len(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fgna_htNAKZ"
   },
   "source": [
    "Solo nos devuelve la longitud de la primera parte del arreglo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZGEjq4FNFHU"
   },
   "source": [
    "驴 Y qu茅 pasar铆a si utilizamos `.size`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlzRdrcbNMT7",
    "outputId": "2765f8e6-0ff5-40bf-dce5-64a1dbf435fe"
   },
   "outputs": [],
   "source": [
    "tensor.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVsyNisWNOql"
   },
   "source": [
    "Nos devuelve la multiplicaci贸n de las dimensiones (total de elementos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbid7WSKNTcz"
   },
   "source": [
    "La representaci贸n `(3,3,3)` de un tensor la podemos interpretar como 3 filas, 3 columnas y 3 matrices de 3x3 \"superpuestas\" unas de otras.\n",
    "\n",
    "Por ejemplo, si en una matriz 3x3 podemos representar una imagen; entonces, en un tensor de 3x3x3 podemos representar un video de 3 fotogramas. De esta forma podr铆amos pensar en un tensor como **la evoluci贸n de una matriz en el tiempo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ae0T_tkOIN5"
   },
   "source": [
    "![](https://i.postimg.cc/25f2FS5P/Capture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsTXWM8COtHC"
   },
   "source": [
    "### Transposici贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando hablamos de la transposici贸n de una matriz, nos referimos al proceso de \"voltear\" una matriz, es decir, intercambiar filas por columnas. En realidad es una operaci贸n muy sencilla de hacer, pero con un mont贸n de aplicaciones importantes.\n",
    "\n",
    "Por ejemplo, si tenemos una matriz de $3 \\times 2$ y la transponemos, obtendremos una matriz $2 \\times 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer un proceso similar con los vectores. Por ejemplo, si tenemos un vector fila y hacemos la transposici贸n, entonces obtendremos un vector columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar la transposici贸n, estamos haciendo una especie de \"espejo\" alrededor de la diagonal, por lo que **los elementos de la diagonal se mantienen iguales**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.postimg.cc/GtrCWCzN/Capture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scalar = 5.679\n",
    "row_vector = np.array([1,2,3])\n",
    "column_vector = np.array([[1],\n",
    "                          [2],\n",
    "                          [3]])\n",
    "matrix = np.array([[1,2,4],\n",
    "                   [2,3,4],\n",
    "                   [6,5,8]])\n",
    "tensor = np.array([\n",
    "                   [ [11,22,33],  [44,55,66],   [77,88,99]    ],\n",
    "                   [ [99,368,777],[666,555,444],[333,222,111] ],\n",
    "                   [ [13,297,306],[546,58,642],   [27,328,943]],\n",
    "                   [ [56,67,89],  [111,231,333],  [77,88,99]  ]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar una transposici贸n utilizamos el atributo `.T` de los `narray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_row_vec = row_vector.T\n",
    "print(f'Vector original:\\n{row_vector}\\nVector Transpuesto:\\n{T_row_vec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que en el caso del vector fila lo mantendr谩 igual, al menos de que realicemos operaciones con el."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_col_vec = column_vector.T\n",
    "print(f'Vector original:\\n{column_vector}\\nVector Transpuesto:\\n{T_col_vec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en el caso del vector columna si vemos como lo pasa a un vector fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix = matrix.T\n",
    "print(f'Matriz original:\\n{matrix}\\nMatriz Transpuesta:\\n{T_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver como nuestras filas de la matriz original pasan a ser las nuevas columnas y viceversa con las columnas originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_tensor = tensor.T\n",
    "print(f'Tensor original:\\n{tensor}\\n\\nTensor Transpuesto:\\n{T_tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que el Tensor es una generalizaci贸n del mismo objeto matem谩tico que la matriz, en este caso vamos a ir tomando elemento por elemento de la primera columna para formar la nueva fila y as铆 hasta recorrerlas todas.\n",
    "\n",
    "En este caso en particular vemos como pasamos de tener \"4 matrices de 3x3 concatenadas\", a tener \"3 matrices de 4x3 concatenadas\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si aplicamos 2 veces la transposici贸n de una matriz, obtendremos la misma matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(A^{T})^T = A$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix = matrix.T\n",
    "T_T_matrix = T_matrix.T\n",
    "print(f'Matriz original:\\n{matrix}\\nMatriz doblemente Transpuesta:\\n{T_T_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es de mucha ayuda en la resoluci贸n de ecuaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma de matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suma de matrices est谩 definida cuando los objetos tienen las mismas dimensiones, y para sumar (o restar) 2 matrices basta con sumar cada uno de los elementos con el mismo sub铆ndice. De la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "A + B =\n",
    "  \\left[\n",
    "    \\begin{array}{cccc}\n",
    "      a_{11} & a_{12} & \\ldots & a_{1n}\\\\\n",
    "      a_{21} & a_{22} & \\ldots & a_{2n}\\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      a_{m1} & a_{m2} & \\ldots & a_{mn}\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  +\n",
    "    \\left[\n",
    "    \\begin{array}{cccc}\n",
    "      b_{11} & b_{12} & \\ldots & b_{1n}\\\\\n",
    "      b_{21} & b_{22} & \\ldots & b_{2n}\\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      b_{m1} & b_{m2} & \\ldots & b_{mn}\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  =\n",
    "  \\left[\n",
    "    \\begin{array}{cccc}\n",
    "      a_{11} + b_{11}& a_{12}+ b_{12} & \\ldots & a_{1n} + b_{1n}\\\\\n",
    "      a_{21} + b_{21}& a_{22}+ b_{22} & \\ldots & a_{2n} + b_{2n}\\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      a_{m1}+b_{m1} & a_{m2}+ b_{m2} & \\ldots & a_{mn} + b_{mn}\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.postimg.cc/x1Qz6JKy/Capture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],\n",
    "              [2,3,4],\n",
    "              [3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[3,2,1],\n",
    "              [3,1,4],\n",
    "              [6,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = A + B\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = A - B\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de sumar un escalar a nuestra matriz, entonces sumar铆amos el escalar a cada elemento de la matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 10 + A\n",
    "print(f'Escalar:{10}\\nA:\\n{A}\\n\\nEscalar + A:\\n{E}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasa exactamente lo mismo en el caso de la multiplicaci贸n (si ambas matrices son de las mismas dimensiones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = A * B\n",
    "print(f'A:\\n{A}\\nB:\\n{B}\\nA*B:\\n{F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma de matrices y vectores con dimensiones distintas (broadcasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El t茅rmino *broadcasting* describe como *NumPy* trata a los arrays con diferentes dimensiones durante operaciones aritm茅ticas. Sujeto a varias restricciones, se le aplica *broadcast* al array m谩s peque帽o a trav茅s del array m谩s grande, de forma que terminen con dimensiones compatibles. \n",
    "\n",
    "El *broadcasting* nos provee de un medio para vectorizar operaciones con arrays, de forma que el bucle se produce en C en lugar de en Python. Esto lo hace sin hacer copias innecesarias de datos y usualmente, conduce a implementaciones eficientes de algoritmos. Sin embargo, existen casos en donde el *broadcasting* es una mala idea por qu茅 podr铆a conducir a ineficientes usos de memoria que podr铆an alentar el c贸mputo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "scalar = 5.679\n",
    "vector = np.array([3,4,5])\n",
    "matrix = np.array([[1,2],\n",
    "                   [3,4],\n",
    "                   [5,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que cuando tratamos de sumar elementos de diferentes dimensiones no tenemos como tal una operaci贸n definida como en el caso siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = vector + matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esto ocurre por qu茅 tenemos una matriz $3\\times 2$ tratando de sumarse con un vector fila $3\\times 1$. En este caso no coinciden las dimensiones.\n",
    "\n",
    "驴Qu茅 pasar铆a si utilizamos la transposici贸n de la matriz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix = matrix.T\n",
    "T_A = vector + T_matrix\n",
    "print(T_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma no tenemos error ya que nuestra matriz pasa a ser una matriz $2\\times 3$ que s铆 se puede sumar con un vector $3 \\times 1$.\n",
    "\n",
    "Notemos como podemos realizar las operaciones cuando los n煤meros o dimensiones de en medio coinciden, en este casi el 3 con el : $2\\times 3 \\rightarrow 3 \\times 1$. De est谩 forma lo que estamos haciendo es \"duplicar\" el vector fila, de manera que se sume en cada fila de la matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/2114/1*lY8Ve6Uz_bqVI5NPh5RPZA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justo a esto es a lo que le llamamos **broadcasting**, estamos \"extendiendo\" la dimensi贸n de menor tama帽o para completar la de menor tama帽o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internamente, Python hace **broadcasting** al sumar un escalar con una matriz, ya que est谩 \"extendiendo\" dicho escalar para poder sumar cada elemento de la matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma que la suma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = matrix + 50\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "internamente es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C_Py = matrix + np.array([[50],[50],[50]])\n",
    "print(C_Py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones con matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto interno de matrices y  vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $V$ un espacio vectorial *sobre el cuerpo* $\\mathbb{R}$ *de los reales*. El **producto interno** o **producto escalar** definido sobre $V$ es una aplicaci贸n entre el conjunto de todos los pares de vectores $(u,v)$ y $\\mathbb{R}$, cuyo resultado es un n煤mero real denotado por $\\langle u, v \\rangle$, que satisface las siguientes propiedades para todo $u,v,w \\in V$ y todo escalar $\\alpha \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tag{1} \\langle u,v \\rangle = \\langle v,u \\rangle$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tag{2} \\alpha \\langle u,v \\rangle = \\langle (\\alpha u),v \\rangle = \\langle u ,(\\alpha v) \\rangle$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tag{3} \\langle u+v , w \\rangle = \\langle u,w \\rangle +  \\langle v,w \\rangle $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tag{4} \\langle u , u \\rangle \\geq 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\\tag{4.1}\\langle u , u \\rangle = 0 \\text{ si y s贸lo si } u= 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar la multiplicaci贸n de un vector por una matriz debemos de asegurarnos que sus dimensiones coincidan de la siguiente forma:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(n\\times m)(m\\times l)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde:\n",
    "    \n",
    "* $n$ es el n煤mero de filas de la matriz.\n",
    "* $m$ es el n煤mero de columnas de la matriz y debe coincidir con el n煤mero de filas del vector.\n",
    "* $l$ es el n煤mero de columnas del vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a escribir los elementos con los que vamos a estar trabajando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_vector = np.array([-4,5,8])\n",
    "\n",
    "column_vector = np.array([[-6],\n",
    "                          [-2],\n",
    "                          [ 5]])\n",
    "matrix = np.array([[-3,5,-6],\n",
    "                   [7,10,-1]])\n",
    "\n",
    "matrix2 = np.array([[-2,10],\n",
    "                    [-1,-4],\n",
    "                    [7,9],])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver la diferencia entre el **producto de un vector y una matriz** (seg煤n lo interpreta Python), con el **producto interno** de los mismos. El producto interno se aplica utilizando `.dot()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero veamos **como hace Python para interpretar** el caso del **producto de un vector y una matriz**, as铆 sin m谩s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = matrix * row_vector\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/J1NHDXY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nosotros indicamos la multiplicaci贸n del vector por la matriz con el operador `*`, entonces Python realizar谩 el calculo de arriba; el cual nos recordara al *broadcasting* del que hablamos anteriormente. Podemos imaginar este proceso como si estuviera \"replicando\" el vector fila, de manera que multiplique componente por componente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product =  row_vector * matrix \n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en este caso, no tiene problema en multiplicar primero la matriz o el vector de esta forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el otro lado, si quisieramos aplicar el mismo producto con `*` y un **vector columna**, no encontrar铆a compatibilidad con las dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = matrix * column_vector\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, hablemos sobre el **producto interior** o **producto punto** entre matriz y vector. Para realizar esto tendremos que asegurarnos de que se cumpla la condici贸n de arriba: $(n\\times m)(m \\times l)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos con el producto de nuestro vector columna por nuestra matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_col = matrix.dot(column_vector)\n",
    "print(dot_product_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tenemos una matriz de $(2\\times 3)$ y un vector columna de $(3\\times 1)$, por lo que las dimensiones coinciden y podemos realizar correctamente el producto de vector y matriz, el cual se realiza de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/Wo6XcCM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驴Qu茅 pasar铆a si tratamos de realizar el producto del *vector por la matriz*, es decir, el orden inverso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_col2 = column_vector.dot(matrix)\n",
    "print(dot_product_col2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos arroja un error, ya que las dimensiones no coinciden ya que tendriamos el caso $(3\\times 1)(2 \\times 3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del **vector fila** ocurre un caso similar, ya que si tratamos de hacer el producto de nuestra matriz por el **vector fila**, tendr铆amos incompatibilidad con el caso $(2\\times 3)(1 \\times 3)$.\n",
    "\n",
    "En este caso **Python s铆 lo puede realizar**, ya que utilizar un m茅todo como el *broadcasting*, **pero antes de revisarlo veamos como ser铆a el caso con las dimensiones correctas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_row = row_vector.dot(matrix2)\n",
    "print(f'Vector: {row_vector}\\nMatriz:\\n {matrix2}\\nProduct: {dot_product_row}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notemos que estamos multiplicando vector por matriz, no matriz por vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/pfOTMol.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora s铆, volvamos al caso donde tenemos diferentes dimensiones, pero Python encuentra el modo de hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Matriz:\\n{matrix}\\nVector:{row_vector}\\nShape:(2x3)(1x3)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_dot_product = matrix.dot(row_vector)\n",
    "print(strange_dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un inicio, las dimensiones no coincide. As铆 que Python opta por aplicar nuevamente el *broadcasting*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.postimg.cc/CKLw1SgV/Capture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto interno entre 2 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1 ,2 ,3],\n",
    "              [4 ,5 ,6],\n",
    "              [7 ,8 ,9],\n",
    "              [10,11,12]])\n",
    "\n",
    "B = np.array([[2,3],\n",
    "              [5,7],\n",
    "              [11,13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(f'Shape A: {A.shape}\\nShape B: {B.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver si est谩n definidos los productos $A \\cdot B$ y $B \\cdot A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A \\cdot B$ s铆 est谩 definida, ya que coinciden los 3's y nos quedamos con un arreglo de $(4 \\times 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dot_B = A.dot(B)\n",
    "print(f'A dot B:\\n{A_dot_B}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La operaci贸n que se realiz贸 fue la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/rQMLX0c.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_dot_A = B.dot(A)\n",
    "print(f'A dot B:\\n{B_dot_A}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en el caso de $B \\cdot A$ no est谩 definida por la incompatibilidad de las dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades de las matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asociativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A \\times (B \\times C) = (A \\times B) \\times C$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributiva:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A \\times (B+C) = (A \\times B) + (A \\times C)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conmutativa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$B \\times C = C \\times B$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a corroborar con c贸digo cuales de estas propiedades se cumplen para el producto interno de matrices y de vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[2,3],[5,7],[11,13]])\n",
    "B = np.array([[1,3],[2,1]])\n",
    "C = np.array([[3,1],[4,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asociativa\n",
    "A_BC = A.dot(B.dot(C))\n",
    "AB_C = (A.dot(B)).dot(C)\n",
    "print(f'A(BC):\\n{A_BC}\\n(AB)C:\\n{AB_C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cumple la ASOCIATIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributiva\n",
    "A_Bpc = A.dot(B+C)\n",
    "AB_AC = A.dot(B)+ A.dot(C)\n",
    "print(f'A*(B+C):\\n{A_Bpc}\\n(AB)+(AC):\\n{AB_AC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cumple la DISTRIBUTIVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conmutativa\n",
    "B_C = B.dot(C)\n",
    "C_B = C.dot(B)\n",
    "print(f'B*C:\\n{B_C}\\nC*B:\\n{C_B}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO se cumple la CONMUTATIVA en la mayor铆a de los casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conmutatividad en producto interno de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([[2],[7]])\n",
    "v2 = np.array([[3],[5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a las dimensiones de nuestros vectores, tendremos que hacerlas coincidir con una transposici贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1T_dot_v2 = v1.T.dot(v2)\n",
    "print(v1T_dot_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2T_dot_v1 = v2.T.dot(v1)\n",
    "print(v2T_dot_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resto de propiedades tambi茅n se cumplen para el caso de los vectores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposici贸n del producto de matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una propiedad que nos indica lo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{pmatrix}\n",
    "A \\cdot B\n",
    "\\end{pmatrix}^t = B^t \\cdot A^t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y recordemos una propiedad que vimos anteriormente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${{(A \\cdot B)}^{t}}^t = A \\cdot B $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde indicamos la transposici贸n de la matriz con la letra $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a corroborar esa propiedad en c贸digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2,3], [5,7], [11,13]])\n",
    "B = np.array([[1,3], [2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A:\\n{A}\\nB:\\n{B}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Matrices shapes \\nA:{A.shape}\\nB:{B.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpuestas\n",
    "A_t = A.T\n",
    "B_t = B.T\n",
    "print(f'A transpuesta:\\n{A_t}\\nB transpuesta:\\n{B_t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_t = (A.dot(B)).T\n",
    "print(f'(AB) transpuesta:\\n{AB_t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bt_At = (B.T).dot(A.T)\n",
    "print(f'B transpuesta por A transpuesta:\\n{Bt_At}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AB_t == Bt_At)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C贸mo comprobar la soluci贸n de un sistema de ecuaciones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos algunas nociones b谩sicas del 谩lgebra lineal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinaci贸n lineal\n",
    "\n",
    "Es el vector que se obtiene al sumar una series de vectores multiplicados por escalares.\n",
    "\n",
    "Sean $v_1,v_2,...,v_n$ vectores en un espacio vectorial $V$. Entonces, cualquier vector de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\alpha_{1}v_{1}+\\alpha_{2}v_{2}+\\dots +\\alpha_{n}v_{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $\\alpha_{i} v_{i}$ son escalares, se denomina **combinaci贸n lineal** de $v_1,v_2, v_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea la combinaci贸n lineal de las variables $x_1, x_2, ..., x_n$ dada por la expresi贸n:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_1x_1+a_2x_2+ \\dots + a_nx_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los n煤meros reales $a_1,\\dots,a_n \\in \\mathbb{R}$, se denominan **coeficientes de la combinaci贸n**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecuaci贸n lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una **ecuaci贸n lineal** en las inc贸gnitas o variables $x_1, \\dots, x_n$ es una expresi贸n de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_1x_1+a_2x_2+ \\dots + a_nx_n = b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $b \\in \\mathbb{R}$, se denomina **t茅rmino constante**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una $n-$tupla $(s_1, \\dots, s_n)$es una **soluci贸n** de la ecuaci贸n lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_1x_1+a_2x_2+ \\dots + a_nx_n = b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si, al sustituir las variables $x_1, x_2, \\dots, x_n$ por los n煤meros $s_1,\\dots,s_n$ se obtiene una identidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sistema de ecuaciones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **sistema de $m$ ecuaciones lineales** y $n$ **inc贸gnitas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "a_{11}x_1+a_{12}x_2+ &\\dots& + a_{1n}x_n = b_{1}  \\\\\n",
    "a_{21}x_1+a_{22}x_2+ &\\dots& + a_{2n}x_n = b_{2}  \\\\\n",
    "               &\\vdots& \\\\\n",
    "a_{m1}x_1+a_{m2}x_2+ &\\dots& + a_{mn}x_n = b_{m}  \\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiene **soluci贸n** $(s_1, \\dots, s_n)$ si dicha $n-$tupla es una soluci贸n **de todas** las ecuaciones del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La soluci贸n de un sistema lineal no existe necesariamente, y si lo hace, no es necesariamente 煤nica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si un sistema de ecuaciones tiene soluci贸n o soluciones, se denomina **sistema compatible**; en caso contrario, diremos que es un **sistema incompatible**. Y al conjunto de todas las soluciones de un sistema de ecuaciones lineales dado se denomina **conjunto de soluciones**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos el siguiente sistema de ecuaciones:\n",
    "\n",
    "$$\\begin{cases} \n",
    "y = 3x + 5 \\\\\n",
    "y = 2x + 3\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que para graficar una funci贸n, tendremos que evaluarla a lo largo de diferentes puntos. Por lo que queremos obtener peque帽os intervalos en donde vamos a obtener nuestra funci贸n evaluada, para hacerlo hagamos un arreglo como el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5) # Intervalo de -5 a 5 de 1 en 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a escribir las ecuaciones que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = 3*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = 2*x + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a graficar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure() #Crea figura\n",
    "plt.axvline(x=0, color = 'black') # Eje X\n",
    "plt.axhline(y=0, color=  'black') # Eje Y\n",
    "plt.grid() # Cuadricula\n",
    "plt.plot(x, y_1) \n",
    "plt.plot(x, y_2)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlim(-5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar que las rectas se tocan en un punto, es decir, comparten un valor posible de $x$ que nos d谩 el mismo valor en $y$. Esto nos dice que existe una soluci贸n del sistema, ya que es soluci贸n de ambas ecuaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, podemos proceder a realizar el despeje:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "2x + 3 &= 3x+5 \\\\\n",
    "x &= -2\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "2x + 3    &= y \\\\\n",
    "2(-2) + 3 &= y \\\\\n",
    "-1        &= y\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(-2,-1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pero aqu铆 no estamos lidiando con 谩lgebra \"com煤n\", as铆 que vamos a ver como podr铆amos representar este sistema de forma *matricial*. Para hacerlo, vamos a \"pasar\" todas las variables de un lado de la igualdad y las constantes del otro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "y = 3x + 5 \\\\\n",
    "y = 2x + 3\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "-3x + y = 5 \\\\\n",
    "-2x + y = 3\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a \"extraer\" los coeficientes de nuestro sistema, de manera que tengamos una matriz (con los coeficientes) y un vector (con las variables). De forma que el sistema, se describa mediante el **producto interno** de una matriz y un vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "-3 & 1\\\\\n",
    "-2 & 1\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "5 \\\\\n",
    "3 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As铆 que, ahora escribamos nuestro sistema en forma matricial a c贸digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-3, 1],\n",
    "              [-2, 1]])\n",
    "res_vec = np.array([[5],\n",
    "                    [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a comprobar la soluci贸n que obtuvimos arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_1 = np.array([[-2],[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = A.dot(sol_1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisieramos encontrar la soluci贸n utilizando Python, har铆amos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linalg.solve(A, res_vec)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usamos el m茅todo `.solve()` y le pasamos la matrix coeficiente y despues los valores independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[-3, 1],\n",
    "              [-2, 1]])\n",
    "\n",
    "res_vec = np.array([[5],\n",
    "                    [3]])\n",
    "\n",
    "x = np.linalg.solve(A, res_vec)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos especiales de matrices: Identidad, Inversa y Singular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz Identidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz identidad** es una matriz que cumple la propiedad de ser el elemento neutro del producto de matrices. Esto quiere decir que el producto de cualquier matriz por la matriz identidad (mientras est茅 definido) no tiene ning煤n efecto y nos devuelve la matriz original. La columna $i-$茅sima de una matriz identidad es el **vector unitario** $e_i$ de una base vectorial inmersa en un espacio Eucl铆deo de dimensi贸n $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En NumPy basta con escribir la instrucci贸n `.eye()` e indicarle las dimensiones que queremos que tenga nuestra matriz identidad o los cu谩ntos elementos tendr谩 la diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(2)\n",
    "print(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(4)\n",
    "print(identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notemos que todos los elementos est谩n definidos como `floats`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a verificar cu谩l es el efecto de esta matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(3)\n",
    "\n",
    "vector = np.array([[1],\n",
    "                   [2],\n",
    "                   [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = identity.dot(vector)\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(4)\n",
    "\n",
    "matrix = np.array([[1,2,3,4],\n",
    "                   [5,6,7,8],\n",
    "                   [9,10,11,12],\n",
    "                   [13,14,15,16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product2 = identity.dot(matrix)\n",
    "print(product2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimos que la **matriz identidad** no transforma el espacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz Inversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz inversa** es la transformaci贸n lineal de una matriz mediante la multiplicaci贸n del inverso del determinante de la matriz por la matriz adjunta transpuesta. Es decir, es la multiplicaci贸n del *inverso del determinante* por la matriz adjunta traspuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y se cumple que el producto de una matriz por su inversa, es igual a la matriz identidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A \\cdot A^{-1} =  A^{-1} \\cdot A =I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz inversa se puede calcular por el **m茅todo de Gauss** o por el **m茅todo de determinantes**. Para hacerlo en Python tenemos la instrucci贸n `.linalg.inv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,0,1],[0,1,1],[-1,1,1]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inverse = np.linalg.inv(A)\n",
    "print(A_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos que obtendr铆amos la matriz identidad al realizar el producto interno de estas matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ident = A.dot(A_inverse)\n",
    "print(ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ident2 = A_inverse.dot(A)\n",
    "print(ident2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz Singular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que no siempre existe esta matriz inversa. **Cuando la matriz NO tiene inversa, la llamamos singular**. La definimos de la siguiente forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz singular** es la *matriz cuadrada* de orden $N$, cuyo **determinante es nulo** $(=0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente matriz ser铆a un caso de matriz singular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular = np.array([[1,1],[1,1]])\n",
    "print(singular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(singular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que nos arroja el error `LinAlgError: Singular matrix`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTA: No podr铆amos intentar esto con matrices que no sean cuadradas $(m \\times m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando la Inversa de una matriz para resolver un sistema de ecuaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos el siguiente sistema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "3x + y = 1 \\\\\n",
    "2x + y = 1\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y en forma matricial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "3 & 1\\\\\n",
    "2 & 1\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos pedirle a NumPy que nos muestre los resultados que est谩n muy proximos a 0, como si fueran 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,1],\n",
    "              [2,1]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1],\n",
    "              [1]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que tendr铆amos que hacer para \"despejar\" a $A$  ser铆a encontrar la inversa de la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a calcular nuestro $x$ (el vector de variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = A_inv.dot(b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamor a verificarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dot_x = A.dot(x)\n",
    "print(A_dot_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y como vemos, s铆 obtenemos el vector `[1 1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, podr铆amos utilizar la misma matriz inversa de $A$ para encontrar otro sistema con la misma matriz de coeficientes, pero que est茅 igualada a otra matriz $b$ diferente.\n",
    "\n",
    "Por ejemplo, probemos con el sistema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "3x + y = 3 \\\\\n",
    "2x + y = 7\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "3 & 1\\\\\n",
    "2 & 1\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "3 \\\\\n",
    "7 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizando la misma inversa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_2 = A_inv.dot(np.array([[3],[7]]))\n",
    "print(sol_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a verificar si es una soluci贸n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.dot(sol_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, calculando la inversa podemos calcular la soluci贸n de otro sistema de ecuaciones igualado a matrices $b$ distintas. Esto es lo que habitualmente hacemos al resolver un **sistema de ecuaciones hom贸geneo** y despu茅s, calculamos una **soluci贸n particular**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas de ecuaciones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de sistemas sin soluci贸n, con una soluci贸n y con infinitas soluciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un sistema es:\n",
    "\n",
    "\n",
    "* **COMPATIBLE** si tiene alguna tupla soluci贸n (colecci贸n finita y ordenada de elementos, $(a_1,\\dots,a_n)$ en un cuerpo $k$)\n",
    "\n",
    "    * **COMPATIBLE DETERMINADO** si tiene una *煤nica* tupla soluci贸n.\n",
    "\n",
    "    * **COMPATIBLE INDETERMINADO** si tiene *m谩s de una* tupla soluci贸n\n",
    "\n",
    "* **INCOMPATIBLE** si no tiene ninguna tupla o vector soluci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queremos los graficos de forma interctiva debajo de cada celda\n",
    "%matplotlib notebook \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sistema Incompatible (sin soluciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos el siguiente sistema de ecuaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "y = 3x  + 5 \\\\\n",
    "y = -1x + 3 \\\\\n",
    "y = 2x  + 1\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear el rango de valores de $x$ para evaluar las ecuaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribimos las ecuaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = 3*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = -x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 = 2*x + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para cada una generemos la figura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.axvline(x = 0, color= 'black')\n",
    "plt.axhline(y = 0, color= 'black')\n",
    "plt.plot(x, y_1)\n",
    "plt.plot(x, y_2)\n",
    "plt.plot(x, y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la imagen podemos observar que las ecuaciones se intersectan en distintos puntos, pero **no existe un punto donde se toquen las 3 al mismo tiempo**, por lo que podr铆amos deducir que dicho sistema de ecuaciones no tiene soluci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sistema Compatible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora consideremos el siguiente sistema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "y = \\frac{x + 5}{2}\\\\\n",
    "y = \\frac{-1x + 7}{2} \\\\\n",
    "y = \\frac{2x + 7}{3}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = ( x + 5) / 2\n",
    "y_2 = (-x + 7) / 2\n",
    "y_3 = (2*x + 7) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.axvline(x = 0, color= 'black')\n",
    "plt.axhline(y = 0, color= 'black')\n",
    "plt.plot(x, y_1)\n",
    "plt.plot(x, y_2)\n",
    "plt.plot(x, y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que las 3 rectas se intersectan en un punto. Por lo que el sistema *s铆 tiene soluci贸n* y adem谩s, *es 煤nica*. Por lo que es un sistema **compatible determinado**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://slideplayer.es/slide/5478638/17/images/5/Sistema+compatible+determinado+Sistema+compatible+indeterminado.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una funci贸n que nos va a ayudar a visualizar vectores para trabajar en el resto de contenidos. Escribiremos el c贸digo aqu铆 y tambi茅n lo guardaremos en otro archivo en local para hacer la llamada a la funci贸n desde otro notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2,5])\n",
    "v2 = np.array([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_vectores(vectors, color, alpha=1):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    \n",
    "    # Ejes\n",
    "    plt.axvline(x=0, color='black')\n",
    "    plt.axhline(y=0, color='black')\n",
    "    \n",
    "    for i in range(len(vectors)):\n",
    "        # Recorremos cada vector y los concatenamos\n",
    "        # (Para poner la cola del vector - origen)\n",
    "        x = np.concatenate([[0,0], vectors[i]])\n",
    "        \n",
    "        # Graficamos\n",
    "        plt.quiver([x[0]],\n",
    "                   [x[1]],\n",
    "                   [x[2]],\n",
    "                   [x[3]],\n",
    "                   angles = 'xy',\n",
    "                   scale_units='xy',\n",
    "                   scale= 1,\n",
    "                   color= color[i],\n",
    "                   alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graficar_vectores([v1, v2], ['blue','red'], alpha=1)\n",
    "\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(-1,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a estar utilizando constantemente esta funci贸n, pero recordemos que cada que reiniciemos el notebook se borrar谩 de la memoria y tendremos que buscar la celda y ejecutar de nuevo. Para evitar esto, la guardaremos en un nuevo notebook y simplemente \"mandaremos a ejecutar\" dicho notebook cada que queramos utilizar la funci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos el comando `%run\"\"` con la ruta relativa de nuestro archivo dentro de las comillas, el cual que contiene la funci贸n que queremos utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar que esto funciona, reinicie el notebook e intente ejecutar la instrucci贸n:\n",
    "\n",
    "```Python\n",
    "graficar_vectores([v1, v2], ['blue','red'], alpha=1)\n",
    "\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(-1,6)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y aparecer谩 que no est谩 definida dicha funci贸n, as铆 que despu茅s ejecute la linea con la instrucci贸n `%run\"\"` y ahora s铆 se podr谩 ejecutar el graficado ya que ha sido llamado desde el otro notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驴Qu茅 es una combinaci贸n lineal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M谩s arriba en la secci贸n de sistemas de ecuaciones definimos que era una combinaci贸n lineal. A grandes rasgos y de una forma muy \"hablada\", podemos decir que es multiplicar vectores por escalares y sumar dichos productos entre si, de forma que obtendr铆amos un nuevo vector. As铆 podr铆amos describir el nuevo vector como **una combinaci贸n lineal** de los vectores anteriores que los conforman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ a_1 v_1  + \\dots +  a_n v_n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamemos a la funci贸n de graficar vectores\n",
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos los vectores\n",
    "v1 = np.array([2,5])\n",
    "v2 = np.array([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribimos una combinaci贸n lineal de esos vectores\n",
    "v1v2 = 2*v1 + 3*v2\n",
    "print(v1v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_vectores([v1,v2,v1v2], color = ['red','blue','purple'], alpha = 1)\n",
    "plt.xlim(-1,13.5)\n",
    "plt.ylim(-1,16.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a煤n cuesta algo de trabajo interpretar la combinaci贸n, as铆 que vamos a graficar los vectores rojo y azul multiplicandolos por los escalares correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_vectores([2*v1,3*v2,v1v2], color = ['red','blue','purple'], alpha = 1)\n",
    "plt.xlim(-1,13.5)\n",
    "plt.ylim(-1,16.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es mucho m谩s claro, podemos visualizar al vector resultante como si colocaramos la cola del vector azul en la punta del vector rojo, de manera que obtendr铆amos nuestro paralelogramo.\n",
    "\n",
    "Vamos a modificar un poco la funci贸n de graficado para que nos dibuje el paralelogramo. Lo hice de forma que primero recibe el vector resultante y luego los 2 vectores que conforman la combinaci贸n lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_vectores_punta_cola(vectors, color, alpha=1):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    \n",
    "    # Ejes\n",
    "    plt.axvline(x=0, color='black')\n",
    "    plt.axhline(y=0, color='black')\n",
    "    \n",
    "    for i in range(len(vectors)):\n",
    "        # Este c贸digo en especial solo servir铆a para combinar 2 vectores\n",
    "        if i == 1:\n",
    "            x = np.concatenate([[0,0], vectors[i]])\n",
    "        elif i == 2: \n",
    "            x = np.concatenate([ vectors[i-1] , vectors[i] ])\n",
    "        else:\n",
    "            x = np.concatenate([[0,0], vectors[i]])\n",
    "        \n",
    "        # Graficamos\n",
    "        plt.quiver([x[0]],\n",
    "                   [x[1]],\n",
    "                   [x[2]],\n",
    "                   [x[3]],\n",
    "                   angles = 'xy',\n",
    "                   scale_units='xy',\n",
    "                   scale= 1,\n",
    "                   color= color[i],\n",
    "                   alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_vectores_punta_cola([v1v2, 2*v1,3*v2], color = ['purple','red','blue'], alpha = 1)\n",
    "plt.xlim(-1,13.5)\n",
    "plt.ylim(-1,16.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, definamos una funci贸n para graficar un subconjunto de las posibles combinaciones lineales que podr铆amos tener al multiplicar nuestros vectores por un cierto rango de escalares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='pink')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-100,100)\n",
    "plt.ylim(-100,100)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que estamos viendo son solo unas pocas de las posibles combinaciones lineales posibles de 2 vectores. Si siguieramos expandiendo esto, describir铆amos a todo el espacio $\\mathbb{R}^2$. \n",
    "\n",
    "As铆 que con ciertos vectores \"base\" podr铆amos describir todo el espacio a partir de combinaciones lineales de estos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驴Qu茅 es un espacio y un subespacio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **espacio vectorial** es un conjunto *no vac铆o* de $V$ objetos llamados **vectores**, en el que se han definido dos operaciones: la suma y el producto escalar sujetas a diez axiomas que se dan a continuaci贸n. Los axiomas deben ser v谩lidos para todos los vectores $u$, $v$, y $w$ en $V$ y todos los escalares $\\alpha$ y $\\beta$ reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $u + v \\in V$\n",
    "* $u + v = v + u$\n",
    "* $(u + v) + w = u+(v + w)$\n",
    "* Existe un vector nulo $0v \\in V$ tal que, $v + 0v = v$\n",
    "* Para cada $v$ en $V$, existe un opuesto $(-v) \\in V$ tal que, $v + (-v) = 0v$\n",
    "* $\\alpha v \\in V$ \n",
    "* $\\alpha(u+v) = \\alpha u + \\alpha v $\n",
    "* $(\\alpha + \\beta) v = \\alpha v + \\beta v$\n",
    "* $\\alpha(\\beta v) = (\\alpha \\beta) v$\n",
    "* $1v = v$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso nos estamos refiriendo a un **espacio vectorial real**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los espacios $\\mathbb{R}^n$, con $n \\ge 1$, son los ejemplos principales de espacios vectoriales. La intuici贸n geom茅trica para $\\mathbb{R}^3$ nos ayudar谩 a entender y visualizar muchos conceptos de esta unidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vectores de $\\mathbb{R}^n$ son $n-$tuplas de n煤meros reales, osea:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbb{R}^n = \\{ (x_1,x_2, \\dots, x_n), \\text{ con } x_i \\in \\mathbb{R} \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En $\\mathbb{R}^n$, la suma de vectores y el producto por un escalar se definen como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean $u=(u_1,u_2, \\dots, u_n)$ y $v=(v_1,v_2, \\dots, v_n)$  $\\in \\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ u + v = (u_1  + v_1 , u_2 + v_2 , \\dots , u_n + v_n) \\in \\mathbb{R}^n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\alpha v = (\\alpha v_1, \\alpha v_2, \\dots, \\alpha v_n) \\in \\mathbb{R}^n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $V$ un espacio vectorial y $W$ un subconjunto no vac铆o de $V$.\n",
    "\n",
    "$W$ es un **subespacio** de $V$ si $W$ es en s铆 mismo un espacio vectorial con las mismas operaciones (suma de vectores y producto escalar) definidas en $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condiciones necesarias y suficientes para definir un subespacio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $W$ un subconjunto de un espacio vectorial $V$, $\\left( {W \\subseteq V} \\right)$. $W$ es un **subespacio** de $V$ si y s贸lo si se cumplen las siguientes condiciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $0V$ est谩 en $W$.\n",
    "* Si $u$ y $v$ est谩n en $W$, entonces, $u+v$ est谩n en $W$.\n",
    "* Si $u$ est谩 en $W$ Y $k$ es un escalar, $ku$ est谩 en $W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La condici贸n #1 nos asegura que $W$ **no es vac铆o**. Mientras que las propiedades a,b y c corresponden a los axiomas 4,1 y 6.\n",
    "\n",
    "A煤n faltar铆a comprobar que cada vector de $W$ tiene su opuesto en $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear 2 vectores \"base\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,1])\n",
    "v2 = np.array([-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamemos a la funci贸n de graficar vectores\n",
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a ver que otros vectores nos generar铆an como espacio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-25,25)\n",
    "plt.ylim(-25,25)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As铆 que, a partir de combinaciones lineales de $v1=(1,1)$ y $v2=(-1,-1)$ s贸lo podr铆amos obtener nuevos vectores que sigan la trayectoria de la recta de arriba. As铆 que NO podemos utilizarlos como nuestros vectores \"base\" para construir  todo $\\mathbb{R}^2$. De hecho, si nos fijamos podemos notar que $v2$ puede producirse como una combinaci贸n lineal de $v1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, para conformar un espacio tendremos que tener una base de vectores **linealmente independientes** (m谩s adelante explicaremos que es eso). En este caso, para formar a $\\mathbb{R}^2$ tendr铆amos que utilizar los vectores $v1=(1,0)$ y $v2=(0,1)$. Vamos a corroborarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,0])\n",
    "v2 = np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-0.5,1.5)\n",
    "plt.ylim(-0.5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-20,20)\n",
    "plt.ylim(-20,20)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y podemos ver que ahora s铆 estamos generando todo el espacio $\\mathbb{R^2}$ (recordemos que solo hicimos la iteraci贸n de -10 a 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi茅n podr铆amos construir el espacio con los siguientes vectores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,0])\n",
    "v2 = np.array([2,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-0.5,4)\n",
    "plt.ylim(-5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-25,25)\n",
    "plt.ylim(-25,25)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a visualizar como el espacio $\\mathbb{R}^2$ es un **subespacio** de $\\mathbb{R}^3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,0,0])\n",
    "v2 = np.array([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        ax.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b, v1[2]*a + v2[2]*b,\n",
    "                   marker= '.', color='purple')\n",
    "\n",
    "ax.set_xlabel('Eje X')\n",
    "ax.set_ylabel('Eje Y')\n",
    "ax.set_zlabel('Eje Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el espacio $\\mathbb{R}^2$ solo conforma una \"capa\" dentro de $\\mathbb{R}^3$, y como todos los elementos de $\\mathbb{R}^2$ est谩n contenidos en $\\mathbb{R}^3$, decimos que $\\mathbb{R}^2$ es un **subespacio de** $\\mathbb{R}^3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 谩lgebra lineal le llamamos **hiperplano** es un espacio de *menor dimensi贸n* al espacio en el cu谩l estamos trabajando. Por ejemplo, si estamos trabajando en $\\mathbb{R}^3$ entonces, $\\mathbb{R}^2$ es un **hiperplano**.\n",
    "\n",
    "Si estamos en un espacio de 3 dimensiones, el hiperplano ser铆a una \"capa\" u \"hoja\" como la que vemos arriba, en el caso de estar trabajando en 2 dimensiones tendr铆amos como hiperplano a una recta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjunto generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $\\{ v_1,v_2,\\dots, v_n \\}$ un conjunto de vectores de un espacio vectorial $V$.\n",
    "\n",
    "Si **todo vector** de $V$ se puede expresar como combinaci贸n lineal de  $ v_1,v_2,\\dots, v_n $, entonces se dice que $\\{ v_1,v_2,\\dots, v_n \\}$ es un **conjunto generador de V**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectores linealmente Independientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimos que 2 o m谩s vectores son **linealmente independientes** si ninguno de ellos puede ser escrito como una **combinaci贸n lineal** de los restantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O por el otro lado, un conjunto de vectores ${v_1, v_2, \\dots , v_n}$ de un espacio vectorial $V$ es **linealmente dependiente** si y s贸lo si al menos unos de los vectores puede expresarse como una combinaci贸n lineal de los dem谩s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la combinaci贸n de los $n$ vectores es igual al vector cero, entonces cada uno de los coeficientes de la combinaci贸n lineal es cero:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_1 \\vec{v_1} + a_2 \\vec{v_2} + \\dots + a_n \\vec{v_n} = \\vec{0} \\implies a_1 = a_2 = \\dots = a_n = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vectores linealmente independientes tienen distinta direcci贸n y sus componentes no son proporcionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retomemos nuestro ejemplos anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,1])\n",
    "v2 = np.array([-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-25,25)\n",
    "plt.ylim(-25,25)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recordemos que obtuvimos ese espacio ya que, $v2$ *se puede expresar como una combinaci贸n lineal de* $v1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, veamos el caso donde generamos a $\\mathbb{R}^2$ utilizando nuestros 2 vectores linealmente independientes $(1,0)$ y $(0,1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,1])\n",
    "v2 = np.array([1,0])\n",
    "\n",
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-20,20)\n",
    "plt.ylim(-20,20)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驴C贸mo generar铆amos a $\\mathbb{R}^3$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los vectores $v1=(1,0,0)$, $v2=(0,1,0)$ y $v3=(0,0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,0,0])\n",
    "v2 = np.array([0,1,0])\n",
    "v3 = np.array([0,0,1])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        for c in range(-10,10):\n",
    "            ax.scatter(v1[0]*a + v2[0]*b + v3[0]*c, v1[1]*a + v2[1]*b + v3[1]*c, v1[2]*a + v2[2]*b + v3[2]*c,\n",
    "                       marker= '.', color='purple')\n",
    "\n",
    "ax.set_xlabel('Eje X')\n",
    "ax.set_ylabel('Eje Y')\n",
    "ax.set_zlabel('Eje Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validar que una matriz tenga inversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que un sistema de ecuaciones tenga soluci贸n necesitamos que la matriz $A$ (que representa al sistema) sea cuadrada  y que todos sus vectores sean linealmente independientes.\n",
    "\n",
    "Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0,1,0,0],\n",
    "              [0,0,1,0],\n",
    "              [0,1,1,0],\n",
    "              [1,0,0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta matriz puede darnos la finta de que es cuadrada y contiene vectores linealmente independientes, pero poniendo un poco de atenci贸n notaremos que el 3er vector corresponde a una combinaci贸n lineal de los primeros 2 vectores. Por lo que al \"recrear\" nuestra matriz utilizando 煤nicamente vectores linealmente independientes, tendremos una matriz de $3 \\times 4$ la cual no es cuadrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos interpretar esto como si tuvieramos un sistema de ecuaciones donde tenemos la misma ecuaci贸n multiplicada por un factor $k$, donde aparentar铆a ser una nueva ecuaci贸n, pero NO nos est谩 dando ninguna informaci贸n extra para resolver el sistema. Por ello nos interesamos en crear la matriz 煤nicamente con vectores linearmente independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos descomponer nuestra matriz utilizando los autovalores y autovectores que ya hemos visto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas, V = np.linalg.eig(A.T)\n",
    "print(f'lambda:\\n {lambdas}\\nEigen Vector:\\n {V}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos 4 valores lambda o **eigenvalues**. Y uno de ellos es 0, para el 3er indice. Esto ser谩 importante m谩s adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La operaci贸n que realizamos en la instrucci贸n de arriba fue la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/hq6xg8j.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma de saber si hay una soluci贸n 煤nica para un sistema de ecuaciones o ver si nuestra matriz tiene inversa es asegurandonos de que cero no sea un valor propio de la matriz, ya que de ser as铆 la matriz ser铆a singular (no tiene inversa). Y como vimos en la salida de la linea anterior, tenemos un 0 en nuestro 3er indice de la lista de lambdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime el indice correspondiente a la columna de la matriz donde obtuvimos un eigenvalue igual a cero\n",
    "print(A[lambdas == 0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu铆 encontramos que tenemos un valor `lambda == 0` ya que el vector `[0 1 1 0]` se puede escribir como la suma de los vectores `[0 1 0 0]` y `[0 0 1 0]`.\n",
    "\n",
    "Al final esto es una convenci贸n, podr铆amos describir al vector 2 como una combinaci贸n lineal del 1 o el 3. En realidad siempre que tengamos 3 vectores y 1 de ellos puede ser descrito mediante los otros dos, podemos elegir la \"base\" que queramos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驴Qu茅 pasar铆a si intentaramos calcular la inversa de esta matriz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LinAlgError: Singular matrix`: tenemos una matriz singular. De hecho si vemos nuestra matriz como *columnas* podemos ver que la columna 1 y 4 son iguales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando en nuestra matriz tenemos vectores que pueden describirse mediante combinaciones lineales de los otros, ya se en las filas o en las columnas, obtendremos un determinante = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驴Qu茅 es una norma y para qu茅 se usa? Desigualdad triangular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La definici贸n general de la norma se basa en generalizar a espacios vectoriales abstractos el concepto de m贸dulo de un vector de un espacio eucl铆deo. En un espacio no eucl铆deo, la noci贸n de camino m谩s corto entre dos puntos no es m谩s identificable que con el de la l铆nea recta; por lo cual, se recurre a las propiedades operacionales de la norma eucl铆dea.\n",
    "\n",
    "En un espacio eucl铆deo los vectores son representados como segmentos orientados entre puntos del espacio. Dado un vector de un espacio vectorial eucl铆deo, la norma de un vector es definida como la **distancia** (en l铆nea recta) **entre dos puntos A y B** que delimitan al vector. Coincidiendo en un espacio eucl铆deo la norma de un vector con el m贸dulo del vector $\\vec{AB}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso general de un espacio eucl铆deo de $n$ dimensiones se tiene qu茅:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$||{AB}|| = \\sqrt{(b_1 - a_1)^2 + (b_2 - a_2)^2 + \\dots + (b_n - a_n)^2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esto se sigue que, fijada una base ortonormal $B$ en la cual un vector $v$ se da a partir de sus componentes en esta base, $VB=(v_1,v_2,\\dots, v_n)$, la norma de dicho vector vendr谩 dada por:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ ||v||= \\sqrt{v_1^2+ v_2^2+ \\dots + v_n^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La norma de un vector siempre tiene que ser $||v|| \\geq 0$.\n",
    "* $||v|| = 0 \\Longleftrightarrow v = 0$.\n",
    "* Dados 2 vectores $u$ y $v$, al sumar $u+v =s$ y calcular la norma de $||s||$ obtendremos que: $||s|| \\leq ||u|| + ||v||$.\n",
    "* $||av|| = abs(a) * ||v||$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La 3er propiedad es conocida como **desigualdad triangular**. Y nos da la noci贸n de que el camino m谩s corto siempre es una linea recta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver como calcular la norma en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Paleta de colores\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2,7])\n",
    "v2 = np.array([3,5])\n",
    "v1_plus_v2 = v1 + v2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2, v1_plus_v2], color=['red','blue', 'purple'], alpha=1)\n",
    "plt.xlim(-1,6)\n",
    "plt.ylim(-1,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular la norma, utilizamos la funci贸n `linalg.norm()` de NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_v1   = round(np.linalg.norm(v1),3)\n",
    "norm_v2   = round(np.linalg.norm(v2),3)\n",
    "norm_v1v2 = np.linalg.norm(v1_plus_v2)\n",
    "print(f'||v1||: {norm_v1}\\n||v2||: {norm_v2}\\n||v1+v2||: {norm_v1v2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_v1v2 <= norm_v1 + norm_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se respeta la desigualdad triangular. El 煤nico caso donde tenemos $||v+u|| = ||v||+||u||$ es cuando los 3 vectores est谩n uno sobre el otro (sobre la misma linea recta), es decir, cuando son colineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a graficar la suma de nuestros vectores, de forma que quede la punta de $v_1$ con la cola de $v_2$ y luego el vector resultante desde la cola de $v_1$ a la punta de $v_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,0,2,7])\n",
    "v2 = np.array([0,0,3,5])\n",
    "\n",
    "v1_aux = np.array([v1[2], v1[3], v2[2], v2[3]])\n",
    "v1v2 = np.array([0,0,5,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.quiver([v1[0], v1_aux[0], v1v2[0]], \n",
    "           [v1[1], v1_aux[1], v1v2[1]],\n",
    "           [v1[2], v1_aux[2], v1v2[2]],\n",
    "           [v1[3], v1_aux[3], v1v2[3]],\n",
    "           angles = 'xy',\n",
    "           scale_units = 'xy',\n",
    "           scale = 1,\n",
    "           color = sns.color_palette())\n",
    "plt.grid()\n",
    "plt.axhline(y=0, color='black')\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.xlim(-1,6)\n",
    "plt.ylim(-1,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de normas: norma 0, norma 1, norma 2, norma infinito y norma L2 al cuadrado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos distintos tipos de normas que solemos utilizar en Machine Learning, por ejemplo, para medir los errores. Entre las m谩s comunes tenemos los siguientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiendo de que tenemos un vector $v=(v_1, v_2, \\dots, v_n)$:\n",
    "\n",
    "* $L0$: N煤mero de elementos de $v$ diferentes de 0, $\\# v_i \\not = 0$\n",
    "* $L1$: La suma de los valores absolutos de las elementos de $v$, $\\sum_{i}{abs(v_i)}$\n",
    "* $L2$: Distancia eucl铆deana, $||v||= \\sqrt{v_1^2+ v_2^2+ \\dots + v_n^2} $\n",
    "* $L2^2$: Distancia eucl铆dea al cuadrado,  $||v||^2= v_1^2+ v_2^2+ \\dots + v_n^2$ \n",
    "    * Por ejemplo, al hacer producto interno de un vector por si mismo, $v \\cdot v^t$. Esto nos podr铆a brindar ventajas computacionales.\n",
    "* $L \\infty$: El valor m谩ximo de nuestros valores absolutos de los elementos de $v$, $\\text{max}_i (abs(v_i))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver como podr铆amos calcularlas con Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1,2,0,5,6,0])\n",
    "print(vector)\n",
    "print(np.linalg.norm(vector, ord = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1,2,3,4,5])\n",
    "print(vector)\n",
    "print(np.linalg.norm(vector, ord = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La instrucci贸n .norm tiene por defecto la norma L2\n",
    "l2 = np.linalg.norm(vector)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([3,4])\n",
    "print(vector)\n",
    "print(np.linalg.norm(vector, ord = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $L2^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_2 = (np.linalg.norm(vector, ord = 2)**2)\n",
    "print(l2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que tambi茅n se puede representar como el producto interno del vector por s铆 mismo transpuesto para que las dimensiones coincidan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dot = vector.dot(vector.T)\n",
    "print(l2_dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $L \\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1,2,3,4,-500])\n",
    "print(np.linalg.norm(vector, ord=np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las normas se utilizan para determinar el m贸dulo de regularizaci贸n en la construcci贸n de modelos de Machine Learning. La regularizaci贸n se utiliza para \"castigar\" la complejidad de un modelo y evitar *overfitting*, laS m谩s utilizadas son $L2$ por su simplicidad y $L1$ para esparcidad de los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M谩s info en: [Regularizaci贸n para lograr la simplicidad: Regularizaci贸n L](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization) (Se quitar谩 la versi贸n en espa帽ol el 31 de Julio). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/FmyrdWw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El producto interno como funci贸n de una norma y su visualizaci贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente vimos que podemos ver a la norma $L2$ como el producto interno del vector por si mismo, transpuesto; ahora, vamos a explorar la idea de expresar el producto interno de 2 vectores como **la norma de cada vector por el 谩ngulo que est谩n formando entre ellos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, teniendo los vectores $v_1$ y $v_2$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ v_1^t  \\cdot v_2 = norm(v_1) norm(v_2) \\cos(\\alpha) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,0,0,3])\n",
    "v2 = np.array([0,0,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.axvline(x=0, color='gray')\n",
    "plt.axhline(y=0, color = 'gray')\n",
    "plt.xlim(-2,4)\n",
    "plt.ylim(-2,4)\n",
    "\n",
    "plt.quiver([v1[0], v2[0]],\n",
    "           [v1[1], v2[1]],\n",
    "           [v1[2], v2[2]],\n",
    "           [v1[3], v2[3]],\n",
    "           angles = 'xy',\n",
    "           scale_units= 'xy',\n",
    "           scale = 1,\n",
    "           color = sns.color_palette()\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener un triangulo rect谩ngulo y a la vez tener un 谩ngulo de 90 grados partido a la mitad por el vector amarillo, sabemos que el 谩ngulo que forman los vectores es de 45掳."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos la igualdad que mencionamos arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,3])\n",
    "v2 = np.array([3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( (v1.T).dot(v2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar `math` o `numpy` para darle los valores de coseno y del 谩ngulo.\n",
    "\n",
    "Para el caso de `math` tenemos `math.cos` para la funci贸n coseno y `math.pi` para indicarle el valor de pi y lo dividimos entre 4, ya que, $\\pi / 2 = 90掳$ y queremos la mitad  de eso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print( np.linalg.norm(v1)*np.linalg.norm(v2)*math.cos(math.pi / 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de `NumPy` tenemos `np.cos` para la funci贸n coseno y `np.deg2rad()` para indicarle en radianes un valor que suministramos en grados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.linalg.norm(v1)*np.linalg.norm(v2)*np.cos( np.deg2rad(45) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que s铆 se puede describir un producto interno entre 2 vectores como el producto de sus normas por el coseno del 谩ngulo que forman. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No olvidemos agregar el 谩ngulo en **radianes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eso se vuelve importante en Machine Learning ya qu茅 el coseno se utiliza para medir el **accuracy** del modelo, midiendo la similitud entre las etiquetas y los valores que el modelo ha predicho.\n",
    "\n",
    "Teniendo la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\cos{x} = \\frac{v_1v_2}{norm(v_1)norm(v_2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto lo podemos imaginar como si tuvieramos 2 vectores, 1 de ellos representa el **vector de predicciones** y el otro, representa el **vector de etiquetas** (valores reales) y lo que queremos en un modelo es conseguir que el 谩ngulo entre esos 2 vectores sea el m铆nimo posible, sin entrar en un sobre-ajuste; as铆 conseguir铆amos buenas predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VIDEO: 驴Qu茅 tan parecidos son dos textos?| Similaridad coseno](https://www.youtube.com/watch?v=z0b7TAVtHrw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIDEO: Similaridad coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo las siguientes palabras:\n",
    "\n",
    "1. Tigre Tigre Perro\n",
    "2. Tigre Oso Perro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En dos vectores:\n",
    "\n",
    "$v_1 = [2,0,1]$ \n",
    "\n",
    "$v_2 = [1,1,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "v1 = np.array([2,0,1])\n",
    "v2 = np.array([1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, representandolos de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                   | 1           | 2             |\n",
    "|-------------------|-------------|---------------|\n",
    "| Tigre             | 2           | 1             | \n",
    "| Oso               | 0           | 1             | \n",
    "| Perro             | 1           | 1             | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la similaridad, como ya lo mencionamos antes, estar谩 dada por:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{sim}(A,B) = \\cos{\\theta} = \\frac{A \\cdot B}{||A|| ||B||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/WpfDNBt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/5l0TUjp.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El producto punto ser铆a el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_dot_v2 = (v1.T).dot(v2)\n",
    "print(v1_dot_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a obtener las normas de los vectores, utilizaremos $L2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_v1 = np.linalg.norm(v1, ord = 2)\n",
    "print(norm_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_v2 = np.linalg.norm(v2, ord = 2)\n",
    "print(norm_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando el valor del $\\cos{\\theta}$ a partir de eso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_theta = v1_dot_v2 / (norm_v1 * norm_v2)\n",
    "print(cos_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer esto directamente utilizando ScikitLearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([[2,0,1]])\n",
    "v2 = np.array([[1,1,1]])\n",
    "print(cosine_similarity(v1, v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices y vectores especiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La matriz diagonal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz diagonal** es una matriz cuadrada en la que todos los elementos que no son de la diagonal principal, son cero. Los elementos de la diagonal principal pueden ser nulos o no.\n",
    "\n",
    "Son matrices de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "a & 0 & 0 & 0 \\\\ \n",
    "0 & b & 0 & 0 \\\\ \n",
    "0 & 0 & c & 0 \\\\ \n",
    "0 & 0 & 0 & d \\\\ \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las razones por las que las matrices diagonales son tan importantes en 谩lgebra lineal es por la facilidad con la que permiten realizar c谩lculos. Por eso son tan utilizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Suma y resta de matrices diagonales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suma de dos matrices diagonales es muy sencilla, simplemente hay que sumar (o restar) los n煤meros de las diagonales:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ diag(a_1,\\dots,a_n) \\pm diag(b_1,\\dots,b_n) = diag(a_1 \\pm b_1 ,\\dots,a_n \\pm b_n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "2 & 0 & 0 & 0 \\\\ \n",
    "0 & 4 & 0 & 0 \\\\ \n",
    "0 & 0 & 6 & 0 \\\\ \n",
    "0 & 0 & 0 & 8 \\\\ \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiplicaci贸n de matrices diagonales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ diag(a_1,\\dots,a_n) \\cdot diag(b_1,\\dots,b_n) = diag(a_1 \\cdot b_1 ,\\dots,a_n \\cdot b_n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver una multiplicaci贸n de 2 matrices de 2 diagonales, tan solo tenemos que multiplicar los elementos de las diagonales entre s铆:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & -3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 0 & 0 \\\\ \n",
    "0 & 4 & 0 & 0 \\\\ \n",
    "0 & 0 & -9 & 0 \\\\ \n",
    "0 & 0 & 0 & 16 \\\\ \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de la **potencia** ocurre los mismo, elevamos cada elemento de la matriz al exponente al que tenemos la matriz entera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determinante de una matriz diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El determinante de una matriz diagonal es el producto de los elementos de la diagonal principal, ya que el resto de elementos tendr谩 un 0 que \"cancele\" esa parte del determinante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = diag(a_1, \\dots, a_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$det(A)= \\prod_{i=1}^{n}{a_i} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inversa de una matriz diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una matriz diagonal se puede invertir, **si y s贸lo si, todos los elementos de la diagonal principal son diferentes de 0**. En dicho caso decimos que la matriz diagonal es una matriz regular (s铆 se puede invertir)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrarla, basta con escribir el rec铆proco de cada uno de los elementos de la matriz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{pmatrix}\n",
    "\\longrightarrow\n",
    "A^{-1}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\frac{1}{1} & 0 & 0 & 0 \\\\ \n",
    "0 &\\frac{1}{2} & 0 & 0 \\\\ \n",
    "0 & 0 & \\frac{1}{3} & 0 \\\\ \n",
    "0 & 0 & 0 & \\frac{1}{4} \\\\ \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eigenvalues de una matriz diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores propios de una matriz diagonal son los elementos de su diagonal principal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{pmatrix}\n",
    "\\longrightarrow\n",
    "\\lambda_1 =1 ; \n",
    "\\lambda_2 =2 ;\n",
    "\\lambda_3 =3 ;\n",
    "\\lambda_4 =4 ;\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar la instrucci贸n `np.diag()` para crear una matriz diagonal y 煤nicamente indicarle los valores de la diagonal principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_elements = np.array([1,2,3,4,5])\n",
    "diag_matrix = np.diag(diag_elements)\n",
    "print(diag_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener una matriz diagonal y **multiplicarla por un vector** realmente no estamos obteniendo una combinaci贸n lineal como tal, ya qu茅 la primer componente del vector se multiplica con el primer elemento de la diagonal principal, el segundo con el segundo y as铆."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{pmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\ \n",
    "x_2 \\\\ \n",
    "x_3 \\\\ \n",
    "x_4 \\\\ \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 * x_1 \\\\ \n",
    "2* x_2 \\\\ \n",
    "3* x_3 \\\\ \n",
    "4* x_4 \\\\ \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimos que lo que est谩 haciendo es una **ponderaci贸n de los elementos del vector**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo la matriz diagonal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.diag([2,3,4,5])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y un vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([[1,1,1,1]])\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos el producto, con el vector traspuesto por el tema de las dimensiones :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_v1 = A.dot(v1.T)\n",
    "print(A_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un nuevo vector que \"amplifica\" los valores de la diagonal principal en proporci贸n a los valores del vector, en este caso 1; as铆 que se mantuvo igual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver el caso en donde queremos calcular la **inversa de la matriz**, lo cu谩l es muy f谩cil. Si queremos encontrar una matriz tal que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A A^{-1} = I$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, tendremos que conseguir que las diagonales se vuelvan 1. Y sabemos que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a \\cdot \\frac{1}{a} = \\frac{a}{a} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que bastar铆a con multiplicar cada elemento de la diagonal principal por sus rec铆procos. Es decir, por otra matriz que en su diagonal principal contenga los rec铆procos de la matriz original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo la matriz diagonal $A$ de arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.diag([2,3,4,5])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y su matriz diagonal inversa, a帽adiendo los rec铆procos de la diagonal principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = np.diag([1/2, 1/3, 1/4, 1/5])\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y multiplicamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = A.dot(A_inv)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como esperabamos, obtuvimos la matriz identidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hecho de poder calcular la inversa de una forma tan f谩cil, y por lo tanto, poder resolver ciertas operaciones m谩s f谩cilmente; nos ayuda a reducir mucho el coste computacional de ciertos problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz sim茅trica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una matriz es sim茅trica si es **una matriz cuadrada**, que adem谩s tiene la caracter铆stica de ser igual a su transpuesta. Una matriz de $n\\times m$ elementos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\begin{pmatrix}\n",
    "a_{11} & a_{12} & a_{13} & \\dots & a_{1m} \\\\ \n",
    "a_{21} & a_{22} & a_{23} & \\dots & a_{2m} \\\\ \n",
    "a_{31} & a_{32} & a_{33} & \\dots & a_{2m} \\\\ \n",
    "\\vdots & \\vdots & \\vdots & \\ddots& \\vdots  \\\\\n",
    "a_{n1} & a_{n2} & a_{n3} & \\dots & a_{nm} \\\\ \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es sim茅trica, su es una matriz cuadrada $(m=n)$ y adem谩s, $a_{ij} = a_{ji}$ para todo $i$, $j$ con $i$, $j$ $=1,2,3,4,\\dots,n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = A^T \\implies \\text{ es sim茅trica}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\begin{pmatrix}\n",
    "-8 & 1 & 3 \\\\ \n",
    " 1 & 7 & 4 \\\\ \n",
    " 3 & 4 &9 \\\\ \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos visualizarlo como si fuera un \"espejo\" a trav茅s de la diagonal principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Propiedades de las matrices sim茅tricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. La suma de dos matrices sim茅tricas es una matriz sim茅trica.\n",
    "2. El producto de dos matrices sim茅tricas NO siempre es sim茅trico.\n",
    "3. Si $A$ es una matriz sim茅trica $p\\times p$, y $B$ una matriz $p \\times q$, entonces $B^{T}AB$ es sim茅trica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los teoremas b谩sicos que concierne a este tipo de matrices es el **teorema  espectral de dimensi贸n finita**, que dice que toda matriz sim茅trica cuyos elementos sean *reales*, es *diagonalizable*. En particular, es diagonalizable mediante una **matriz ortogonal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo con Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simetrica = np.array([[1,2,3],\n",
    "                      [2,1,7],\n",
    "                      [3,7,11]])\n",
    "print(simetrica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simetrica_T = simetrica.T\n",
    "print(simetrica_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos ver que obtenemos la misma matriz al transponerla.\n",
    "\n",
    "Ahora, vamos a verificar la siguiente propiedad:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ (AB)^t = B^t A^t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pero si son sim茅tricas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ (AB)^t = B A$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y esto 煤ltimo tambi茅n tiene implicaciones importantes al agilizar nuestros c贸mputos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectores ortogonales, matrices ortogonales y sus propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectores Ortogonales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hay que aclarar que, **NO existen vectores que sean ortogonales por s铆 mismos**, ya que estos requieren estar \"en compa帽铆a\"  o en referencia de otro vector para poder definirlos como ortogonales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos vectores son **ortogonales** si su **producto interno es cero**. En general, el t茅rmino de **ortogonalidad** es una generalizaci贸n de la noci贸n que nos da el concepto de **perpendicularidad**. En el caso de un espacio eucl铆deo decimos que **ortogonal** y **perpendicular** significan lo mismo; sin embargo, en espacios de dimensi贸n finita y en geometr铆as no eucl铆deas, el concepto de ortogonalidad generaliza al de perpendicularidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente imagen tendr铆amos el caso de 3 **planos ortogonales**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/3D_coordinate_system.svg/350px-3D_coordinate_system.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que existe una relaci贸n entre el producto interno de 2 vectores y el 谩ngulo que forman entre s铆; m谩s espec铆ficamente, con el coseno del 谩ngulo que forman. Y como estamos hablando de vectores **perpendiculares**, es decir, con un 谩ngulo de $\\pi / 2$ radianes o 90掳, tendr铆amos el caso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\cos{\\pi / 2} = \\cos{90掳} = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualicemos este caso con Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0,0,2, 2])\n",
    "y = np.array([0,0,2,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.quiver([x[0],y[0]],\n",
    "           [x[1],y[1]],\n",
    "           [x[2],y[2]],\n",
    "           [x[3],y[3]],\n",
    "           angles = 'xy',\n",
    "           scale_units = 'xy',\n",
    "           scale = 1,\n",
    "           color = sns.color_palette()\n",
    "          )\n",
    "\n",
    "plt.grid()\n",
    "plt.axhline(y=0, color='gray')\n",
    "plt.axvline(x=0, color='gray')\n",
    "\n",
    "plt.xlim(-2,4)\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualmente podemos intuir que tenemos 2 vectores perpendiculares entre s铆, pero eso es gracias a que tenemos la escala correcta. As铆 que mejor, vamos a calcular el 谩ngulo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabiendo que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x \\cdot y = ||x|| ||y|| \\cos{\\theta} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "despejemos theta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\cos{\\theta} = \\frac{x \\cdot y}{||x|| ||y||} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\theta =  \\arccos{\\frac{x \\cdot y}{||x|| ||y||}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2, 2])\n",
    "y = np.array([2,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.arccos( (x.dot(y.T) ) / (  np.linalg.norm(x)*np.linalg.norm(y) ) )\n",
    "print(f'{theta} rads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_deg = np.degrees(theta)\n",
    "print(f'{theta_deg} Deg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectores Ortonormales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el otro lado, tenemos a los vectores **ortonormales**. Estos son vectores que tambi茅n tienen un **producto interno igual a 0** y *adem谩s*, son **vectores unitarios**, es decir, su norma es igual a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.centroestudioscervantinos.es/wp-content/uploads/2021/01/vectores-ortogonales-y-ortonomales-lifeder.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomemos los vectores anteriores que ya son **ortogonales**, pero a煤n NO son **ortonormales**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2, 2])\n",
    "y = np.array([2,-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculemos la norma de cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(x))\n",
    "print(np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no tienen norma $=1$, por lo que no son **ortonormales**. \n",
    "\n",
    "Vamos a tomar los siguientes vectores de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0,0,1, 0])\n",
    "y = np.array([0,0,0, -1])\n",
    "\n",
    "plt.quiver([x[0],y[0]],\n",
    "           [x[1],y[1]],\n",
    "           [x[2],y[2]],\n",
    "           [x[3],y[3]],\n",
    "           angles = 'xy',\n",
    "           scale_units = 'xy',\n",
    "           scale = 1,\n",
    "           color = sns.color_palette()\n",
    "          )\n",
    "\n",
    "plt.grid()\n",
    "plt.axhline(y=0, color='gray')\n",
    "plt.axvline(x=0, color='gray')\n",
    "\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a corroborar que son **ortogonales** aplicando el producto interno, esperando obtener cero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.dot(y.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tenemos 2 vectores **ortogonales**, ahora vamos a verificar que tengan norma $=1$ para verificar que sean **ortonormales**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(x))\n",
    "print(np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, tenemos 2 vectores que son **ortonormales** ya que forman un 谩ngulo de 90掳 y tienen una norma igual a 1.\n",
    "\n",
    "Este es un concepto importante al momento de construir un espacio vectorial y definir sus operaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices ortogonales y sus propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una matriz es **ortogonal** cuando todas sus filas son **mutuamente ortonormales** y tambi茅n sus columnas son **mutuamente ortonormales**. Es decir, si pensamos a las filas y columnas como vectores, estos vectores ser铆an mutuamente ortonormales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra definici贸n ser铆a la siguiente:\n",
    "\n",
    "Una matriz $A$ es **ortogonal** si multiplicada por su transpuesta $A^T$ da como resultado la matriz identidad $I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A A^{T} =  A^{T}A = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como consecuencia de lo anterior, tenemos que la transpuesta de una matriz ortogonal es igual a su **matriz inversa**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A^T = A^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[1,0,0],\n",
    "                   [0,1,0],\n",
    "                   [0,0,1],\n",
    "                  ])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la norma de los vectores, aunque sea f谩cil de ver que tienen norma $=1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(matrix[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(matrix[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(matrix[:, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar que sus columnas son mutuamente ortonormales, es decir, son **ortonorgonales** de **norma = 1**. En este caso podemos ver que son de norma 1, pues es el $1$ es el 煤nico valor que tienen en sus componentes, y podr铆amos hacer un producto interno para saber que son ortogonales.\n",
    "\n",
    "Comencemos haciendo el producto de las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(matrix[:, 0].dot(matrix[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(matrix[:, 0].dot(matrix[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(matrix[:, 1].dot(matrix[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tambi茅n si queremos podemos hacer el de las filas, aunque ya lo tenemos claro con haber realizado las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(matrix[0, :].dot(matrix[1,:]))\n",
    "print(matrix[0, :].dot(matrix[2,:]))\n",
    "print(matrix[1, :].dot(matrix[2,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hemos visto que si la visualizamos como vectores columna o fila, obtendremos vectores mutuamente ortonormales. Ahora vamos a comprobar las propiedades que vimos arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "Identity = matrix.dot(matrix.T)\n",
    "print(Identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "M_T = matrix.T\n",
    "print(M_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "M_inverse = np.linalg.inv(matrix)\n",
    "print(M_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(M_T == M_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que s铆 se cumplen. As铆 que, esta es una matriz ortogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las matrices no tenemos como tal una matriz **ortonormal** ya que no tendr铆a caso definirla de esa forma ya que contamos con vectores mutuamente ortonormales y no habr铆a forma de encontrar una distinci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a introducir r谩pidamente el concepto de **matrices de rotaci贸n**. Las cuales nos ayudar谩n a generar matrices ortogonales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de rotaci贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 谩lgebra lineal, una **matriz de rotaci贸n** es la matriz que representa una rotaci贸n en el espacio eucl铆deo. Por ejemplo, la matriz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R(\\theta)=\n",
    "\\begin{bmatrix}\n",
    "\\cos{\\theta} & -\\sin{\\theta} \\\\\n",
    "\\sin{\\theta} &  \\cos{\\theta}\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "que representa una rotaci贸n de $\\theta$ grados del plano **en sentido antihorario**. En tres dimensiones, las matrices de rotaci贸n representan rotaciones de manera concisa y se usan frecuentemente en geometr铆a, f铆sica e inform谩tica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver como podr铆amos utilizar una matriz de rotaci贸n de ese estilo para generar matrices ortogonales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887  0.50636564]\n",
      " [-0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[np.cos(100), -np.sin(100)],\n",
    "              [np.sin(100),  np.cos(100)],\n",
    "             ])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos si tiene vectores de norma = 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print( np.linalg.norm(A[0,:]) )\n",
    "print( np.linalg.norm(A[1,:]) )\n",
    "print( np.linalg.norm(A[:,0]) )\n",
    "print( np.linalg.norm(A[:,1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un valor muy muy cercano a 1, esto se debe a que existen ciertos problemas para representar nuestros n煤meros computacionalmente.\n",
    "\n",
    "\n",
    "Ahora, vamos a confirmar que son **mutuamente ortogonales**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(A[0,:].dot(A[1,:]))\n",
    "print(A[:,0].dot(A[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As铆 ya hemos confirmado que est谩 conformada por vectores **ortonormales**. Vamos a verificar las propiedades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887 -0.50636564]\n",
      " [ 0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "A_T = A.T\n",
    "print(A_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887 -0.50636564]\n",
      " [ 0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -7.93771519e-18]\n",
      " [-7.93771519e-18  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(A_T.dot(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 7.93771519e-18]\n",
      " [7.93771519e-18 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(A.dot(A_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que obtenemos la misma matriz, aunque no tenemos como tal ceros fuera de la diagonal principal, pero **s铆 tenemos n煤meros muy muy cercanos a 0**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver algunos de los errores a los que podr铆amos llegar si no tenemos cuidado con esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887 -0.50636564]\n",
      " [ 0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887 -0.50636564]\n",
      " [ 0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "print(A_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aqu铆 todo normal, estamos repitiendo los pasos anteriores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驴Que pasar铆a si dividieramos entre el producto de nuestra traspuesta y de la matriz original? Tendr铆amos una operaci贸n que no estar铆a definida (o infinito). Sin embargo, utilizando el resultado anterior obtenemos lo siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -1.25980837e+17]\n",
      " [-1.25980837e+17  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(1/ A_T.dot(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos obteniendo valores muy muy grandes en nuestros elementos fuera de la diagonal principal. Esto de debe a que realiz贸 los c贸mputos con los valores `-7.93771519e-18` los cuales al hacer el rec铆proco nos da un n煤mero que es muy muy grande, de forma que estar铆a amplificando estos elementos de la matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El determinante y la traza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El determinante se define como una [forma multilineal alternada](https://es.wikipedia.org/wiki/Forma_multilineal) sobre un espacio vectorial. Esta definici贸n indica una serie de propiedades matem谩ticas y generaliza el concepto de determinante de una matriz haci茅ndolo aplicable en distintos campos. El concepto de *determinante* fue introducido para estudiar el n煤mero de soluciones de los sistemas de ecuaciones lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El determinante de una matriz siempre es un n煤mero real y 煤nicamente lo podremos calcular para matrices cuadradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de matrices, el terminante de una matriz nos indica si estamos ante un **sistema singular** o **no singular** de ecuaciones lineales. Por ello, si el resultado del determinante es cero, estaremos ante una matriz singular, y si el resultado es $\\not = 0$ entonces estamos ante una matriz no singular.\n",
    "\n",
    "Este nos habla sobre la **transformaci贸n que ejerce una matriz sobre el espacio que est谩 transformando**. Si es negativo, nos da el \"espejo\" de nuestro espacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre algunos de sus usos tenemos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nos permite estudiar la posici贸n relativa de rectas y planos.\n",
    "\n",
    "* Podemos obtener la ecuaci贸n impl铆cita de un plano.\n",
    "\n",
    "* Son un instrumento para calcular 谩reas de figuras en el plano.\n",
    "\n",
    "* Nos ayudan a calcular el rango de una matriz con par谩metros.\n",
    "\n",
    "* Son 煤tiles para calcular el volumen de los paralep铆pedos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que podemos construir nuestro espacio a partir de una *base* de *vectores* que nos permitan construir el resto a partir de operaciones de suma o multiplicaci贸n (combinaciones lineales).\n",
    "\n",
    "驴Qu茅 pasar铆a si tuvieramos bases de vectores en la misma direcci贸n, pero con diferentes magnitudes? En ese caso, podr铆an cambiar algunas de nuestra funciones al reescribir nuestras matrices en funciones de esos nuevos vectores. Para esto utilizamos la **traza** que nos permite trabajar **independientemente del sistema de referencia** en el que estemos trabajando, de forma que siempre nos devuelve los mismos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/LoqexDt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 谩lgebra lineal, la **traza** es una matriz $A$ de tama帽o $n \\times m$, denotada por $tr(A)$, se define como la suma de los elementos de la diagonal principal de $A$, es decir:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$tr(A) = \\sum_{i = 1}^{n}{a_{ii}} = a_{11}+ a_{22} + \\dots + a_{nn}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $a_{ii}$ representa el elemento que est谩 en la $i-$茅sima fila y en la $i-$茅sima columna de la matriz $A$. Para cualquier otra matriz, la traza es la **suma de sus valores propios**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido al especial comportamiento de la traza de una matriz al cambiar de base, puede definirse una un铆vocamente  la traza de una aplicaci贸n lineal, **independientemente de cual sea la base elegida**, Si un espacio vectorial de dimensi贸n finita est谩 dotado de un producto escalar y se tiene una base ortonormal, entonces la traza de un *endomorfismo* de dicho espacio viene dada por:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ tr f := \\sum_{k}\\langle f(e_{k}), e_{k}\\rangle $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede comprobarse que si $A_{f}$ es la matriz de dicha aplicaci贸n respecto a dicha base, la cantidad anterior **es igual** a la traza de la matriz $A$. Y de hecho, si $B_{f}$ es la matriz de la misma aplicaci贸n respecto a cualquier otra base ortonormal se tiene:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ tr f = tr A_{f} = tr B_{f} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.array([[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9],\n",
    "                  ])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la traza de nuestra matriz haremos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "traza =  np.trace(matrix)\n",
    "print(traza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir nuevos vectores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,1])\n",
    "v2 = np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.25, 1.25)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graficar_vectores([v1,v2], ['purple','blue'], 1)\n",
    "plt.xlim(-0.25,1.25)\n",
    "plt.ylim(-0.25,1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驴Qu茅 pasar铆a si aplicamos una matriz a estos 2 vectores? Recordemos que con estos vectores podemos generar a todo $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2,0],\n",
    "              [0,2]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que este tipo de matrices \"amplifican\" las coordenadas de nuestros vectores. En este caso los estar铆a duplicando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n",
      "[2 0]\n"
     ]
    }
   ],
   "source": [
    "A_v1 = A.dot(v1)\n",
    "A_v2 = A.dot(v2)\n",
    "print(A_v1)\n",
    "print(A_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.25, 2.25)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graficar_vectores([A_v1,A_v2], ['red','green'], 1)\n",
    "plt.xlim(-0.25,2.25)\n",
    "plt.ylim(-0.25,2.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que seguimos teniendo 2 vectores ortogonales, pero ya no son de norma igual a 1, sino que ahora miden 2.\n",
    "\n",
    "Imaginemos esto como si tuvieramos 2 cuadrados a partir de las longitudes de nuestros vectores, de forma que ahora contamos con 2 cuadrados proporcionales de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/HdMOokZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular el determinante de A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "det_A = np.linalg.det(A)\n",
    "print(det_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos decir que, *el cuadrado unitario* formado por 2 vectores *ortonormales*, aumento 4 veces su 谩rea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "area_T = abs( (A_v1[0] - A_v2[0])  * abs( A_v1[1] - A_v2[1]) ) # lado * Lado\n",
    "print(area_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que ocurrir铆a en caso de tener un **determinante negativo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2  0]\n",
      " [ 0  2]]\n"
     ]
    }
   ],
   "source": [
    "B = A * [-1, 1]\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.0\n"
     ]
    }
   ],
   "source": [
    "det_B = np.linalg.det(B)\n",
    "print(det_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que es lo que les har铆a esta matriz a nuestros vectores anteriores, vamos a escribirlos de nuevo y vamos a graficarlos todos juntos para que sea m谩s visual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,1])\n",
    "v2 = np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_B = B.dot(v1)\n",
    "v2_B = B.dot(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 2.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graficar_vectores([v1_B, v2_B, v1, v2], ['red','blue','purple','green'], 1)\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el signo negativo del determinante **est谩 haciendo rotar a nuestro espacio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPiv9zPYkOv/TkQILiye/UB",
   "collapsed_sections": [],
   "name": "Fundamentos_Algebra_Lineal_con_Python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenidos ",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "439.667px",
    "left": "49px",
    "top": "162.567px",
    "width": "306px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
